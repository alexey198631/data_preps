{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa16cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import importlib\n",
    "\n",
    "# keeping company information in additional file\n",
    "import data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2c66d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_person_n = data_file.sales_person_n\n",
    "exlbu=data_file.exlbu\n",
    "exlpanrter=data_file.exlpanrter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f995c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data_files/order_data.db')\n",
    "query = \"SELECT * FROM orders\"  # Replace 'tablename' with your table name\n",
    "df_orders = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "conn2 = sqlite3.connect('data_files/customer_data.db')\n",
    "query = \"SELECT * FROM customers\"  # Replace 'tablename' with your table name\n",
    "df_customers = pd.read_sql_query(query, conn2)\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0827efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes I keep this lines\n",
    "wdf = df_customers.copy()\n",
    "dfc = df_orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3e892e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bu_defin = df_orders.loc[:, ['bu2', 'for_bu']]\n",
    "bu_defin.dropna(inplace=True)\n",
    "bu_defin.drop_duplicates(inplace=True)\n",
    "bu_defin.reset_index(inplace=True, drop=True)\n",
    "bu_defin.loc[bu_defin['bu2'] == exlbu, 'for_bu'] = 'PCI Transmitters'\n",
    "bu_defin['for_bu'] = bu_defin['for_bu'].astype('category')\n",
    "bu_defin['bu2'] = bu_defin['bu2'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d93334b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data = dfc.loc[:,['company_code_n', 'year_month', 'FY', \n",
    "       'bu2', 'sales_person_n', 'sales_order_so', 'sold_to_customer',\n",
    "       'sold_to_customer_n','order_intake_amount_eur', 'special case']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a403293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bu column for future reports\n",
    "order_data = order_data.merge(bu_defin, how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c11f3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_columns = list(order_data.columns) + ['customer_name', 'indirect_direct', 'tier', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case with specific SO for agent\n",
    "agent_so = data_file.special_so\n",
    "agent_one = data_file.agent_one\n",
    "so_order_data = order_data[order_data['sales_order_so'] == agent_so]\n",
    "\n",
    "so_order_data['customer_name'] = agent_one\n",
    "so_order_data['indirect_direct'] = 'Indirect'\n",
    "so_order_data['tier'] = 'Channel Partner'\n",
    "so_order_data['type'] = 'Agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc4b65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special case with specific cutomers for agent\n",
    "partners_data = wdf[wdf['tier'].notna() | wdf[exlpanrter].notna()]\n",
    "agent_two = data_file.agent_two\n",
    "partners_data.loc[partners_data[exlpanrter].notna(), 'customer_name'] = agent_two\n",
    "partners_data = partners_data.loc[:, ['sold_to_customer', 'agent_person', 'company_code_n', 'sold_to_customer_n','customer_name', \n",
    "       'indirect_direct', 'channel', 'type', 'tier']]\n",
    "\n",
    "partners_data['sold_to_customer'] = partners_data['sold_to_customer'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e06c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_partners = partners_data[partners_data['agent_person'].notna()]\n",
    "# agent sales records preparation\n",
    "agents_order_data = order_data[order_data['sales_person_n'].isin(sales_person_n)]\n",
    "agents_order_data = agents_order_data.merge(agent_partners, left_on='sales_person_n', right_on='sold_to_customer_n', how='left')\n",
    "agents_order_data = agents_order_data.filter(regex='^(?!.*_y)')\n",
    "# Exclude '_x' from all column names\n",
    "agents_order_data.columns = agents_order_data.columns.str.replace('_x', '')\n",
    "agents_order_data = agents_order_data.loc[:, order_columns]\n",
    "agents_order_data['type'] = 'Agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7fd659a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude agents sales from order data not to double lines\n",
    "order_data = order_data[~order_data['sales_person_n'].isin(sales_person_n)]\n",
    "# all partners except agents data preparation\n",
    "other_order_data = order_data[order_data['sold_to_customer'].isin(partners_data['sold_to_customer'])]\n",
    "other_order_data = other_order_data.merge(partners_data, left_on='sold_to_customer', right_on='sold_to_customer', how='left')\n",
    "other_order_data = other_order_data.filter(regex='^(?!.*_y)')\n",
    "# Exclude '_x' from all column names\n",
    "other_order_data.columns = other_order_data.columns.str.replace('_x', '')\n",
    "other_order_data = other_order_data.loc[:, order_columns]\n",
    "# Update values in columns based on the specific value\n",
    "other_order_data.loc[other_order_data['indirect_direct'] == 'Direct', 'tier'] = 'Channel Partner'\n",
    "other_order_data.loc[other_order_data['indirect_direct'] == 'Direct', 'type'] = 'Agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8bd40c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining all the sales records\n",
    "full_data = pd.concat([other_order_data, agents_order_data, so_order_data])\n",
    "full_data.reset_index(inplace=True, drop=True)\n",
    "#full_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1905c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_rows = full_data[full_data.duplicated(subset=['company_code_n', 'year_month', 'FY', 'bu2', 'sales_person_n',\n",
    "       'sales_order_so', 'sold_to_customer', 'sold_to_customer_n', 'for_bu', 'customer_name', 'indirect_direct', 'tier',\n",
    "       'type'], keep=False)]\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/outcome/duplicated_rows.xlsx')\n",
    "# Save each DataFrame to a separate sheet in the same file\n",
    "duplicated_rows.to_excel(writer, sheet_name='duplicated_rows')\n",
    "# Save the file\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c3a6c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing purposes I keep this lines\n",
    "full_data_df = full_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "78d82bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_data = reserve.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "59dce12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69770"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e9b37ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean other division products\n",
    "\n",
    "# define a list of products which I want to mark separetely\n",
    "product_list = data_file.tm_product_list\n",
    "tm_threshold = 0.6\n",
    "\n",
    "# define total sum of orders for each customer\n",
    "total_sum = full_data_df.groupby('customer_name')['order_intake_amount_eur'].sum()\n",
    "total_sum = total_sum.rename('total_OI')\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, total_sum, on='customer_name', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['total_OI'] = full_data_df['total_OI'].fillna(0)\n",
    "\n",
    "# Calculate the sum of sales for the products which I want to mark across all companies\n",
    "total_tm = full_data_df[full_data_df['bu2'].isin(product_list)].groupby('customer_name')['order_intake_amount_eur'].sum().reset_index()\n",
    "# Rename the 'order_intake_amount_eur' column to 'tm_sum'\n",
    "total_tm.rename(columns={'order_intake_amount_eur': 'tm_sum'}, inplace=True)\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, total_tm, on='customer_name', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['tm_sum'] = full_data_df['tm_sum'].fillna(0)\n",
    "\n",
    "# calculate the percentage of sales for the products in the list for each company\n",
    "full_data_df['tm_share'] = full_data_df['tm_sum'] / full_data_df['total_OI']\n",
    "full_data_df['tm_share'] = full_data_df['tm_share'].fillna(0)\n",
    "\n",
    "# label companies where the percentage of sales for all products in the list is greater than treshold value\n",
    "full_data_df['tm_check'] = 'no'\n",
    "full_data_df.loc[full_data_df['tm_share'] > tm_threshold, 'tm_check'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "31777f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marking special case\n",
    "\n",
    "special_one = data_file.special_one\n",
    "special_one_office = data_file.special_one_office\n",
    "# Filter the DataFrame based on the conditions\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] == special_one_office) , 'tm_check'] = 'no'\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] != special_one_office) , 'tier'] = 'Independent Sales Company'\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] != special_one_office) , 'type'] = 'Trading Firm'\n",
    "\n",
    "special_two = data_file.special_two\n",
    "special_two_file_name = data_file.special_two_file_name\n",
    "\n",
    "# Filter the DataFrame based on the conditions\n",
    "# Convert 'data' column to datetime format\n",
    "full_data_df['FY'] = pd.to_datetime(full_data_df['FY'])\n",
    "\n",
    "special_two_so = pd.read_excel(special_two_file_name)\n",
    "condition_a = full_data_df['sales_person_n'] != special_two\n",
    "condition_b = full_data_df['sales_person_n'] == special_two\n",
    "condition_c = full_data_df['sales_order_so'].isin(special_two_so['sales_order_so'])\n",
    "condition_d = full_data_df['FY'].dt.year > 2022\n",
    "full_data_df = full_data_df.loc[ condition_a | (condition_b & condition_c) | (condition_b & condition_d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47cda779",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_exclusion_office = data_file.tm_exclusion_office\n",
    "special_three = data_file.special_three\n",
    "special_four = data_file.special_four\n",
    "special_five = data_file.special_five\n",
    "\n",
    "# eclusion case for t&m \n",
    "exl_condition_a = full_data_df['FY'].dt.year == 2022\n",
    "exl_condition_b = full_data_df['company_code_n'] != tm_exclusion_office\n",
    "exl_condition_c = full_data_df['tm_check'] == 'yes'\n",
    "exl_condition_d = full_data_df['customer_name'] == special_three\n",
    "exl_condition_e = full_data_df['customer_name'] == special_four\n",
    "exl_condition_f = full_data_df['customer_name'] == special_five\n",
    "full_data_df.loc[exl_condition_a & exl_condition_d | exl_condition_a & exl_condition_e | exl_condition_a & exl_condition_f | exl_condition_a & exl_condition_b & exl_condition_c, 'tm_check'] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c879a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68567"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f3ed2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "column_order = ['sold_to_customer','customer_name', 'sold_to_customer_n', 'company_code_n', 'indirect_direct', 'tier', 'type', 'year_month', 'FY', \n",
    "       'bu2', 'for_bu', 'sales_order_so', 'sales_person_n','order_intake_amount_eur', 'tm_check', 'tm_share']\n",
    "\n",
    "# Reorder the columns\n",
    "full_data_df = full_data_df[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "751eeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/outcome/results.xlsx')\n",
    "# Save each DataFrame to a separate sheet in the same file\n",
    "full_data_df.to_excel(writer, sheet_name='results', index=False)\n",
    "# Save the file\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d02ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders['FY'] = pd.to_datetime(df_orders['FY'])\n",
    "df_orders.loc[(df_orders['special case'] == 3) & (df_orders['FY'].dt.year == 2022) , 'order_intake_amount_eur'].sum()\n",
    "lost_orders = check_order[~check_order['sales_order_so'].isin(full_data_df['sales_order_so'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9a8494bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other way to indentify T&M customers\n",
    "\n",
    "#clean other division products\n",
    "\n",
    "# define a list of products which I want to mark separetely\n",
    "product_list = data_file.tm_product_list\n",
    "pers_tm_threshold = 0.55\n",
    "\n",
    "# define total sum of orders for each customer\n",
    "person_total_sum = full_data_df.groupby('sales_person_n')['order_intake_amount_eur'].sum()\n",
    "person_total_sum = person_total_sum.rename('person_total_OI')\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, person_total_sum, on='sales_person_n', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['person_total_OI'] = full_data_df['person_total_OI'].fillna(0)\n",
    "\n",
    "# Calculate the sum of sales for the products which I want to mark across all companies\n",
    "person_total_tm = full_data_df[full_data_df['bu2'].isin(product_list)].groupby('sales_person_n')['order_intake_amount_eur'].sum().reset_index()\n",
    "# Rename the 'order_intake_amount_eur' column to 'tm_sum'\n",
    "person_total_tm.rename(columns={'order_intake_amount_eur': 'pers_tm_sum'}, inplace=True)\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, person_total_tm, on='sales_person_n', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['pers_tm_sum'] = full_data_df['pers_tm_sum'].fillna(0)\n",
    "\n",
    "# calculate the percentage of sales for the products in the list for each company\n",
    "full_data_df['pers_tm_share'] = full_data_df['pers_tm_sum'] / full_data_df['person_total_OI']\n",
    "full_data_df['pers_tm_share'] = full_data_df['pers_tm_share'].fillna(0)\n",
    "\n",
    "# label companies where the percentage of sales for all products in the list is greater than treshold value\n",
    "full_data_df['pers_tm_check'] = 'no'\n",
    "full_data_df.loc[full_data_df['pers_tm_share'] > pers_tm_threshold, 'pers_tm_check'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "99182a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter companies with only 'yes' values in column P\n",
    "filtered_companies = full_data_df[full_data_df['pers_tm_check'] == 'yes']['sold_to_customer'].tolist()\n",
    "filtered_companies_no = full_data_df[full_data_df['pers_tm_check'] == 'no']['sold_to_customer'].tolist()\n",
    "filtered_companies = [x for x in filtered_companies if x not in filtered_companies_no]\n",
    "filtered_companies = list(set(filtered_companies))\n",
    "\n",
    "full_data_df['personal check'] = 'no'\n",
    "full_data_df.loc[full_data_df['sold_to_customer'].isin(filtered_companies), 'personal check'] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfbfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/outcome/results_pers.xlsx')\n",
    "# Save each DataFrame to a separate sheet in the same file\n",
    "full_data_df.to_excel(writer, sheet_name='results', index=False)\n",
    "# Save the file\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
