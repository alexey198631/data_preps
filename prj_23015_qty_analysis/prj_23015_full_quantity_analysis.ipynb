{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d395b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import importlib\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# keeping company information in additional file\n",
    "import data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da26203",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509b7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_bu = data_file.key_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6aca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation of db from excel source copied from Tableau # APPLY ONLY IF NO DB EXISTS\n",
    "\n",
    "source_file = 'data_files/source_data.xlsx'\n",
    "# Convert the sheet to a Pandas dataframe\n",
    "df_1 = pd.read_excel(source_file, sheet_name='1719')\n",
    "df_2 = pd.read_excel(source_file, sheet_name='2023')\n",
    "\n",
    "df = pd.concat([df_1, df_2])\n",
    "\n",
    "conn = sqlite3.connect('data_files/ms_orders_data.db')\n",
    "df.to_sql('codes', conn, index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0844df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading database data and transforming it to pandas datafranme\n",
    "\n",
    "product_orders_db_path = data_file.product_orders_db_path \n",
    "\n",
    "conn = sqlite3.connect(product_orders_db_path)\n",
    "query = \"SELECT * FROM codes\" \n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "customer_db_path = data_file.customer_db_path\n",
    "\n",
    "conn = sqlite3.connect(customer_db_path)\n",
    "query = \"SELECT * FROM customers\"  \n",
    "df_customers = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88f1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning initial data from intercompany orders\n",
    "\n",
    "df['sold_to_customer_n_latest'] = df['sold_to_customer_n_latest'].astype(str)\n",
    "#exclusion lines with some specific companies\n",
    "my_company_name = data_file.my_company_name\n",
    "exclusion_company_one = data_file.exclusion_company_one\n",
    "exclusion_company_two = data_file.exclusion_company_two\n",
    "exclusion_company_three = data_file.exclusion_company_three\n",
    "\n",
    "#necessary modifications of columns\n",
    "df['bu'] = df['bu'].astype(str)\n",
    "df['company_upper'] = df['sold_to_customer_n_latest'].str.upper()\n",
    "# Filter out rows with unwanted value in column2\n",
    "df = df[~df['company_upper'].str.contains(my_company_name) & ~df['company_upper'].str.contains(exclusion_company_one) & ~df['company_upper'].str.contains(exclusion_company_two) & ~df['company_upper'].str.contains(exclusion_company_three)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9120c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe based on conditions  delete rows where both columns = 0\n",
    "df = df[(df['order_intake_quantity'] != 0) | (df['order_intake_euro'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0dd22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same format for sold_to_customer column for further merging\n",
    "df['sold_to_customer'] = df['sold_to_customer'].astype(str)\n",
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "\n",
    "#keep only necessary columns\n",
    "df_cusmoters_for_merging = df_customers.loc[:, ['sold_to_customer','customer_name', 'indirect_direct', 'channel', 'type', 'tier_new', 'tier']]\n",
    "\n",
    "df_merged = df.merge(df_cusmoters_for_merging, on='sold_to_customer', how='left')\n",
    "\n",
    "df_merged = df_merged.loc[:, ['year_month', 'company_code_n', 'sales_order_so', 'sold_to_customer',\n",
    "       'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'material_n',\n",
    "       'ms_code', 'order_intake_quantity', 'order_intake_euro', 'customer_name', 'indirect_direct', 'channel', 'type',\n",
    "       'tier_new', 'tier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7db16008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving information only for key bu groups\n",
    "\n",
    "df = df_merged[df_merged['bu'].isin(key_bu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving information only for necessary channel  - APPLY IT ONLY IF NECESSARY\n",
    "\n",
    "df = df_merged[df_merged['tier'] == 'Channel Partner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7b8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding fiscal year information\n",
    "\n",
    "temp_df = df.copy()\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df['year_month_date'] = pd.to_datetime(temp_df['year_month'], format='%Y%m')\n",
    "temp_df['FY'] = np.where(temp_df['year_month_date'].dt.month >= 4, temp_df['year_month_date'].dt.year, temp_df['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df['quarter'] = temp_df['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df['half_year'] = np.where(temp_df['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66fc589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some position with added _000000 suffix (stockable position) and auxililary position with suffixes like BOP, ENT, EXP\n",
    "# it necessary to clean them\n",
    "\n",
    "# Splitting the 'material' column and keeping the part before '_0'\n",
    "temp_df['material'] = temp_df['material'].str.split('_0', expand=True)[0]\n",
    "\n",
    "# Delete rows where 'ms_code' contains text with 'BOP'\n",
    "temp_df['ms_code'] = temp_df['ms_code'].astype(str)\n",
    "temp_df = temp_df[~temp_df['ms_code'].str.contains('BOP')]\n",
    "\n",
    "# Delete rows where 'ms_code' contains text with 'ENT'\n",
    "temp_df = temp_df[~temp_df['ms_code'].str.contains('ENT')]\n",
    "\n",
    "# Delete rows where 'ms_code' contains text with 'EXP'\n",
    "temp_df = temp_df[~temp_df['ms_code'].str.contains('EXP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f49f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only the most valuable position\n",
    "\n",
    "threshold_value = 0.95\n",
    "\n",
    "key_materials = temp_df.copy()\n",
    "\n",
    "# Calculate the sum of orders for each material within each business unit\n",
    "summary = key_materials.groupby(['bu', 'material'])['order_intake_euro'].sum().reset_index()\n",
    "\n",
    "# Sort the materials within each business unit based on their sum values in descending order\n",
    "summary = summary.sort_values(['bu', 'order_intake_euro'], ascending=[True, False])\n",
    "\n",
    "# Calculate the cumulative sum of the sorted materials within each business unit\n",
    "summary['cumulative_sum'] = summary.groupby('bu')['order_intake_euro'].cumsum()\n",
    "\n",
    "# Calculate the threshold value that represents 95% of the total sum value within each business unit\n",
    "summary['total_sum'] = summary.groupby('bu')['order_intake_euro'].transform('sum')\n",
    "summary['threshold'] = summary['total_sum'] * threshold_value\n",
    "\n",
    "# Filter the materials within each business unit based on the threshold value\n",
    "summary_filtered = summary[summary['cumulative_sum'] <= summary['threshold']]\n",
    "\n",
    "more_valuable_materials = list(summary_filtered['material'].unique())\n",
    "\n",
    "key_materials = temp_df[temp_df['material'].isin(more_valuable_materials)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79835f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_materials = key_materials.loc[:, ['FY', 'customer_name', 'bu', 'material', 'ms_code', 'order_intake_quantity', 'order_intake_euro']]\n",
    "\n",
    "# FY23 has just started, so it is better to exlude values for further analysis\n",
    "key_materials = key_materials[key_materials['FY'] < 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products - full code - quantities in Year periods\n",
    "pivot_df_material_qty = key_materials.pivot_table(index=['customer_name', 'bu', 'material'], \n",
    "                          columns='FY', \n",
    "                          values='order_intake_quantity', \n",
    "                          aggfunc='sum',fill_value=0)\n",
    "\n",
    "pivot_df_material_qty.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# products quantities in Year periods\n",
    "pivot_df_material_qty_no_customer = key_materials.pivot_table(index=['bu', 'material'], \n",
    "                          columns='FY', \n",
    "                          values='order_intake_quantity', \n",
    "                          aggfunc='sum',fill_value=0)\n",
    "\n",
    "pivot_df_material_qty_no_customer.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION with customer information\n",
    "\n",
    "# products codes quantities in Year periods\n",
    "pivot_df_qty = key_materials(index=['customer_name', 'bu', 'material', 'ms_code'], \n",
    "                          columns='FY', \n",
    "                          values='order_intake_quantity', \n",
    "                          aggfunc='sum')\n",
    "\n",
    "# products codes orders sum in Year periods\n",
    "pivot_df_sum = key_materials.pivot_table(index=['customer_name', 'bu', 'material', 'ms_code'], \n",
    "                          columns='FY', \n",
    "                          values='order_intake_euro', \n",
    "                          aggfunc='sum')\n",
    "\n",
    "result_pivot = pivot_df_qty.join(pivot_df_sum, lsuffix='_qty', rsuffix='_eur')\n",
    "\n",
    "\n",
    "# Resetting the index to make customer_name and material as normal columns\n",
    "result_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Renaming the columns for clarity\n",
    "result_pivot.columns.name = None\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    qty_column = f'{year}_qty'\n",
    "    eur_column = f'{year}_eur'\n",
    "    \n",
    "    result_pivot[eur_column] = result_pivot[eur_column] / result_pivot[qty_column]\n",
    "    result_pivot[eur_column] = result_pivot[eur_column].round(2)\n",
    "    result_pivot[eur_column] = result_pivot[eur_column].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "#result_pivot = result_pivot.loc[:, ['customer_name', 'bu', 'material', 'ms_code','2017_eur',\n",
    "#       '2018_eur', '2019_eur', '2020_eur', '2021_eur', '2022_eur', '2023_eur']]\n",
    "    \n",
    "#pivot_df_material_qty = pivot_df_material_qty.reset_index()\n",
    "result_pivot.to_excel('data_files/result_pivot_with_customers.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trends info with customer information\n",
    "\n",
    "# convert the dataframe to long format\n",
    "df_long_qty = pivot_df_material_qty.melt(id_vars=['customer_name', 'bu', 'material'], var_name='year', value_name='qty')\n",
    "\n",
    "# convert year to integer\n",
    "df_long_qty['year'] = df_long_qty['year'].astype(int)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Group by customer_name and material and run a regression for each group\n",
    "for (customer_name, material), group in df_long_qty.groupby(['customer_name', 'material']):\n",
    "    # Skip this group if it only has one row\n",
    "    if len(group) <= 1:\n",
    "        continue\n",
    "        \n",
    "    group['qty'] = group['qty'].fillna(0)\n",
    "    \n",
    "    # Check if group is empty\n",
    "    if group.empty:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Run the regression\n",
    "    X = group['year'].values.reshape(-1,1)  # reshape is needed because we have only one feature\n",
    "    y = group['qty']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Save the slope coefficient (i.e., trend) in the results\n",
    "    results[(customer_name, material)] = model.coef_[0]\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "trends = pd.DataFrame.from_dict(results, orient='index', columns=['trend'])\n",
    "\n",
    "# Reset the index\n",
    "trends.reset_index(inplace=True)\n",
    "\n",
    "# Split the tuple into two separate columns\n",
    "trends[['customer_name', 'material']] = pd.DataFrame(trends['index'].tolist(), index=trends.index)\n",
    "\n",
    "# Drop the original 'index' column\n",
    "trends.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Set the column names (optional, the column names should be correct now)\n",
    "# trends.columns = ['customer_name', 'material', 'trend']\n",
    "\n",
    "# Sort the DataFrame by customer_name and material\n",
    "trends = trends.sort_values(['customer_name', 'material'])\n",
    "\n",
    "#pivot_to_excel\n",
    "trends.to_excel('data_files/trends_with_customers.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc604b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trends info without customers inforamtion\n",
    "\n",
    "# convert the dataframe to long format\n",
    "df_long_qty = pivot_df_material_qty.melt(id_vars=['customer_name', 'bu', 'material'], var_name='year', value_name='qty')\n",
    "\n",
    "# convert year to integer\n",
    "df_long_qty['year'] = df_long_qty['year'].astype(int)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Group by customer_name and material and run a regression for each group\n",
    "for (material, bu), group in df_long_qty.groupby(['material', 'bu']):\n",
    "    # Skip this group if it only has one row\n",
    "    if len(group) <= 1:\n",
    "        continue\n",
    "        \n",
    "    group['qty'] = group['qty'].fillna(0)\n",
    "    \n",
    "    # Check if group is empty\n",
    "    if group.empty:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Run the regression\n",
    "    X = group['year'].values.reshape(-1,1)  # reshape is needed because we have only one feature\n",
    "    y = group['qty']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    print(model.coef_)\n",
    "    \n",
    "    # Save the slope coefficient (i.e., trend) in the results\n",
    "    results[(material, bu)] = model.coef_[0]\n",
    "\n",
    "# Convert the results to a pandas DataFrame\n",
    "trends = pd.DataFrame.from_dict(results, orient='index', columns=['trend'])\n",
    "\n",
    "# Reset the index\n",
    "trends.reset_index(inplace=True)\n",
    "\n",
    "# Split the tuple into two separate columns\n",
    "trends[['material', 'bu']] = pd.DataFrame(trends['index'].tolist(), index=trends.index)\n",
    "\n",
    "# Drop the original 'index' column\n",
    "trends.drop(columns=['index'], inplace=True)\n",
    "\n",
    "# Set the column names (optional, the column names should be correct now)\n",
    "# trends.columns = ['customer_name', 'material', 'trend']\n",
    "\n",
    "# Sort the DataFrame by customer_name and material\n",
    "trends = trends.sort_values(['material'])\n",
    "\n",
    "#pivot_to_excel\n",
    "trends.to_excel('data_files/trends_wo_customers.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with forecasting\n",
    "\n",
    "Convert the dataframe to long format\n",
    "df_long_qty = pivot_df_material_qty_no_customer.melt(id_vars=['bu', 'material'], var_name='year', value_name='qty')\n",
    "\n",
    "# Convert year to integer\n",
    "df_long_qty['year'] = df_long_qty['year'].astype(int)\n",
    "\n",
    "# Initialize a dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Group by bu and material and run a regression for each group\n",
    "for (bu, material), group in df_long_qty.groupby(['bu', 'material']):\n",
    "    # Skip this group if it only has one row\n",
    "    if len(group) <= 1:\n",
    "        continue\n",
    "    \n",
    "    group['qty'] = group['qty'].fillna(0)\n",
    "    \n",
    "    # Check if group is empty\n",
    "    if group.empty:\n",
    "        continue\n",
    "    \n",
    "    # Run the regression\n",
    "    X = group['year'].values.reshape(-1, 1)  # reshape is needed because we have only one feature\n",
    "    y = group['qty']\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Save the regression model in the results\n",
    "    results[(bu, material)] = model\n",
    "\n",
    "# Create a new dataframe for the forecast\n",
    "forecast = pd.DataFrame(columns=['bu', 'material', 'year', 'qty'])\n",
    "\n",
    "# Generate the forecast for each group\n",
    "for (bu, material), model in results.items():\n",
    "    # Get the last observed year\n",
    "    last_year = df_long_qty[(df_long_qty['bu'] == bu) & (df_long_qty['material'] == material)]['year'].max()\n",
    "    \n",
    "    # Generate the forecast for 2023 and 2024\n",
    "    forecast_year = pd.DataFrame({'year': [2023, 2024]})\n",
    "    forecast_year['bu'] = bu\n",
    "    forecast_year['material'] = material\n",
    "    \n",
    "    # Predict the values for the forecast years\n",
    "    forecast_year['qty'] = model.predict(forecast_year['year'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Append the forecast to the main dataframe\n",
    "    forecast = forecast.append(forecast_year)\n",
    "\n",
    "# Sort the forecast dataframe by bu and material\n",
    "forecast.sort_values(['bu', 'material'], inplace=True)\n",
    "\n",
    "# Reset the index of the forecast dataframe\n",
    "forecast.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#pivot_df_material_qty = pivot_df_material_qty.reset_index()\n",
    "forecast.to_excel('data_files/forecast_info.xlsx', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
