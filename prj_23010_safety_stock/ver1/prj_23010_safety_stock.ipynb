{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdcdb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read Data1.xlsx into a dataframe\n",
    "orders_data_fy17_fy21 = pd.read_excel('data_files/Data1.xlsx')\n",
    "\n",
    "# Read Data2.xlsx into a dataframe\n",
    "orders_data_fy21_fy22 = pd.read_excel('data_files/Data2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e0d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep desired columns\n",
    "temp_df = orders_data_fy17_fy21[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'order intake EUR']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df['year_month_date'] = pd.to_datetime(temp_df['year_month'], format='%Y%m')\n",
    "temp_df['FY'] = np.where(temp_df['year_month_date'].dt.month >= 4, temp_df['year_month_date'].dt.year, temp_df['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df['quarter'] = temp_df['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df['half_year'] = np.where(temp_df['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df = temp_df.rename(columns={'sold_to_customer_n_latest': 'customer', 'order intake EUR': 'order_intake_EUR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "811d69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df\n",
    "new_df.to_excel('data_files/new_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca099de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/5mz4jdsj64n5f2jltclyq9zh0000gn/T/ipykernel_46914/2938834960.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df2['year_month_date'] = pd.to_datetime(temp_df2['year_month'], format='%Y%m')\n",
      "/var/folders/k0/5mz4jdsj64n5f2jltclyq9zh0000gn/T/ipykernel_46914/2938834960.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df2['FY'] = np.where(temp_df2['year_month_date'].dt.month >= 4, temp_df2['year_month_date'].dt.year, temp_df2['year_month_date'].dt.year - 1)\n",
      "/var/folders/k0/5mz4jdsj64n5f2jltclyq9zh0000gn/T/ipykernel_46914/2938834960.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df2['quarter'] = temp_df2['year_month_date'].dt.month.map(quarter_dict)\n",
      "/var/folders/k0/5mz4jdsj64n5f2jltclyq9zh0000gn/T/ipykernel_46914/2938834960.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df2['half_year'] = np.where(temp_df2['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n"
     ]
    }
   ],
   "source": [
    "temp_df2 = orders_data_fy21_fy22[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'Order Intake Euro']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df2['year_month_date'] = pd.to_datetime(temp_df2['year_month'], format='%Y%m')\n",
    "temp_df2['FY'] = np.where(temp_df2['year_month_date'].dt.month >= 4, temp_df2['year_month_date'].dt.year, temp_df2['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df2['quarter'] = temp_df2['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df2['half_year'] = np.where(temp_df2['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df2 = temp_df2.rename(columns={'sold_to_customer_n_latest': 'customer', 'Order Intake Euro': 'order_intake_EUR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "781e2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df2\n",
    "temp_df2.to_excel('data_files/new_file2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ea3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two prepared df\n",
    "orders_data = pd.concat([temp_df, temp_df2], ignore_index=True)\n",
    "# Check sales_data\n",
    "orders_data.to_excel('data_files/orders_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e648ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns were changed to categorical data type: \n",
      "company_code_n\n",
      "bu\n",
      "bu_n\n",
      "FY\n",
      "quarter\n",
      "half_year\n"
     ]
    }
   ],
   "source": [
    "orders_data_opt = orders_data.copy()\n",
    "# Reduce the memory usage of the dataframe and improve performance\n",
    "def check_unique_values(df):\n",
    "    changed_columns = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values < 50:\n",
    "            df[col] = df[col].astype('category')\n",
    "            changed_columns.append(col)\n",
    "    if len(changed_columns) > 0:\n",
    "        print(\"The following columns were changed to categorical data type: \")\n",
    "        for col in changed_columns:\n",
    "            print(col)\n",
    "    else:\n",
    "        print(\"No columns were changed to categorical data type.\")\n",
    "        \n",
    "check_unique_values(orders_data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd33fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'ms_code' contains text with 'BOP'\n",
    "orders_data_opt['ms_code'] = orders_data_opt['ms_code'].astype(str)\n",
    "orders_data_opt = orders_data_opt[~orders_data_opt['ms_code'].str.contains('BOP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fdf0aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total amount of orders per ms_code in eur\n",
    "\n",
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_amount.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['ms_code', 'order_intake_EUR']]\n",
    "    \n",
    "    # Group by ms_code and sum order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_EUR', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1518164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total quantity of ms_codes per month\n",
    "\n",
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_quantity_per_month.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['year_month_date', 'ms_code', 'order_intake_quantity']]\n",
    "    \n",
    "    # Group by month and ms_code and sum order_intake_quantity and order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['year_month_date', 'ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_quantity', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6313e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a744e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ analysis\n",
    "\n",
    "def mean_std_from_first_nonzero(row):\n",
    "    # Find the index of the first non-zero value in the row\n",
    "    nonzero_indices = np.nonzero(row.values[1:])[0]\n",
    "    if len(nonzero_indices) > 0:\n",
    "        first_nonzero_index = nonzero_indices[0] + 1  # Add 1 to account for the fact that we started at the second column\n",
    "        mean = row.iloc[first_nonzero_index:].mean()  # Calculate the mean of the remaining values\n",
    "        std = row.iloc[first_nonzero_index:].std()  # Calculate the standard deviation of the remaining values\n",
    "        return pd.Series({'Mean': mean, 'Std': std})  # Return the mean and standard deviation as a Series\n",
    "    else:\n",
    "        return pd.Series({'Mean': 0, 'Std': 0})  # If all values are zero, return 0 for mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f69011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table for ms_code for each month with NaN values filled with 0\n",
    "pivot_table_month = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns='year_month_date', aggfunc='sum', fill_value=0) # margins=True , fill_value=0\n",
    "pivot_table_month.reset_index(inplace=True)\n",
    "# sort the pivot table by the total column in descending order\n",
    "#pivot_table_month = pivot_table_month.sort_values(by='All', ascending=False)\n",
    "\n",
    "pivot_table_half_year = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns=['FY', 'half_year'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_year.reset_index(inplace=True)\n",
    "\n",
    "pivot_table_half_quarter = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns=['FY', 'quarter'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_quarter.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Calculate the sum of the last year for different pivots\n",
    "last_12_sum = pivot_table_month.iloc[:, -12:].sum(axis=1)\n",
    "last_2_sum = pivot_table_half_year.iloc[:, -2:].sum(axis=1)\n",
    "last_4_sum = pivot_table_half_quarter.iloc[:, -4:].sum(axis=1)\n",
    "\n",
    "\n",
    "# Select the rows where the sum is greater than 0\n",
    "pivot_table_month = pivot_table_month[last_12_sum > 0]\n",
    "pivot_table_month.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year[last_2_sum > 0]\n",
    "pivot_table_half_year.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter[last_4_sum > 0]\n",
    "pivot_table_half_quarter.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# calculate mean and std deviation for each product from the first month where it was sold\n",
    "# Apply the function to each row of the dataframe, and store the results in new columns\n",
    "pivot_table_month[['Mean_from_first', 'Std_from_first']] = pivot_table_month.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_year[['Mean_from_first_hy', 'Std_from_first_hy']] = pivot_table_half_year.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_quarter[['Mean_from_first_q', 'Std_from_first_q']] = pivot_table_half_quarter.apply(mean_std_from_first_nonzero, axis=1)\n",
    "\n",
    "# calculate mean and std deviation for each product\n",
    "df_mean = pivot_table_month.iloc[:, 1:].mean(axis=1)\n",
    "df_std = pivot_table_month.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_h = pivot_table_half_year.iloc[:, 1:].mean(axis=1)\n",
    "df_std_h = pivot_table_half_year.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_q = pivot_table_half_quarter.iloc[:, 1:].mean(axis=1)\n",
    "df_std_q = pivot_table_half_quarter.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "# categorize products based on std deviation\n",
    "df_category = pd.cut(df_std, bins=[-float('inf'), 0.5*pivot_table_month['Mean_from_first'].mean(), pivot_table_month['Mean_from_first'].mean(), float('inf')], labels=['Z', 'Y', 'X'])\n",
    "df_category_h = pd.cut(df_std_h, bins=[-float('inf'), 0.5*pivot_table_half_year['Mean_from_first_hy'].mean(), pivot_table_half_year['Mean_from_first_hy'].mean(), float('inf')], labels=['ZH', 'YH', 'XH'])\n",
    "df_category_q = pd.cut(df_std_q, bins=[-float('inf'), 0.5*pivot_table_half_quarter['Mean_from_first_q'].mean(), pivot_table_half_quarter['Mean_from_first_q'].mean(), float('inf')], labels=['ZQ', 'YQ', 'XQ'])\n",
    "\n",
    "# add new columns to the original dataframe\n",
    "pivot_table_month = pivot_table_month.assign(Mean=df_mean, Std=df_std, Category=df_category)\n",
    "pivot_table_month = pivot_table_month.loc[:,['ms_code','Mean_from_first', 'Std_from_first', 'Mean', 'Std', 'Category']]\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year.assign(Mean_hy=df_mean_h, Std_hy=df_std_h, Category_hy=df_category_h)\n",
    "pivot_table_half_year = pivot_table_half_year.loc[:,['ms_code','Mean_from_first_hy', 'Std_from_first_hy', 'Mean_hy', 'Std_hy', 'Category_hy']]\n",
    "pivot_table_half_year = pivot_table_half_year.reset_index(level=0, drop=True)\n",
    "pivot_table_half_year.columns = pivot_table_half_year.columns.get_level_values(0)\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.assign(Mean_q=df_mean_q, Std_q=df_std_q, Category_q=df_category_q)\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.loc[:,['ms_code','Mean_from_first_q', 'Std_from_first_q', 'Mean_q', 'Std_q', 'Category_q']]\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.reset_index(level=0, drop=True)\n",
    "pivot_table_half_quarter.columns = pivot_table_half_quarter.columns.get_level_values(0)\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/order_data_XYZ.xlsx', engine='xlsxwriter')\n",
    "pivot_table_month.to_excel(writer, sheet_name='month')\n",
    "pivot_table_half_year.to_excel(writer, sheet_name='half year')\n",
    "pivot_table_half_quarter.to_excel(writer, sheet_name='quarter')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4851f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing information\n",
    "priced = pd.read_excel('data_files/priced_positions.xlsx')\n",
    "priced = priced.loc[:,['Model', 'COGS', 'Chk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d35591",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_opt_with_price = pd.merge(orders_data_opt, priced, left_on='ms_code', right_on='Model', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7037b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/test.xlsx', engine='xlsxwriter')\n",
    "orders_data_opt_with_price.to_excel(writer, sheet_name='month')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6effc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_opt = orders_data_opt_with_price.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1251632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC + XYZ analysis per bu\n",
    "\n",
    "# Create a new Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/order_data_ABC_XYZ_per_bu.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Get a list of the unique 'bu' values\n",
    "bu_values = sorted(orders_data_opt['bu'].unique())\n",
    "\n",
    "# Loop over each 'bu' value\n",
    "for bu in bu_values:\n",
    "\n",
    "    # Filter the data for the current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu]\n",
    "    \n",
    "    # prices \n",
    "    \n",
    "    indexed_df = bu_df.set_index('ms_code')\n",
    "    ms_code_price = indexed_df['COGS'].to_dict()\n",
    "    ms_code_priced = pd.Series(ms_code_price)\n",
    "    \n",
    "    indexed_df_status = bu_df.set_index('ms_code')\n",
    "    ms_code_status = indexed_df['Chk'].to_dict()\n",
    "    ms_code_statused = pd.Series(ms_code_status)\n",
    "\n",
    "    # Group by 'ms_code' and calculate the total 'order_intake_EUR'\n",
    "    total_eur = bu_df.groupby('ms_code')['order_intake_EUR'].sum()\n",
    "    total_quant = bu_df.groupby('ms_code')['order_intake_quantity'].sum()\n",
    "\n",
    "    # Calculate the share of 'order_intake_EUR' for each 'ms_code'\n",
    "    eur_share = total_eur / total_eur.sum()\n",
    "\n",
    "    # Sort the 'ms_code' by descending 'order_intake_EUR'\n",
    "    sorted_ms = total_eur.sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted 'order_intake_EUR'\n",
    "    cumulative_sum = sorted_ms.cumsum()\n",
    "\n",
    "    # Calculate the percentage of the cumulative sum\n",
    "    cumulative_percent = cumulative_sum / total_eur.sum() * 100\n",
    "\n",
    "    # Categorize the 'ms_code' into ABC groups based on the cumulative percentage\n",
    "    abc_group = pd.cut(cumulative_percent, bins=[0, 70, 90, 100], labels=['A', 'B', 'C'])\n",
    "\n",
    "    # Create a new dataframe with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Total_EUR': total_eur,\n",
    "        'Share': eur_share,\n",
    "        'Cumulative_Sum_EUR': cumulative_sum,\n",
    "        'Cumulative_Percent': cumulative_percent,\n",
    "        'ABC_Group': abc_group,\n",
    "        'Quantity': total_quant,\n",
    "        'COGS': ms_code_priced,\n",
    "        'Status': ms_code_statused\n",
    "    })\n",
    "    \n",
    "\n",
    "    # Write the results to a new sheet in the Excel file\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df = results_df.rename(columns={'index': 'ms_code'})\n",
    "    results_df = results_df.merge(pivot_table_month[['ms_code', 'Mean_from_first', 'Std_from_first', 'Category']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df= results_df.merge(pivot_table_half_quarter[['ms_code', 'Mean_from_first_q', 'Std_from_first_q', 'Category_q']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df = results_df.merge(pivot_table_half_year[['ms_code', 'Mean_from_first_hy', 'Std_from_first_hy', 'Category_hy']],\n",
    "                       on='ms_code', how='left')\n",
    "    \n",
    "    abc_xyz = results_df.loc[:,['ms_code', 'Total_EUR', 'ABC_Group',  'Category', 'Quantity', 'Mean_from_first',\n",
    "       'Category_q', 'Mean_from_first_q', 'Category_hy', 'Mean_from_first_hy', 'COGS', 'Status']]\n",
    "    \n",
    "    abc_xyz = abc_xyz.rename(columns={\n",
    "        'ms_code': 'Model',\n",
    "        'Mean_from_first': 'Mean',\n",
    "        'Category': 'Category_XYZ',\n",
    "        'Mean_from_first_q': 'Mean_Q',\n",
    "        'Category_q': 'Category_XYZ_Q',\n",
    "        'Mean_from_first_hy': 'Mean_HY',\n",
    "        'Category_hy': 'Category_XYZ_HY'})\n",
    "    \n",
    "    abc_xyz['Quantity'] = abc_xyz['Quantity'].round(0)\n",
    "    abc_xyz['Mean'] = abc_xyz['Mean'].round(0)\n",
    "    abc_xyz['Mean_Q'] = abc_xyz['Mean_Q'].round(0)\n",
    "    abc_xyz['Mean_HY'] = abc_xyz['Mean_HY'].round(0)\n",
    "    \n",
    "    abc_xyz = abc_xyz.sort_values(by=['ABC_Group', 'Category_XYZ', 'Total_EUR', 'Quantity'], ascending=[True, False, False, False])\n",
    "    \n",
    "    abc_xyz['sum'] = 0  # initialize 'sum' column to 0\n",
    "    mask = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ'] == 'X')  # create a boolean mask for the rows to multiply\n",
    "    mask2 = (abc_xyz['Status'] == 1)\n",
    "    abc_xyz.loc[mask2, 'COGS'] = ((abc_xyz.loc[mask2, 'Total_EUR'])* 0.7 / abc_xyz.loc[mask2, 'Quantity'])\n",
    "\n",
    "    abc_xyz.loc[mask, 'sum'] = abc_xyz.loc[mask, 'COGS'] * abc_xyz.loc[mask, 'Mean']  # multiply the selected rows and assign to 'sum' column\n",
    "\n",
    "    abc_xyz.to_excel(writer, sheet_name=bu)\n",
    "\n",
    "# Save and close the Excel writer object\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5eb83cc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(0    False\n2    False\n3    False\n1     True\nName: Status, dtype: bool, 'Total_EUR')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(0    False\n2    False\n3    False\n1     True\nName: Status, dtype: bool, 'Total_EUR')' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mabc_xyz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal_EUR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3628\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3629\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3631\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5635\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5636\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (0    False\n2    False\n3    False\n1     True\nName: Status, dtype: bool, 'Total_EUR')"
     ]
    }
   ],
   "source": [
    "abc_xyz[mask2, 'Total_EUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb71edc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EG21RPO01           0.0\n",
       "RPOMM600-S11-D12    1.0\n",
       "UP4RPLY             0.0\n",
       "UP4RPLYOF           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_code_statused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4080ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month</th>\n",
       "      <th>company_code_n</th>\n",
       "      <th>customer</th>\n",
       "      <th>bu</th>\n",
       "      <th>bu_n</th>\n",
       "      <th>material</th>\n",
       "      <th>ms_code</th>\n",
       "      <th>order_intake_quantity</th>\n",
       "      <th>order_intake_EUR</th>\n",
       "      <th>year_month_date</th>\n",
       "      <th>FY</th>\n",
       "      <th>quarter</th>\n",
       "      <th>half_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201704</td>\n",
       "      <td>YEF-A</td>\n",
       "      <td>STSI Integrated technical services Ltd</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.509000e+06</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q1</td>\n",
       "      <td>HY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201704</td>\n",
       "      <td>YEF-E</td>\n",
       "      <td>CEPSA-COMPANIA ESPANOLA DE PETROLEO</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.454010e+05</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q1</td>\n",
       "      <td>HY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201704</td>\n",
       "      <td>YEF-G</td>\n",
       "      <td>Framatome GmbH</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.499617e+05</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q1</td>\n",
       "      <td>HY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201704</td>\n",
       "      <td>YEF-NL</td>\n",
       "      <td>GLT-PLUS V.O.F.</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.488083e+05</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q1</td>\n",
       "      <td>HY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201704</td>\n",
       "      <td>YEF-GB</td>\n",
       "      <td>British Pipeline Agency Ltd</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.040634e+05</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q1</td>\n",
       "      <td>HY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530631</th>\n",
       "      <td>202212</td>\n",
       "      <td>YEF-GB</td>\n",
       "      <td>National Grid</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.755482e+05</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q3</td>\n",
       "      <td>HY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530632</th>\n",
       "      <td>202303</td>\n",
       "      <td>YEF-E</td>\n",
       "      <td>UTE TR Minatitlan</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9.672987e+05</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q4</td>\n",
       "      <td>HY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530633</th>\n",
       "      <td>202303</td>\n",
       "      <td>YEF-I</td>\n",
       "      <td>SAIPEM SPA BRANCH MOSCOW</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.333130e+06</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q4</td>\n",
       "      <td>HY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530634</th>\n",
       "      <td>202303</td>\n",
       "      <td>YEF-E</td>\n",
       "      <td>UTE TR Minatitlan</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.609083e+06</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q4</td>\n",
       "      <td>HY2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530635</th>\n",
       "      <td>202301</td>\n",
       "      <td>YEF-NL</td>\n",
       "      <td>GYGAZ SNC</td>\n",
       "      <td>YY1X7</td>\n",
       "      <td>for Lump sum Order</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>ENT00000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.400000e+06</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q4</td>\n",
       "      <td>HY2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468225 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_month company_code_n                                customer  \\\n",
       "0           201704          YEF-A  STSI Integrated technical services Ltd   \n",
       "1           201704          YEF-E     CEPSA-COMPANIA ESPANOLA DE PETROLEO   \n",
       "2           201704          YEF-G                          Framatome GmbH   \n",
       "3           201704         YEF-NL                         GLT-PLUS V.O.F.   \n",
       "4           201704         YEF-GB             British Pipeline Agency Ltd   \n",
       "...            ...            ...                                     ...   \n",
       "530631      202212         YEF-GB                           National Grid   \n",
       "530632      202303          YEF-E                       UTE TR Minatitlan   \n",
       "530633      202303          YEF-I                SAIPEM SPA BRANCH MOSCOW   \n",
       "530634      202303          YEF-E                       UTE TR Minatitlan   \n",
       "530635      202301         YEF-NL                               GYGAZ SNC   \n",
       "\n",
       "           bu                bu_n     material      ms_code  \\\n",
       "0       YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "1       YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "2       YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "3       YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "4       YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "...       ...                 ...          ...          ...   \n",
       "530631  YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "530632  YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "530633  YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "530634  YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "530635  YY1X7  for Lump sum Order  ENT00000001  ENT00000001   \n",
       "\n",
       "        order_intake_quantity  order_intake_EUR year_month_date    FY quarter  \\\n",
       "0                         1.0      1.509000e+06      2017-04-01  2017      Q1   \n",
       "1                         1.0      7.454010e+05      2017-04-01  2017      Q1   \n",
       "2                         1.0      6.499617e+05      2017-04-01  2017      Q1   \n",
       "3                         0.0      5.488083e+05      2017-04-01  2017      Q1   \n",
       "4                         0.0      4.040634e+05      2017-04-01  2017      Q1   \n",
       "...                       ...               ...             ...   ...     ...   \n",
       "530631                    0.0     -6.755482e+05      2022-12-01  2022      Q3   \n",
       "530632                    1.0     -9.672987e+05      2023-03-01  2022      Q4   \n",
       "530633                    0.0     -2.333130e+06      2023-03-01  2022      Q4   \n",
       "530634                    1.0     -2.609083e+06      2023-03-01  2022      Q4   \n",
       "530635                    0.0     -3.400000e+06      2023-01-01  2022      Q4   \n",
       "\n",
       "       half_year  \n",
       "0            HY1  \n",
       "1            HY1  \n",
       "2            HY1  \n",
       "3            HY1  \n",
       "4            HY1  \n",
       "...          ...  \n",
       "530631       HY2  \n",
       "530632       HY2  \n",
       "530633       HY2  \n",
       "530634       HY2  \n",
       "530635       HY2  \n",
       "\n",
       "[468225 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6460d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "priced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
