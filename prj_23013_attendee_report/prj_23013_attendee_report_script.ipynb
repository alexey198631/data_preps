{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e7165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis Python application is designed to extract data from a CSV file and create separate pandas DataFrames \\nfor specific rows that contain key words such as 'Host Details', 'Panelist Details', and 'Attendee Details'. \\nThe program reads the CSV file row by row and detects the target rows containing the key words using a flag variable. \\nWhen a target row is found, the program creates a new DataFrame and appends the subsequent rows to it until the next \\ntarget row is found. Once all the target rows have been processed, the program returns a list of \\nDataFrames containing the data from the CSV file that corresponds to each of the target rows. This application \\ncan be useful for data processing and analysis tasks that require separate DataFrames for different types of data, \\nsuch as attendance reports or meeting logs.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This Python application is designed to extract data from a CSV file and create separate pandas DataFrames \n",
    "for specific rows that contain key words such as 'Host Details', 'Panelist Details', and 'Attendee Details'. \n",
    "The program reads the CSV file row by row and detects the target rows containing the key words using a flag variable. \n",
    "When a target row is found, the program creates a new DataFrame and appends the subsequent rows to it until the next \n",
    "target row is found. Once all the target rows have been processed, the program returns a list of \n",
    "DataFrames containing the data from the CSV file that corresponds to each of the target rows. This application \n",
    "can be useful for data processing and analysis tasks that require separate DataFrames for different types of data, \n",
    "such as attendance reports or meeting logs.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c50e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "key_words = ['Report Generated:', 'Host Details', 'Panelist Details', 'Attendee Details']\n",
    "df_names = [x.replace(' ', '_').lower() for x in key_words]\n",
    "\n",
    "# Set the path to the folder containing the CSV files\n",
    "folder_path = 'data_files/csv/'\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c11a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_data_list(file_path, key_words):\n",
    "    \n",
    "    all_rows = []\n",
    "    key_words = key_words.copy()\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "\n",
    "        # Read the CSV file row by row and process each row data\n",
    "        for row in csvreader:\n",
    "            all_rows.append(row)\n",
    "\n",
    "    key_indexes = []\n",
    "    for k in key_words:\n",
    "        for i, row in enumerate(all_rows):\n",
    "            if k in row:\n",
    "                key_indexes.append(i)\n",
    "                \n",
    "    var_names = [x.replace(' ', '_').lower() for x in key_words]\n",
    "    \n",
    "    # Create an empty dictionary to store the variables\n",
    "    section_data_list = {}\n",
    "    \n",
    "    for i in range(len(var_names)):\n",
    "        # Get the start and end indices for the current variable\n",
    "        start = key_indexes[i]\n",
    "        end = key_indexes[i+1] if i < len(var_names)-1 else None\n",
    "\n",
    "        section_data_list[var_names[i]] = all_rows[start:end]\n",
    "    \n",
    "    return section_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76bee638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_section_data(key, section_data_list):\n",
    "    \n",
    "    data = section_data_list[key]\n",
    "    \n",
    "    # Create an empty list to store the rows after the target row\n",
    "    length_of_row = []\n",
    "    \n",
    "    for row in data[1:]:\n",
    "        length_of_row.append(len(row))\n",
    "\n",
    "    # Identify the minimum value from the list of lenght of rows\n",
    "    min_value = min(length_of_row)\n",
    "    \n",
    "    data_m = data[1:]\n",
    "\n",
    "    for i, row in enumerate(data_m):\n",
    "        if len(row) > min_value:\n",
    "            data_m[i] = row[:-1]\n",
    "        else:\n",
    "            data_m[i] = row\n",
    "\n",
    "    # Create a pandas DataFrame from the list of rows after the target row\n",
    "    df = pd.DataFrame(data_m[1:], columns=data_m[0])\n",
    "    df.name = key\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6481c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of file paths by concatenating the folder path with each CSV file name\n",
    "list_of_file_paths = [folder_path + x for x in csv_files]\n",
    "\n",
    "# Loop through each file path in the list\n",
    "for file_path in list_of_file_paths:\n",
    "    # Call a function to extract data from sections in the file that contain certain key words\n",
    "    # The function returns a list of dictionaries containing the extracted data\n",
    "    section_data_list = section_data_list(file_path, key_words)\n",
    "    # Create an empty list to store the extracted dataframes\n",
    "    dfs_ = []\n",
    "    for key in df_names:\n",
    "        # Call a function to extract a specific dataframe from the section data list\n",
    "        # The function returns the extracted dataframe\n",
    "        dfs_.append(extract_section_data(key, section_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01de3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The following code deals with data that contains information about participants of a webinar. \n",
    "Some participants have connected multiple times for various reasons, resulting in multiple entries for the same person.\n",
    "The goal is to remove all duplicate values while preserving the actual time elapsed from the first login to \n",
    "the last logout of the webinar.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51385d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def right_format(df):\n",
    "    # change format of columns\n",
    "    df['Time in Session (minutes)'] = pd.to_numeric(df['Time in Session (minutes)'], errors='coerce')\n",
    "    df['Join Time'] = pd.to_datetime(df['Join Time'], errors='coerce').dt.time\n",
    "    df['Leave Time'] = pd.to_datetime(df['Leave Time'], errors='coerce').dt.time\n",
    "\n",
    "    # replace '--' values with None\n",
    "    df = df.replace('--', None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4212aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_unique_email(df, value):\n",
    "    \n",
    "    key_df = df[df['Email'] == value]\n",
    "    \n",
    "    time1 = key_df['Join Time'].iloc[0]\n",
    "    time2 = key_df['Leave Time'].iloc[-1]\n",
    "    key_df['Leave Time'].iloc[0] = time2\n",
    "        \n",
    "    # get difference between time1 and time2 in minutes\n",
    "    diff = (datetime.datetime.combine(datetime.date.today(), time2) - datetime.datetime.combine(datetime.date.today(), time1)).total_seconds() / 60   \n",
    "    key_df['Time in Session (minutes)'].iloc[0] = diff\n",
    "    key_df = key_df.drop_duplicates(subset='Email', keep='first')\n",
    "    \n",
    "    return key_df\n",
    "\n",
    "\"\"\"\n",
    "The following function is designed to substitute verified contact information from a table into a webinar participant's \n",
    "details if they have attended previous webinars. If the participant has not attended before, the function saves \n",
    "their details to a separate file along with the information they entered.\n",
    "\n",
    "\"\"\"\n",
    "def old_and_new_contacts(df):\n",
    "    column_list = list(df.columns)\n",
    "    contacts_df = pd.read_excel('data_files/data_base.xlsx', sheet_name='webinar_invitees', header=3)\n",
    "    df['Email'] = df['Email'].str.strip().str.lower()  \n",
    "    new_contacts_df = df[~df['Email'].isin(contacts_df['Email'])]\n",
    "    #& (~df['Last Name'].isin(contacts_df['last_name']))\n",
    "    old_contacts_df = df[df['Email'].isin(contacts_df['Email'])]\n",
    "    \n",
    "    print('check point', len(df), '=',  len(new_contacts_df), '+', len(old_contacts_df))\n",
    "    \n",
    "    old_contacts_df = old_contacts_df.drop(['User Name (Original Name)', 'First Name', 'Last Name', 'Organization'], axis=1)\n",
    "    \n",
    "    merged_df = pd.merge(old_contacts_df, contacts_df, on='Email', how='left')\n",
    "    \n",
    "    merged_df = merged_df.rename(columns={'company_name': 'Organization', 'person': 'User Name (Original Name)', 'first_name': 'First Name',\n",
    "       'last_name': 'Last Name'})\n",
    "\n",
    "    old_contacts_df = merged_df.loc[:, column_list]\n",
    "    \n",
    "    old_and_new_contacts = pd.concat([old_contacts_df, new_contacts_df])\n",
    "    \n",
    "    new_contacts_df = new_contacts_df.loc[:,['User Name (Original Name)', 'First Name', 'Last Name', 'Email', 'Organization']]\n",
    "    new_contacts_df = new_contacts_df.rename(columns={'Organization': 'company_name', 'User Name (Original Name)': 'person', 'First Name': 'first_name',\n",
    "       'Last Name': 'last_name'})\n",
    "    new_contacts_df['company_name'] = new_contacts_df['company_name'].str.upper().str.strip()\n",
    "    new_contacts_df['person'] = new_contacts_df['person'].apply(lambda x: x.title())\n",
    "    new_contacts_df['first_name'] = new_contacts_df['first_name'].str.strip().str.title()\n",
    "    new_contacts_df['last_name'] = new_contacts_df['last_name'].str.strip().str.title()\n",
    "    \n",
    "    new_contacts_df = new_contacts_df.reindex(columns=['Email', 'company_name', 'person', 'first_name', 'last_name'])\n",
    "    new_contacts_df.reset_index(inplace=True, drop=True )\n",
    "    \n",
    "    writer = pd.ExcelWriter('data_files/new_contacts_df.xlsx')\n",
    "    new_contacts_df.to_excel(writer, sheet_name='new')\n",
    "    writer.save()\n",
    "    \n",
    "    return old_and_new_contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "837ea2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51b4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Leave Time'].iloc[0] = time2\n",
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Time in Session (minutes)'].iloc[0] = diff\n",
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Leave Time'].iloc[0] = time2\n",
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Time in Session (minutes)'].iloc[0] = diff\n",
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Leave Time'].iloc[0] = time2\n",
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  key_df['Time in Session (minutes)'].iloc[0] = diff\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check point 65 = 4 + 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\30050122\\AppData\\Local\\Temp\\ipykernel_8252\\3505255171.py:56: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code snippet prepares data to be added to a report file in the format and columns that match the information \n",
    "in the original report file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hosts  = []\n",
    "panelists = []\n",
    "\n",
    "for df in dfs:\n",
    "    if df.name == 'host_details':\n",
    "        hosts = hosts + list(df['Email'].unique())\n",
    "    elif df.name == 'panelist_details':\n",
    "        hosts = hosts + list(df['Email'].unique())\n",
    "        panelists = panelists + list(df['User Name (Original Name)'].unique())\n",
    "    elif df.name == 'report_generated:':\n",
    "        df['Topic'] = df['Topic'].str.replace('\"', '').str.strip()\n",
    "        webinar_name = df['Topic'].iloc[0]\n",
    "        webinar_duration = df['Actual Duration (minutes)'].iloc[0]\n",
    "        df['Actual Start Time'] = pd.to_datetime(df['Actual Start Time'])\n",
    "        df['Date'] = df['Actual Start Time'].dt.strftime('%d-%m-%Y')\n",
    "        webinar_date = df['Date'].iloc[0]\n",
    "        \n",
    "        \n",
    "for i, df in enumerate(dfs):  \n",
    "    if df.name == 'report_generated:':\n",
    "        #df['Topic'] = df['Topic'].str.replace('\"', '').str.strip()\n",
    "        #webinar_name = df['Topic'].iloc[0]\n",
    "        df['Name in Teams'] = webinar_name\n",
    "        df['Panelists'] = ', '.join(panelists)\n",
    "        df['Actual Start Time'] = pd.to_datetime(df['Actual Start Time'])\n",
    "        df['Date'] = df['Actual Start Time'].dt.strftime('%d-%m-%Y')\n",
    "        df = df.reindex(columns=['Name in Teams', 'Panelists', 'Date', 'Topic', 'Actual Duration (minutes)',\n",
    "       '# Registered', '# Cancelled', 'Unique Viewers', 'Total Users',\n",
    "       'Max Concurrent Views', 'Actual Start Time', 'Webinar ID'])\n",
    "        dfs[i] = df\n",
    "        dfs[i].name = 'webinar_list'\n",
    "    elif df.name == 'panelist_details':\n",
    "        dfs[i-1]['Host/Panelist'] = 'H'\n",
    "        dfs[i]['Host/Panelist'] = 'P'\n",
    "        dfs[i] = pd.concat([df, dfs[i-1]])\n",
    "        dfs[i] = dfs[i].reindex(columns = ['User Name (Original Name)', 'Email', 'Host/Panelist', 'Time in Session (minutes)','Join Time','Leave Time'])\n",
    "        dfs[i].name = 'panelist_details'\n",
    "    elif df.name == 'attendee_details':\n",
    "        dfs[i] = right_format(df)\n",
    "        # get the emails that appear more than once\n",
    "        counts = df['Email'].value_counts()\n",
    "        emails = counts[counts > 1].index.tolist()\n",
    "        # filter out the rows that contain the exclude emails\n",
    "        df_filtered = df[~df['Email'].isin(emails)]\n",
    "        df_duplicated = df[df['Email'].isin(emails)]\n",
    "        for email in emails:\n",
    "            prep_df = keep_unique_email(df_duplicated, email)\n",
    "            df_filtered = pd.concat([df_filtered, prep_df])\n",
    "        df_filtered['Webinar'] = webinar_name\n",
    "        df_filtered['Date'] = webinar_date    \n",
    "        df_filtered['Duration'] = webinar_duration\n",
    "        df_filtered['Time in Session (minutes)'] = df_filtered['Time in Session (minutes)'].astype(float)\n",
    "        df_filtered['Duration'] = df_filtered['Duration'].astype(float)\n",
    "        df_filtered['Rate'] = (df_filtered['Time in Session (minutes)'] / df_filtered['Duration'])\n",
    "        df_filtered['Rate'] = df_filtered['Rate'].round(2)\n",
    "        df_filtered = df_filtered.reindex(columns=['Webinar', 'Date', 'Attended', 'User Name (Original Name)', 'First Name', 'Last Name',\n",
    "       'Email', 'Organization', 'Registration Time', 'Approval Status',\n",
    "       'Join Time', 'Leave Time', 'Time in Session (minutes)',\n",
    "       'Country/Region Name', 'Duration', 'Rate'])\n",
    "        # delete hosts from participants if they were in for any reasons\n",
    "        df_filtered = df_filtered[~df_filtered['Email'].isin(hosts)]\n",
    "        df_filtered = old_and_new_contacts(df_filtered)\n",
    "        dfs[i] = df_filtered\n",
    "        dfs[i].name = 'attendee_details'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d9c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webinar_list done\n",
      "panelist_details done\n",
      "attendee_details done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "saving all the new data to the report file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Prepare data frame for Excel workbook sheet\n",
    "def df_from_sheet(wkb, sht_name):\n",
    "    # Select the sheet you want to modify\n",
    "    sheet = wkb[sht_name]\n",
    "\n",
    "    # Save data frame from sheet data\n",
    "    data_days = sheet.values\n",
    "    cols = next(data_days)[0:]\n",
    "    df = pd.DataFrame(data_days, columns=cols)\n",
    "    return df\n",
    "\n",
    "# Write the updated DataFrame to the worksheet with the same format\n",
    "def same_format_sheet(wkb, sht_name, df, file_name):\n",
    "    sht = wkb[sht_name]\n",
    "    # Create a new worksheet with the same formatting as the existing worksheet\n",
    "    new_worksheet = wkb.create_sheet('Temp')\n",
    "    new_worksheet.sheet_format = sht.sheet_format\n",
    "    new_worksheet.sheet_properties = sht.sheet_properties\n",
    "    new_worksheet.page_setup = sht.page_setup\n",
    "\n",
    "    # Write the updated DataFrame to the worksheet\n",
    "    for r in dataframe_to_rows(df, index=False, header=True):\n",
    "        new_worksheet.append(r)\n",
    "\n",
    "    # Delete all existing rows in the worksheet\n",
    "    sht.delete_rows(1, sht.max_row)\n",
    "    for row in new_worksheet.iter_rows():\n",
    "        sht.append([cell.value for cell in row])\n",
    "\n",
    "    # Delete the temporary worksheet\n",
    "    wkb.remove(new_worksheet)\n",
    "\n",
    "    # Save the changes to the Excel file\n",
    "    wkb.save(file_name)\n",
    "\n",
    "    # Close the workbook\n",
    "    wkb.close()\n",
    "    \n",
    "# Create Data Frame from Excel file\n",
    "def report_data_df(report_file, df):\n",
    "    \n",
    "    key = df.name\n",
    "    new_df = df.copy()\n",
    "\n",
    "    # Load the Reprt xlsx workbook\n",
    "    workbook = openpyxl.load_workbook(report_file)\n",
    "    df_sheets = df_from_sheet(workbook, key)\n",
    "    try:\n",
    "        df_sheets['Date'] = pd.to_datetime(df_sheets['Date'], format='%d/%m/%Y')\n",
    "        df_sheets = df_sheets.dropna(how='all')\n",
    "    except:\n",
    "        df_sheets = df_sheets.dropna(how='all')\n",
    "\n",
    "    # Save columns to a list\n",
    "    cols = list(df_sheets.columns)\n",
    "\n",
    "    # Loop over each column and convert it to the desired data type\n",
    "    for col in new_df.columns:\n",
    "        # Check if the data type of the column is a string ('object')\n",
    "        col_dtype = df_sheets[col].dtype\n",
    "        # Convert the column to dtype of original dataframe\n",
    "        if col_dtype == 'datetime64[ns]':\n",
    "            new_df[col] = pd.to_datetime(new_df[col], format='%d-%m-%Y')\n",
    "        elif col_dtype == 'float':\n",
    "            # Apply the transformation to the entire column\n",
    "            #new_df[col] = new_df[col].apply(lambda x: float(x.replace(',', '.')))\n",
    "            new_df[col] = new_df[col].astype(col_dtype)\n",
    "        else:\n",
    "            new_df[col] = new_df[col].astype(col_dtype)\n",
    "    df_to_write = pd.concat([df_sheets, new_df], ignore_index=True)\n",
    "    same_format_sheet(workbook, key, df_to_write, report_file)\n",
    "    print(key, 'done')\n",
    "    \n",
    "report_file = 'data_files/report.xlsx'\n",
    "\n",
    "for df in dfs:\n",
    "    try:\n",
    "        report_data_df(report_file, df)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d513c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
