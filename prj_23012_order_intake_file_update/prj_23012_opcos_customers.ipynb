{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeee008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import importlib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "# keeping company information in additional file\n",
    "import data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "47573e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining products groups \n",
    "control = data_file.control\n",
    "transmitters = data_file.transmitters\n",
    "flowmeters = data_file.flowmeters\n",
    "gc = data_file.gc\n",
    "analytical = data_file.analytical\n",
    "asi = data_file.asi\n",
    "other_prj_product = data_file.other_prj_product\n",
    "\n",
    "all_groups = control + transmitters + flowmeters + gc + analytical + asi + other_prj_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "1724dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to combine values in bu\n",
    "def combine_values(x):\n",
    "    if x in control:\n",
    "        return f'Control {control}'\n",
    "    elif x in transmitters:\n",
    "        return f'Transmitters {transmitters}'\n",
    "    elif x in flowmeters:\n",
    "        return f'Flowmeters {flowmeters}'\n",
    "    elif x in gc:\n",
    "        return f'GC {gc}'\n",
    "    elif x in analytical:\n",
    "        return f'Analytical Products {analytical}'\n",
    "    elif x in asi:\n",
    "        return f'ASI {asi}'\n",
    "    elif x in other_prj_product:\n",
    "        return f'Other prj products {other_prj_product}'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply the function to create a new column with combined values\n",
    "#df['Business Unit'] = df['bu'].apply(combine_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8e12547",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_copy = df_orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "645fc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_customers = save_copy[['company_code_n','ec_eu_customer', 'ec_eu_customer_n', 'ec_eu_country_n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "88304611",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_customers['ec_eu_customer'] = end_customers['ec_eu_customer'].astype(str)\n",
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "all_cust = df_customers['sold_to_customer'].to_list()\n",
    "\n",
    "end_customers = end_customers[~end_customers['ec_eu_customer'].isin(all_cust)]\n",
    "\n",
    "end_customers = end_customers.drop_duplicates()\n",
    "\n",
    "# Save to Excel\n",
    "end_customers.to_excel('data_files/outcome/output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2c11b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = save_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "280f679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('data_files/order_data.db')\n",
    "query = \"SELECT * FROM orders\"\n",
    "df_orders = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "sum_before = df_orders.order_intake_amount_eur.sum()\n",
    "df_orders = df_orders[df_orders['order_intake_amount_eur'] != 0]\n",
    "sum_after = df_orders.order_intake_amount_eur.sum()\n",
    "\n",
    "check = sum_after - sum_before\n",
    "print(round(check, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6008ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning of industry information\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == '(NOT USE) POWER : HYDRO', 'eu_industry_segment_n_latest'] = 'RENEWABLE ENERGY : HYDRO'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'RENEWABLE POWER: SOLAR, WIND, HYDRO, WTE, BIOMASS AND OTHERS', 'eu_industry_segment_n_latest'] = 'RENEWABLE ENERGY: SOLAR, WIND, HYDRO, WTE, BIOMASS AND OTHERS'\n",
    "\n",
    "\n",
    "# Create a new column based on the 'industry' column\n",
    "df_orders['ec_eu_industry_n'] = df_orders['ec_eu_industry_n'].str.upper()\n",
    "df_orders['eu_industry_segment_n_latest'] = df_orders['eu_industry_segment_n_latest'].str.upper()\n",
    "df_orders['eu_industry_segment_n_latest'] = df_orders['eu_industry_segment_n_latest'].str.replace('：',':')\n",
    "\n",
    "# Create the 'industry' column using numpy.where\n",
    "df_orders['industry'] = np.where( df_orders['eu_industry_segment_n_latest'].str.contains(':'),\n",
    "                                  df_orders['eu_industry_segment_n_latest'].str.split(':').str[0].str.strip(),\n",
    "                                  df_orders['ec_eu_industry_n'])\n",
    "\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'PULP & PAPER', 'industry'] = 'PULP & PAPER'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'MINING (EXCEPT OIL AND GAS)', 'industry'] = 'METALS, MINING AND MINERALS PROCESSING'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'NON-FERROUS METAL MANUFACTURING', 'industry'] = 'METALS, MINING AND MINERALS PROCESSING'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'NONFERROUS METAL (EXCEPT ALUMINUM) PRODUCTION AND PROCESSING', 'industry'] = 'METALS, MINING AND MINERALS PROCESSING'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'FABRICATED METAL PRODUCT MANUFACTURING', 'industry'] = 'METALS, MINING AND MINERALS PROCESSING'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'ALUMINA AND ALUMINUM PRODUCTION AND PROCESSING', 'industry'] = 'METALS, MINING AND MINERALS PROCESSING'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'PHARMACEUTICAL', 'industry'] = 'PHARMACEUTICAL'\n",
    "df_orders.loc[df_orders['eu_industry_segment_n_latest'] == 'MEDICAL EQUIPMENT AND SUPPLIES MANUFACTURING', 'industry'] = 'PHARMACEUTICAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "2d9d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = df_orders[['company_code_n', 'FY', 'bu2', 'sales_order_so', 'sold_to_customer', 'ec_eu_customer_n', 'industry','order_intake_amount_eur']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "973ad2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = sqlite3.connect('data_files/customer_data.db')\n",
    "query = \"SELECT * FROM customers\" \n",
    "df_customers = pd.read_sql_query(query, conn2)\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers  = df_customers[['sold_to_customer', 'customer_name', 'type', 'tier_new', 'countries']]\n",
    "df_customers.columns  = ['sold_to_customer', 'customer_name', 'type', 'business type', 'Country']\n",
    "\n",
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "df_orders['sold_to_customer'] = df_orders['sold_to_customer'].astype(str)\n",
    "merged_with_types = df_orders.merge(df_customers, on='sold_to_customer', how='left')\n",
    "\n",
    "print(len(merged_with_types))\n",
    "\n",
    "merged_with_types['business type'] = merged_with_types['business type'].fillna('Direct')\n",
    "\n",
    "merged_with_types['FY'] = pd.to_datetime(merged_with_types['FY'])\n",
    "\n",
    "merged_with_types['year'] = merged_with_types['FY'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "356d96b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numeric\n",
    "years = list(range(2018, 2023))\n",
    "period_of_analysis = len(years)\n",
    "\n",
    "def determine_trend(row):\n",
    "    values = row[years].values.astype(float)  # Ensure values are floats\n",
    "    slope, _ = np.polyfit(years, values, 1)  # linear fit (degree=1)\n",
    "\n",
    "    if slope > 0:\n",
    "        trend = \"positive\"\n",
    "    else:\n",
    "        trend = \"negative\"\n",
    "\n",
    "    # Here, 5 is just a sample threshold for strong/weak distinction, adjust as needed\n",
    "    #magnitude = \"strong\" if abs(slope) > 5 else \"weak\" {magnitude}\n",
    "\n",
    "    return f\"{trend}\"\n",
    "\n",
    "def determine_slope(row):\n",
    "    values = row[years].values.astype(float)  # Ensure values are floats\n",
    "    slope, _ = np.polyfit(years, values, 1)  # linear fit (degree=1)\n",
    "    \n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "fb21fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_data(df_init, opco):\n",
    "        \n",
    "    if opco != 'all':\n",
    "        df = df_init[df_init['company_code_n'] == opco].copy()\n",
    "    elif opco == 'all':\n",
    "        df = df_init.copy()\n",
    "    else:\n",
    "        df = df_init[df_init['Country'] == 'Norway'].copy()\n",
    "    \n",
    "    \n",
    "    # number of customers\n",
    "    # Get unique sold_to_customer count\n",
    "    grouped = df.groupby(['business type', 'year']).agg(unique_customers=('sold_to_customer', 'nunique')).reset_index()\n",
    "    # Pivot the table\n",
    "    pivot_df = grouped.pivot_table(index=['business type'],\n",
    "                               columns='year',\n",
    "                               values='unique_customers',\n",
    "                               aggfunc='sum').reset_index()\n",
    "    \n",
    "    pivot_df.fillna(0, inplace=True)\n",
    "     \n",
    "    # Add 'Total' row\n",
    "    total_row = pivot_df.sum(numeric_only=True)  # sum only numeric columns\n",
    "    total_row['business type'] = 'All'  # set 'type' column to 'All'\n",
    "    pivot_df = pd.concat([pivot_df, pd.DataFrame([total_row])], ignore_index=True) #\n",
    "    \n",
    "    \n",
    "    pivot_df['Trend'] = pivot_df.apply(determine_trend, axis=1)\n",
    "    #pivot_df['Slope'] = pivot_df.apply(determine_slope, axis=1)\n",
    "    \n",
    "    number_of_customers = pivot_df.copy()\n",
    "    \n",
    "    # industry trends\n",
    "    # Group by the columns and aggregate with sum\n",
    "    grouped = df.groupby(['company_code_n', 'year', 'industry'])['order_intake_amount_eur'].sum().reset_index()\n",
    "    # Optionally, pivot the table for a clearer view\n",
    "    pivot_df = grouped.pivot_table(index=['company_code_n', 'industry'], columns='year', values='order_intake_amount_eur', aggfunc='sum').reset_index()\n",
    "    \n",
    "    pivot_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Add the 'Total' column\n",
    "    pivot_df['Total'] = pivot_df.sum(axis=1, numeric_only=True)\n",
    "\n",
    "    pivot_df['Trend'] = pivot_df.apply(determine_trend, axis=1)\n",
    "    #pivot_df['Slope'] = pivot_df.apply(determine_slope, axis=1)\n",
    "    \n",
    "    \n",
    "    # Sort customers by Total in descending order\n",
    "    result = pivot_df.sort_values(by='Total', ascending=False)\n",
    "\n",
    "    # Calculate cumulative sum and percentage of total\n",
    "    result['Cumulative_Sum'] = result['Total'].cumsum()\n",
    "    result['Cumulative_Percent'] = 100 * result['Cumulative_Sum'] / result['Total'].sum()\n",
    "\n",
    "    # Assign categories based on cumulative percentage\n",
    "    result['Category'] = pd.cut(\n",
    "        result['Cumulative_Percent'], \n",
    "        bins=[0, 80, 95, 100], \n",
    "        labels=['A', 'B', 'C']\n",
    "    )\n",
    "\n",
    "    # Drop temporary columns\n",
    "    result.drop(['Cumulative_Sum', 'Cumulative_Percent'], axis=1, inplace=True)\n",
    "\n",
    "    industry_trends = result.copy()\n",
    "    \n",
    "    \n",
    "    # Filter the DataFrame for category 'A'\n",
    "    category_a_df = industry_trends[industry_trends['Category'] == 'A']\n",
    "\n",
    "    # Group industries by trend\n",
    "    grouped = category_a_df.groupby('Trend')['industry'].apply(list)\n",
    "\n",
    "    # Construct the text\n",
    "    text_parts = []\n",
    "    for trend, industries in grouped.items():\n",
    "        industries_str = ', '.join(industries)\n",
    "        text_parts.append(f\"{industries_str} demonstrate a {trend} trend.\")\n",
    "\n",
    "    text_industry = \" \".join(text_parts)\n",
    "\n",
    "    #product trends\n",
    "    # Group by the columns and aggregate with sum\n",
    "    grouped = df.groupby(['company_code_n', 'year', 'bu2'])['order_intake_amount_eur'].sum().reset_index()\n",
    "    pivot_df = grouped.pivot_table(index=['company_code_n', 'bu2'], columns='year', values='order_intake_amount_eur', aggfunc='sum').reset_index()\n",
    "    pivot_df.fillna(0, inplace=True)\n",
    "    \n",
    "    # Add the 'Total' column\n",
    "    pivot_df['Total'] = pivot_df.sum(axis=1, numeric_only=True)\n",
    "    \n",
    "    pivot_df['Trend'] = pivot_df.apply(determine_trend, axis=1)\n",
    "    #pivot_df['Slope'] = pivot_df.apply(determine_slope, axis=1)\n",
    "    \n",
    "\n",
    "    # Sort customers by Total in descending order\n",
    "    result = pivot_df.sort_values(by='Total', ascending=False)\n",
    "\n",
    "    # Calculate cumulative sum and percentage of total\n",
    "    result['Cumulative_Sum'] = result['Total'].cumsum()\n",
    "    result['Cumulative_Percent'] = 100 * result['Cumulative_Sum'] / result['Total'].sum()\n",
    "\n",
    "    # Assign categories based on cumulative percentage\n",
    "    result['Category'] = pd.cut(\n",
    "        result['Cumulative_Percent'], \n",
    "        bins=[0, 80, 95, 100], \n",
    "        labels=['A', 'B', 'C']\n",
    "    )\n",
    "\n",
    "    # Drop temporary columns\n",
    "    result.drop(['Cumulative_Sum', 'Cumulative_Percent'], axis=1, inplace=True)\n",
    "    \n",
    "    product_trends = result.copy()\n",
    "    \n",
    "    # Filter the DataFrame for category 'A'\n",
    "    category_a_df = product_trends[product_trends['Category'] == 'A']\n",
    "\n",
    "    # Group industries by trend\n",
    "    grouped = category_a_df.groupby('Trend')['bu2'].apply(list)\n",
    "\n",
    "    # Construct the text\n",
    "    text_parts = []\n",
    "    for trend, bu in grouped.items():\n",
    "        bu_str = ', '.join(bu)\n",
    "        text_parts.append(f\"{bu_str} demonstrate a {trend} trend.\")\n",
    "\n",
    "    text_bu = \" \".join(text_parts)\n",
    "    \n",
    "    text_info = [f'From TOP industries for the last {period_of_analysis} years\\n' + text_industry , f'From TOP product bu for the last {period_of_analysis} years\\n' + text_bu]\n",
    "   \n",
    "    return number_of_customers, industry_trends, product_trends, text_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "3437d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to join non-'OTHERS' industries if present\n",
    "def custom_join(x):\n",
    "    non_others = [industry for industry in x if industry != 'OTHERS']\n",
    "    return '; '.join(sorted(set(non_others))) if non_others else 'OTHERS'\n",
    "\n",
    "# Apply the custom function within transform\n",
    "merged_with_types['industry_comb'] = merged_with_types.groupby('customer_name')['industry'].transform(custom_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "a00287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bu = data_file.target_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "80182616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize customers\n",
    "def categorize_customer(row):\n",
    "    recent_years = [2021, 2022, 2023]\n",
    "    # Extract only the columns for years\n",
    "    year_data = row[[2017, 2018, 2019, 2020, 2021, 2022, 2023]]\n",
    "    \n",
    "    # Get years with purchases\n",
    "    purchase_years = year_data[year_data > 0].index.tolist()\n",
    "    \n",
    "    if len(purchase_years) >= 4 and (2022 in purchase_years or 2023 in purchase_years):\n",
    "        return 'Active'\n",
    "    elif not set(recent_years).intersection(purchase_years):\n",
    "        return 'Sleeping'\n",
    "    else:\n",
    "        return 'Sporadic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "67f1bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soyears(temp, q=''):\n",
    "    if q == 'bu':\n",
    "        suf = '_bu'\n",
    "    else:\n",
    "        suf = ''\n",
    "    \n",
    "    df = temp.copy()\n",
    "    \n",
    "    # FY 23 is not full yet\n",
    "    df = df[df['FY'] < 2023]\n",
    "\n",
    "    # 1. Calculate average number of unique 'sales_order_so' per year ('FY') for each 'customer_name'\n",
    "    grouped1 = (temp.groupby(['customer_name', 'FY'])\n",
    "            .agg(unique_so_per_FY=pd.NamedAgg(column='sales_order_so', aggfunc='nunique'))\n",
    "            .reset_index()\n",
    "            .groupby('customer_name')\n",
    "            .agg(so_number_per_FY=pd.NamedAgg(column='unique_so_per_FY', aggfunc='mean'))\n",
    "            .reset_index())\n",
    "    \n",
    "    # 2. Calculate the average amount of 'order_intake_amount_eur' for each 'sales_order_so'\n",
    "    grouped2 = (temp.groupby(['customer_name', 'sales_order_so'])\n",
    "            .agg(mean_amount=pd.NamedAgg(column='order_intake_amount_eur', aggfunc='sum'))\n",
    "            .reset_index()\n",
    "            .groupby('customer_name')\n",
    "            .agg(so_average_in_eur=pd.NamedAgg(column='mean_amount', aggfunc='mean'))\n",
    "            .reset_index())\n",
    "    \n",
    "    # 3. Merge the results\n",
    "    result_df = pd.merge(grouped1, grouped2, on='customer_name', how='inner') \n",
    "    result_df.columns = ['customer_name', f'so_number_per_FY{suf}', f'so_average_in_eur{suf}']\n",
    "       \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def anupamtenyears(opco, df_init):\n",
    "    if opco != 'all':\n",
    "        df = df_init[df_init['company_code_n'] == opco].copy()\n",
    "    elif opco == 'all':\n",
    "        df = df_init.copy()\n",
    "    else:\n",
    "        df = df_init[df_init['Country'] == 'Norway'].copy()\n",
    "    \n",
    "    df['FY'] = pd.to_datetime(df['FY'])\n",
    "    df['FY'] = df['FY'].dt.year\n",
    "    \n",
    "    df['bu2'] = df['bu2'].astype(str)\n",
    "    df_target_bu = df[df['bu2'].isin(target_bu)]\n",
    "    \n",
    "    so_df = soyears(df)\n",
    "    so_df_bu = soyears(df_target_bu, q='bu')\n",
    "    \n",
    "    # Update the values in 'bu2' column if they are in the list\n",
    "    df['bu2'] = df['bu2'].apply(lambda x: 'PCI_' + x if x in target_bu else x)\n",
    "    \n",
    "    \n",
    "    #print(df.order_intake_amount_eur.sum())\n",
    "    #print(df_target_bu.order_intake_amount_eur.sum())\n",
    "    \n",
    "    \n",
    "    # Create the pivot table\n",
    "    pivot_df = df.pivot_table(index=['customer_name','Country','type', 'business type', 'industry_comb'], columns='FY', values='order_intake_amount_eur', aggfunc='sum', fill_value=0) \n",
    "    pivot_df_target = df_target_bu.pivot_table(index=['customer_name', 'Country','type', 'business type', 'industry_comb'], columns='FY', values='order_intake_amount_eur', aggfunc='sum', fill_value=0) \n",
    "    pivot_df_bu = df.pivot_table(index=['customer_name', 'Country', 'type', 'business type', 'industry_comb','FY'], columns='bu2', values='order_intake_amount_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "    \n",
    "    # Add the 'Total' column\n",
    "    pivot_df['Total'] = pivot_df.sum(axis=1)\n",
    "    pivot_df_target['Total'] = pivot_df_target.sum(axis=1)\n",
    "    \n",
    "    pivot_df = pivot_df[['Total']]\n",
    "    pivot_df.columns = ['Total_Total']\n",
    "    \n",
    "        \n",
    "    result = pivot_df.merge(pivot_df_target, left_index=True, right_index=True, how='left')\n",
    "    result['Yoko Product Share'] = result['Total'] / result['Total_Total']\n",
    "    result['Yoko Product Share'].fillna(0, inplace=True)\n",
    "    result = result[[2017, 2018, 2019, 2020, 2021, 2022, 2023, 'Total', 'Total_Total', 'Yoko Product Share']]\n",
    "    result = result.sort_values(by=['Total_Total', 'Yoko Product Share'], ascending=False)\n",
    "    result.fillna(0, inplace=True)\n",
    "    result.reset_index(inplace=True)\n",
    "    \n",
    "    result = result.merge(so_df, how='left', on='customer_name')\n",
    "    result = result.merge(so_df_bu, how='left', on='customer_name')\n",
    "    \n",
    "    pivot_df_bu['Total'] = pivot_df_bu.sum(axis=1)\n",
    "    \n",
    "    \n",
    "    # Sort customers by Total in descending order\n",
    "    result = result.sort_values(by='Total_Total', ascending=False)\n",
    "\n",
    "    # Calculate cumulative sum and percentage of total\n",
    "    result['Cumulative_Sum'] = result['Total_Total'].cumsum()\n",
    "    result['Cumulative_Percent'] = 100 * result['Cumulative_Sum'] / result['Total_Total'].sum()\n",
    "\n",
    "    # Assign categories based on cumulative percentage\n",
    "    result['Category'] = pd.cut(\n",
    "        result['Cumulative_Percent'], \n",
    "        bins=[0, 80, 95, 100], \n",
    "        labels=['A', 'B', 'C']\n",
    "    )\n",
    "\n",
    "    # Drop temporary columns\n",
    "    result.drop(['Cumulative_Sum', 'Cumulative_Percent'], axis=1, inplace=True)\n",
    "    \n",
    "    # Sort customers by Total in descending order\n",
    "    result = result.sort_values(by='Total', ascending=False)\n",
    "\n",
    "    # Calculate cumulative sum and percentage of total\n",
    "    result['Cumulative_Sum'] = result['Total'].cumsum()\n",
    "    result['Cumulative_Percent'] = 100 * result['Cumulative_Sum'] / result['Total'].sum()\n",
    "\n",
    "    # Assign categories based on cumulative percentage\n",
    "    result['Category Product BU'] = pd.cut(\n",
    "        result['Cumulative_Percent'], \n",
    "        bins=[0, 80, 95, 100], \n",
    "        labels=['A', 'B', 'C']\n",
    "    )\n",
    "\n",
    "    # Drop temporary columns\n",
    "    result.drop(['Cumulative_Sum', 'Cumulative_Percent'], axis=1, inplace=True)\n",
    "    \n",
    "   \n",
    "    result['Activeness'] = result.apply(categorize_customer, axis=1)\n",
    "    \n",
    "    \n",
    "    new_customers_per_year = {}\n",
    "    \n",
    "    for year in df['year'].unique():\n",
    "        # Customers up to last year\n",
    "        previous_customers = df[df['year'] < year]['customer_name'].unique()\n",
    "\n",
    "        # Customers this year\n",
    "        customers_this_year = df[df['year'] == year]['customer_name'].unique()\n",
    "\n",
    "        # New customers this year (set difference)\n",
    "        new_customers = set(customers_this_year) - set(previous_customers)\n",
    "\n",
    "        # Store the count of new customers\n",
    "        new_customers_per_year[year] = len(new_customers)\n",
    "    \n",
    "    # Convert the result to a dataframe\n",
    "    new_customers_df = pd.DataFrame(list(new_customers_per_year.items()), columns=['Year', 'New Customers'])\n",
    "\n",
    "    # Transform the dataframe\n",
    "    pivot_df = new_customers_df.pivot(index=None, columns='Year', values='New Customers').reset_index(drop=True)\n",
    "    pivot_df = pivot_df[sorted(pivot_df.columns)]  # Sort columns in ascending order\n",
    "    \n",
    "    # Sum across rows\n",
    "    summed_row = pivot_df.sum(axis=0)\n",
    "\n",
    "    # Convert Series to DataFrame and reshape\n",
    "    final_df = summed_row.to_frame().T\n",
    "\n",
    "    # Set the index\n",
    "    final_df.index = ['Number of new customers']\n",
    "   \n",
    "    new_customers_df = final_df.copy()\n",
    "    \n",
    "    \n",
    "    new_customers_per_year_bu = {}\n",
    "\n",
    "    for year in df_target_bu['year'].unique():\n",
    "        # Customers up to last year\n",
    "        previous_customers = df_target_bu[df_target_bu['year'] < year]['customer_name'].unique()\n",
    "        # Customers this year\n",
    "        customers_this_year = df_target_bu[df_target_bu['year'] == year]['customer_name'].unique()\n",
    "        # New customers this year (set difference)\n",
    "        new_customers = set(customers_this_year) - set(previous_customers)\n",
    "        # Store the count of new customers\n",
    "        new_customers_per_year_bu[year] = len(new_customers)\n",
    "    \n",
    "    # Convert the result to a dataframe\n",
    "    new_customers_bu_df = pd.DataFrame(list(new_customers_per_year_bu.items()), columns=['Year', 'New Customers'])\n",
    "\n",
    "    # Transform the dataframe\n",
    "    pivot_df = new_customers_bu_df.pivot(index=None, columns='Year', values='New Customers').reset_index(drop=True)\n",
    "    pivot_df = pivot_df[sorted(pivot_df.columns)]  # Sort columns in ascending order\n",
    "    \n",
    "    # Sum across rows\n",
    "    summed_row = pivot_df.sum(axis=0)\n",
    "\n",
    "    # Convert Series to DataFrame and reshape\n",
    "    final_df = summed_row.to_frame().T\n",
    "\n",
    "    # Set the index\n",
    "    final_df.index = ['Number of new customers for Product']\n",
    "   \n",
    "    new_customers_df = pd.concat([final_df, new_customers_df])\n",
    "    \n",
    "    \n",
    "    # Filter the dataframe based on conditions\n",
    "    active_top_customers = result[ (result['Category Product BU'] == 'A') & \n",
    "                     (result['Activeness'] == 'Active')]\n",
    "    \n",
    "   \n",
    "    # Filter the dataframe based on conditions\n",
    "    sleeping_top_customers = result[(result['Category Product BU'] == 'A') & \n",
    "                     (result['Activeness'] == 'Sleeping')]\n",
    "    \n",
    "    \n",
    "    active_distributors = result[(result['type'] == 'Distributor') & (result['Activeness'] == 'Active')]\n",
    "\n",
    "    \n",
    "    number_info = [len(active_top_customers), len(sleeping_top_customers), len(active_distributors)]\n",
    "    \n",
    "   \n",
    "    return result, pivot_df_bu, new_customers_df, number_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdae8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all opcos preparation\n",
    "opco_list = ['all']\n",
    "for_trend_df = merged_with_types[merged_with_types['bu2'].isin(target_bu)]\n",
    "\n",
    "for_trend_df['bu2'] = for_trend_df['bu2'].apply(combine_values)\n",
    "\n",
    "for opco in opco_list:\n",
    "\n",
    "    df_customer_count = trend_data(for_trend_df, opco)[0]\n",
    "    df_industry = trend_data(for_trend_df, opco)[1]\n",
    "    df_products = trend_data(for_trend_df, opco)[2]\n",
    "    \n",
    "    print(trend_data(for_trend_df, opco)[3][0], '\\n' + trend_data(for_trend_df, opco)[3][1])\n",
    "    \n",
    "    df_for_excel = anupamtenyears(opco, merged_with_types)[0]\n",
    "    df_target_for_excel = anupamtenyears(opco, merged_with_types)[1]\n",
    "    new_cust = anupamtenyears(opco, merged_with_types)[2]\n",
    "    info_text = anupamtenyears(opco, merged_with_types)[3]\n",
    "    \n",
    "    print(f'Number of active TOP customers of Yokogawa-Product for {opco} is {info_text[0]}\\nNumber of sleeping TOP customers of Yokogawa-Product is {info_text[1]}\\nNumber of active distributors {info_text[2]} ')\n",
    "    \n",
    "    writer = pd.ExcelWriter(f'data_files/outcome/{opco}_overview_18.xlsx')\n",
    "    df_customer_count.to_excel(writer, sheet_name='customer count', index=True)\n",
    "    df_industry.to_excel(writer, sheet_name='industry trends', index=True)\n",
    "    df_products.to_excel(writer, sheet_name='products trends', index=True)\n",
    "    \n",
    "    df_for_excel.to_excel(writer, sheet_name='years', index=True)\n",
    "    df_target_for_excel.to_excel(writer, sheet_name='bu_years', index=True)\n",
    "    new_cust.to_excel(writer, sheet_name='new_customers', index=True)\n",
    "    \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for_plot_df = merged_with_types.copy()\n",
    "\n",
    "# Get unique countries\n",
    "opco_list = ['all']\n",
    "\n",
    "for opco in opco_list:\n",
    "    # Filter DataFrame for a specific country\n",
    "    temp_df = for_plot_df[for_plot_df['company_code_n'] == opco]\n",
    "    \n",
    "    temp_df['order_intake_amount_eur'] = round((temp_df['order_intake_amount_eur'] / 1000) , 0)\n",
    "\n",
    "    # Group by industry and get the sum of order intake amount\n",
    "    grouped = temp_df.groupby('industry')['order_intake_amount_eur'].sum().sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the total sum for labeling purposes\n",
    "    total_sum = grouped.sum()\n",
    "\n",
    "    # Plotting with larger figure size\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = grouped.plot(kind='bar', color=plt.cm.Paired.colors)\n",
    "    ax.set_title(f\"Order Intake Amount per Industry for {opco}\", fontsize=16)\n",
    "    ax.set_ylabel(\"Amount (in kEuro)\", fontsize=14)\n",
    "    #ax.set_xlabel(\"Industry\", fontsize=8)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Set the x-tick labels (industries) to be horizontal and adjust font size if needed\n",
    "    plt.xticks(fontsize=8, rotation=45)  # Set rotation to 0 for horizontal labels\n",
    "    \n",
    "    # Add labels to the bars with the absolute value and percentage\n",
    "    for rect in ax.patches:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height}k€ ({height/total_sum:.0%})',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 5),  # 5 points vertical offset for better spacing\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    # Remove top, left, and right frame, but keep the x-axis (bottom spine)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Save the plot as a .jpg file\n",
    "    plt.savefig(f'data_files/outcome/{opco}_industry_sales.jpg', format='jpg', dpi=300)\n",
    "\n",
    "    plt.close()  # Close the plot to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1791e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discont analysis\n",
    "discounts_df = pd.read_excel('data_files/discounts.xlsx')\n",
    "\n",
    "discounts_df['sstp_approval_no'] = discounts_df['sstp_approval_no'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "discounts_df['sold_to_customer'] = discounts_df['sold_to_customer'].astype(str)\n",
    "discounts_df['sales_order_so'] = discounts_df['sales_order_so'].astype(str)\n",
    "discounts_with_customer_name = discounts_df.merge(df_customers, on='sold_to_customer', how='left')\n",
    "\n",
    "print(len(discounts_with_customer_name))\n",
    "\n",
    "discounts_with_customer_name['business type'] = discounts_with_customer_name['business type'].fillna('Direct')\n",
    "discounts_with_customer_name['eu_industry_segment_n_latest'] = discounts_with_customer_name['eu_industry_segment_n_latest'].fillna('Others')\n",
    "\n",
    "discounts_with_customer_name = discounts_with_customer_name[~discounts_with_customer_name['type'].isna()]\n",
    "\n",
    "wdf = discounts_with_customer_name.copy()\n",
    "\n",
    "wdf = wdf[['customer_name', 'type', 'business type', 'Country', 'fiscal_year', 'year_month', 'sales_order_so',\n",
    "       'sstp_approval_no', 'eu_industry_segment_n_latest', 'bu', 'material', 'ms_code',\n",
    "       'sales_quantity', 'sales_rsp_eur', 'sales_eur', 'cogs(ms)_eur',\n",
    "       'gp_eur']]\n",
    "\n",
    "wdf['FY'] = wdf['fiscal_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3a3326fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_wdf_qty = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "pivot_wdf_sales_rsp = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_sales = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_cogs = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_gp = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "bu_pivot_wdf_qty = wdf.pivot_table(index='bu', columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "bu_pivot_wdf_sales_rsp = wdf.pivot_table(index='bu', columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_sales = wdf.pivot_table(index='bu', columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_cogs = wdf.pivot_table(index='bu', columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_gp = wdf.pivot_table(index='bu', columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "material_pivot_wdf_qty = wdf.pivot_table(index='material', columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "material_pivot_wdf_sales_rsp = wdf.pivot_table(index='material', columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_sales = wdf.pivot_table(index='material', columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_cogs = wdf.pivot_table(index='material', columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_gp = wdf.pivot_table(index='material', columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate % Discount:\n",
    "pivot_wdf_discount = (pivot_wdf_sales_rsp - pivot_wdf_sales) / pivot_wdf_sales_rsp * 100\n",
    "\n",
    "# 2. Calculate % Profit:\n",
    "# Here, you might want to handle cases where 'sales_eur' is zero to avoid division by zero errors\n",
    "with np.errstate(divide='ignore', invalid='ignore'):  # This will handle the divide by zero warning\n",
    "    pivot_wdf_profit = pivot_wdf_gp / pivot_wdf_sales * 100\n",
    "    pivot_wdf_profit[pivot_wdf_sales == 0] = np.nan  # Replace any infinity values with NaN or you can use 0 or any other number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "355461e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sales_order_so and determine its approval status\n",
    "approval_status = wdf.groupby('sales_order_so')['sstp_approval_no'].agg(['sum', 'count'])\n",
    "\n",
    "approval_status['approval_type'] = np.where(\n",
    "    approval_status['sum'] > 0, 'With Approval', 'Without Approval'\n",
    ")\n",
    "\n",
    "# Merge the original dataframe with the approval status\n",
    "wdf = wdf.merge(approval_status[['approval_type']], left_on='sales_order_so', right_index=True, how='left')\n",
    "\n",
    "# Now, get counts for each customer_name\n",
    "total_sales_orders = wdf.groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "sales_orders_with_approval = wdf[wdf['approval_type'] == 'With Approval'].groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "sales_orders_without_approval = wdf[wdf['approval_type'] == 'Without Approval'].groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "# Combine the results\n",
    "result = pd.concat([total_sales_orders, sales_orders_with_approval, sales_orders_without_approval], axis=1)\n",
    "result.columns = ['Total Sales Orders', 'With Approval', 'Without Approval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3f72ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f'data_files/outcome/check_.xlsx')\n",
    "result.to_excel(writer, sheet_name=f'years', index=True)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6b38714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wdf.copy()\n",
    "\n",
    "# 2. Time Series Analysis:\n",
    "monthly_sales = df.groupby('year_month')['sales_eur'].sum()\n",
    "\n",
    "# 3. Product Analysis:\n",
    "top_bu_by_sales = df.groupby('bu')['sales_eur'].sum().nlargest(10)\n",
    "top_products_by_sales = df.groupby('material')['sales_eur'].sum().nlargest(10)\n",
    "top_bu_by_profit = df.groupby('bu')['gp_eur'].sum().nlargest(10)\n",
    "top_products_by_profit = df.groupby('material')['gp_eur'].sum().nlargest(10)\n",
    "\n",
    "# 4. Customer Analysis:\n",
    "top_customers_by_sales = df.groupby('customer_name')['sales_eur'].sum().nlargest(10)\n",
    "\n",
    "# 6. Discount Analysis:\n",
    "df['discount_eur'] = df['sales_rsp_eur'] - df['sales_eur']\n",
    "avg_discount = df['discount_eur'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
