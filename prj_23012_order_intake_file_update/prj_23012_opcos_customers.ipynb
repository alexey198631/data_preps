{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aeee008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import importlib\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "# keeping company information in additional file\n",
    "import data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280f679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('data_files/order_data.db')\n",
    "query = \"SELECT * FROM orders\"  # Replace 'tablename' with your table name\n",
    "df_orders = pd.read_sql_query(query, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders = df_orders[['company_code_n', 'FY', 'bu2', 'sales_order_so', 'sold_to_customer', 'eu_industry_n', 'order_intake_amount_eur', 'eu_industry_segment_n_latest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973ad2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn2 = sqlite3.connect('data_files/customer_data.db')\n",
    "query = \"SELECT * FROM customers\" \n",
    "df_customers = pd.read_sql_query(query, conn2)\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c7d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers  = df_customers[['sold_to_customer', 'customer_name', 'type', 'tier_new', 'countries']]\n",
    "df_customers.columns  = ['sold_to_customer', 'customer_name', 'type', 'business type', 'Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe7c311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION OF THE DATA FILE WITH INDUSTRIES\n",
    "so_industries_init = pd.read_excel('data_files/industries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data type of 'sales_order_so' column is the same in both DataFrames\n",
    "df_orders['sales_order_so'] = df_orders['sales_order_so'].astype(str)\n",
    "so_industries_init['sales_order_so'] = so_industries_init['sales_order_so'].astype(str)\n",
    "\n",
    "# Merge the DataFrames\n",
    "merged_df = df_orders.merge(so_industries_init[['sales_order_so', 'ec_eu_industry_n', 'eu_industry_segment_n_latest']], \n",
    "                     on='sales_order_so', \n",
    "                     how='left')\n",
    "\n",
    "print(len(merged_df))\n",
    "\n",
    "# Fill in the missing values\n",
    "merged_df['eu_industry_n'] = merged_df['eu_industry_n'].fillna(merged_df['ec_eu_industry_n'])\n",
    "merged_df['eu_industry_segment_n_latest'] = merged_df['eu_industry_segment_n_latest_x'].fillna(merged_df['eu_industry_segment_n_latest_y'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df = merged_df.drop(columns=['ec_eu_industry_n', 'eu_industry_segment_n_latest_x', 'eu_industry_segment_n_latest_y'])\n",
    "\n",
    "print(len(merged_df))\n",
    "\n",
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "merged_df['sold_to_customer'] = merged_df['sold_to_customer'].astype(str)\n",
    "merged_with_types = merged_df.merge(df_customers, on='sold_to_customer', how='left')\n",
    "\n",
    "print(len(merged_with_types))\n",
    "\n",
    "merged_with_types['business type'] = merged_with_types['business type'].fillna('Direct')\n",
    "merged_with_types['eu_industry_n'] = merged_with_types['eu_industry_n'].fillna('Others')\n",
    "merged_with_types['eu_industry_segment_n_latest'] = merged_with_types['eu_industry_segment_n_latest'].fillna('Others')\n",
    "\n",
    "# Combine unique values from 'eu_industry_n' for each company\n",
    "merged_with_types['eu_industry_n'] = merged_with_types.groupby('customer_name')['eu_industry_n'].transform(lambda x: '; '.join(sorted(set(x))))\n",
    "merged_with_types['eu_industry_segment_n_latest'] = merged_with_types.groupby('customer_name')['eu_industry_segment_n_latest'].transform(lambda x: '; '.join(sorted(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bu = data_file.target_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a1a77d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soyears(temp, q=''):\n",
    "    if q == 'bu':\n",
    "        suf = '_bu'\n",
    "    else:\n",
    "        suf = ''\n",
    "    \n",
    "    df = temp.copy()\n",
    "    \n",
    "    # FY 23 is not full yet\n",
    "    df = df[df['FY'] < 2023]\n",
    "\n",
    "    # 1. Calculate average number of unique 'sales_order_so' per year ('FY') for each 'customer_name'\n",
    "    grouped1 = (temp.groupby(['customer_name', 'FY'])\n",
    "            .agg(unique_so_per_FY=pd.NamedAgg(column='sales_order_so', aggfunc='nunique'))\n",
    "            .reset_index()\n",
    "            .groupby('customer_name')\n",
    "            .agg(so_number_per_FY=pd.NamedAgg(column='unique_so_per_FY', aggfunc='mean'))\n",
    "            .reset_index())\n",
    "    \n",
    "    # 2. Calculate the average amount of 'order_intake_amount_eur' for each 'sales_order_so'\n",
    "    grouped2 = (temp.groupby(['customer_name', 'sales_order_so'])\n",
    "            .agg(mean_amount=pd.NamedAgg(column='order_intake_amount_eur', aggfunc='sum'))\n",
    "            .reset_index()\n",
    "            .groupby('customer_name')\n",
    "            .agg(so_average_in_eur=pd.NamedAgg(column='mean_amount', aggfunc='mean'))\n",
    "            .reset_index())\n",
    "    \n",
    "    # 3. Merge the results\n",
    "    result_df = pd.merge(grouped1, grouped2, on='customer_name', how='inner') \n",
    "    result_df.columns = ['customer_name', f'so_number_per_FY{suf}', f'so_average_in_eur{suf}']\n",
    "       \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def anupamtenyears(opco, df_init):\n",
    "    if opco != 'all':\n",
    "        df = df_init[df_init['company_code_n'] == opco].copy()\n",
    "    else:\n",
    "        df = df_init[df_init['Country'] == 'Norway'].copy()\n",
    "    \n",
    "    df['FY'] = pd.to_datetime(df['FY'])\n",
    "    df['FY'] = df['FY'].dt.year\n",
    "    \n",
    "    df['bu2'] = df['bu2'].astype(str)\n",
    "    df_target_bu = df[df['bu2'].isin(target_bu)]\n",
    "    \n",
    "    so_df = soyears(df)\n",
    "    so_df_bu = soyears(df_target_bu, q='bu')\n",
    "    \n",
    "    # Update the values in 'bu2' column if they are in the list\n",
    "    df['bu2'] = df['bu2'].apply(lambda x: 'PCI_' + x if x in target_bu else x)\n",
    "    \n",
    "    \n",
    "    print(df.order_intake_amount_eur.sum())\n",
    "    print(df_target_bu.order_intake_amount_eur.sum())\n",
    "    \n",
    "    \n",
    "    # Create the pivot table\n",
    "    pivot_df = df.pivot_table(index=['customer_name','Country','type', 'business type', 'eu_industry_n', 'eu_industry_segment_n_latest'], columns='FY', values='order_intake_amount_eur', aggfunc='sum', fill_value=0) \n",
    "    pivot_df_target = df_target_bu.pivot_table(index=['customer_name', 'Country','type', 'business type', 'eu_industry_n', 'eu_industry_segment_n_latest'], columns='FY', values='order_intake_amount_eur', aggfunc='sum', fill_value=0) \n",
    "    pivot_df_bu = df.pivot_table(index=['customer_name', 'Country', 'type', 'business type', 'eu_industry_n', 'eu_industry_segment_n_latest','FY'], columns='bu2', values='order_intake_amount_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "    \n",
    "    # Add the 'Total' column\n",
    "    pivot_df['Total'] = pivot_df.sum(axis=1)\n",
    "    pivot_df_target['Total'] = pivot_df_target.sum(axis=1)\n",
    "    \n",
    "    pivot_df = pivot_df[['Total']]\n",
    "    pivot_df.columns = ['Total_Total']\n",
    "    \n",
    "    \n",
    "    result = pivot_df.merge(pivot_df_target, left_index=True, right_index=True, how='left')\n",
    "    result['Yoko Product Share'] = result['Total'] / result['Total_Total']\n",
    "    result['Yoko Product Share'].fillna(0, inplace=True)\n",
    "    result = result[[2017, 2018, 2019, 2020, 2021, 2022, 2023, 'Total', 'Total_Total', 'Yoko Product Share']]\n",
    "    result = result.sort_values(by=['Total_Total', 'Yoko Product Share'], ascending=False)\n",
    "    result.fillna(0, inplace=True)\n",
    "    result.reset_index(inplace=True)\n",
    "    \n",
    "    result = result.merge(so_df, how='left', on='customer_name')\n",
    "    result = result.merge(so_df_bu, how='left', on='customer_name')\n",
    "    \n",
    "    pivot_df_bu['Total'] = pivot_df_bu.sum(axis=1)\n",
    "    \n",
    "    return result, pivot_df_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdae8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all opcos preparation\n",
    "opco_list = ['all']\n",
    "\n",
    "for opco in opco_list:\n",
    "    \n",
    "    df_for_excel = anupamtenyears(opco, merged_with_types)[0]\n",
    "    df_target_for_excel = anupamtenyears(opco, merged_with_types)[1]\n",
    "    \n",
    "    writer = pd.ExcelWriter(f'data_files/outcome/{opco}_.xlsx')\n",
    "    df_for_excel.to_excel(writer, sheet_name=f'years', index=True)\n",
    "    df_target_for_excel.to_excel(writer, sheet_name=f'bu_years', index=True)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d3ac105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discont analysis\n",
    "discounts_df = pd.read_excel('data_files/discounts.xlsx')\n",
    "\n",
    "discounts_df['sstp_approval_no'] = discounts_df['sstp_approval_no'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "discounts_df['sold_to_customer'] = discounts_df['sold_to_customer'].astype(str)\n",
    "discounts_df['sales_order_so'] = discounts_df['sales_order_so'].astype(str)\n",
    "discounts_with_customer_name = discounts_df.merge(df_customers, on='sold_to_customer', how='left')\n",
    "\n",
    "print(len(discounts_with_customer_name))\n",
    "\n",
    "discounts_with_customer_name['business type'] = discounts_with_customer_name['business type'].fillna('Direct')\n",
    "discounts_with_customer_name['eu_industry_segment_n_latest'] = discounts_with_customer_name['eu_industry_segment_n_latest'].fillna('Others')\n",
    "\n",
    "discounts_with_customer_name = discounts_with_customer_name[~discounts_with_customer_name['type'].isna()]\n",
    "\n",
    "wdf = discounts_with_customer_name.copy()\n",
    "\n",
    "wdf = wdf[['customer_name', 'type', 'business type', 'Country', 'fiscal_year', 'year_month', 'sales_order_so',\n",
    "       'sstp_approval_no', 'eu_industry_segment_n_latest', 'bu', 'material', 'ms_code',\n",
    "       'sales_quantity', 'sales_rsp_eur', 'sales_eur', 'cogs(ms)_eur',\n",
    "       'gp_eur']]\n",
    "\n",
    "wdf['FY'] = wdf['fiscal_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b5f33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_wdf_qty = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "pivot_wdf_sales_rsp = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_sales = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_cogs = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "pivot_wdf_gp = wdf.pivot_table(index=['customer_name','Country','type', 'business type'], columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "bu_pivot_wdf_qty = wdf.pivot_table(index='bu', columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "bu_pivot_wdf_sales_rsp = wdf.pivot_table(index='bu', columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_sales = wdf.pivot_table(index='bu', columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_cogs = wdf.pivot_table(index='bu', columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "bu_pivot_wdf_gp = wdf.pivot_table(index='bu', columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)\n",
    "\n",
    "material_pivot_wdf_qty = wdf.pivot_table(index='material', columns='FY', values='sales_quantity', aggfunc='sum', fill_value=0) \n",
    "material_pivot_wdf_sales_rsp = wdf.pivot_table(index='material', columns='FY', values='sales_rsp_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_sales = wdf.pivot_table(index='material', columns='FY', values='sales_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_cogs = wdf.pivot_table(index='material', columns='FY', values='cogs(ms)_eur', aggfunc='sum', fill_value=0)\n",
    "material_pivot_wdf_gp = wdf.pivot_table(index='material', columns='FY', values='gp_eur', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate % Discount:\n",
    "pivot_wdf_discount = (pivot_wdf_sales_rsp - pivot_wdf_sales) / pivot_wdf_sales_rsp * 100\n",
    "\n",
    "# 2. Calculate % Profit:\n",
    "# Here, you might want to handle cases where 'sales_eur' is zero to avoid division by zero errors\n",
    "with np.errstate(divide='ignore', invalid='ignore'):  # This will handle the divide by zero warning\n",
    "    pivot_wdf_profit = pivot_wdf_gp / pivot_wdf_sales * 100\n",
    "    pivot_wdf_profit[pivot_wdf_sales == 0] = np.nan  # Replace any infinity values with NaN or you can use 0 or any other number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7a633401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by sales_order_so and determine its approval status\n",
    "approval_status = wdf.groupby('sales_order_so')['sstp_approval_no'].agg(['sum', 'count'])\n",
    "\n",
    "approval_status['approval_type'] = np.where(\n",
    "    approval_status['sum'] > 0, 'With Approval', 'Without Approval'\n",
    ")\n",
    "\n",
    "# Merge the original dataframe with the approval status\n",
    "wdf = wdf.merge(approval_status[['approval_type']], left_on='sales_order_so', right_index=True, how='left')\n",
    "\n",
    "# Now, get counts for each customer_name\n",
    "total_sales_orders = wdf.groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "sales_orders_with_approval = wdf[wdf['approval_type'] == 'With Approval'].groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "sales_orders_without_approval = wdf[wdf['approval_type'] == 'Without Approval'].groupby('customer_name')['sales_order_so'].nunique()\n",
    "\n",
    "# Combine the results\n",
    "result = pd.concat([total_sales_orders, sales_orders_with_approval, sales_orders_without_approval], axis=1)\n",
    "result.columns = ['Total Sales Orders', 'With Approval', 'Without Approval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "05112126",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f'data_files/outcome/check_.xlsx')\n",
    "result.to_excel(writer, sheet_name=f'years', index=True)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4bc51712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wdf.copy()\n",
    "\n",
    "# 2. Time Series Analysis:\n",
    "monthly_sales = df.groupby('year_month')['sales_eur'].sum()\n",
    "\n",
    "# 3. Product Analysis:\n",
    "top_bu_by_sales = df.groupby('bu')['sales_eur'].sum().nlargest(10)\n",
    "top_products_by_sales = df.groupby('material')['sales_eur'].sum().nlargest(10)\n",
    "top_bu_by_profit = df.groupby('bu')['gp_eur'].sum().nlargest(10)\n",
    "top_products_by_profit = df.groupby('material')['gp_eur'].sum().nlargest(10)\n",
    "\n",
    "# 4. Customer Analysis:\n",
    "top_customers_by_sales = df.groupby('customer_name')['sales_eur'].sum().nlargest(10)\n",
    "\n",
    "# 6. Discount Analysis:\n",
    "df['discount_eur'] = df['sales_rsp_eur'] - df['sales_eur']\n",
    "avg_discount = df['discount_eur'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
