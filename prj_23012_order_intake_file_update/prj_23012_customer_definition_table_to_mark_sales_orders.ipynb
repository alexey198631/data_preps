{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa16cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import importlib\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import win32com.client as win32\n",
    "\n",
    "# keeping company information in additional file\n",
    "import data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0dc6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c49d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_person_n = data_file.sales_person_n\n",
    "exlbu=data_file.exlbu\n",
    "exlpanrter=data_file.exlpanrter\n",
    "target_bu = data_file.target_bu\n",
    "\n",
    "# Get current year and month\n",
    "now = datetime.now()\n",
    "last_month = now\n",
    "# Format last month as string in YYYYMM format\n",
    "year_month = last_month.strftime(\"%Y%m\")\n",
    "\n",
    "conn = sqlite3.connect('data_files/order_data.db')\n",
    "query = \"SELECT * FROM orders\"\n",
    "df_orders = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "conn2 = sqlite3.connect('data_files/customer_data.db')\n",
    "query = \"SELECT * FROM customers\"\n",
    "df_customers = pd.read_sql_query(query, conn2)\n",
    "conn2.close()\n",
    "\n",
    "# for testing purposes I keep this lines\n",
    "wdf = df_customers.copy()\n",
    "dfc = df_orders.copy()\n",
    "\n",
    "wdf.loc[wdf['tier'].isna(), 'tier'] = 'Direct'\n",
    "wdf.loc[wdf['tier'] == 'None', 'tier'] = 'Direct'\n",
    "wdf.loc[wdf['tier_new'].isna(), 'tier_new'] = 'Direct'\n",
    "wdf.loc[wdf['tier_new'] == 'None', 'tier_new'] = 'Direct'\n",
    "wdf.loc[wdf[exlpanrter] == 'None', exlpanrter] = 'NA'\n",
    "wdf.loc[wdf[exlpanrter].isna(), exlpanrter] = 'NA'\n",
    "\n",
    "bu_defin = pd.read_excel('data_files/bu_defin.xlsx')\n",
    "bu_defin = bu_defin.loc[:, 'bu2':]\n",
    "bu_defin['for_bu'] = bu_defin['for_bu'].astype(str)\n",
    "bu_defin['bu2'] = bu_defin['bu2'].astype(str)\n",
    "bu_defin['bu2'] = bu_defin['bu2'].str.strip()\n",
    "\n",
    "order_data = dfc.loc[:,['company_code_n', 'year_month', 'FY', \n",
    "       'bu2', 'sales_person_n', 'sales_order_so', 'sold_to_customer',\n",
    "       'sold_to_customer_n','order_intake_amount_eur', 'ec_eu_customer_n', 'ec_eu_industry_n']]\n",
    "\n",
    "order_data['bu2'] = order_data['bu2'].astype(str)\n",
    "order_data['bu2'] = order_data['bu2'].str.strip()\n",
    "\n",
    "# add bu column for future reports\n",
    "order_data = order_data.merge(bu_defin, how='left' )\n",
    "\n",
    "print('should be 0 =', len(order_data) - len(dfc))\n",
    "print('should be 0 =', order_data.order_intake_amount_eur.sum() - dfc.order_intake_amount_eur.sum())\n",
    "\n",
    "order_columns = list(order_data.columns) + ['customer_name', 'indirect_direct', 'tier', 'tier_new', 'type', 'countries']\n",
    "\n",
    "print('agents case ... processing...')\n",
    "\n",
    "# special case with specific SO for agent\n",
    "agent_so = data_file.special_so\n",
    "agent_so_add = data_file.special_so_add \n",
    "agent_so_two = data_file.special_so_two \n",
    "agent_one = data_file.agent_one\n",
    "\n",
    "special_so_three = data_file.special_so_three\n",
    "agent_three = data_file.agent_three\n",
    "\n",
    "so_order_data = order_data[(order_data['sales_order_so'] == agent_so) |(order_data['sales_order_so'] == agent_so_add) | (order_data['sales_order_so'] == agent_so_two) | (order_data['sales_order_so'] == special_so_three)]\n",
    "\n",
    "# exlude these so_order_data raws from df\n",
    "order_data = order_data[~(\n",
    "    (order_data['sales_order_so'] == agent_so) |\n",
    "    (order_data['sales_order_so'] == agent_so_add) |\n",
    "    (order_data['sales_order_so'] == agent_so_two) |\n",
    "    (order_data['sales_order_so'] == special_so_three)\n",
    ")]\n",
    "\n",
    "so_order_data.loc[so_order_data['sales_order_so'] != special_so_three, 'customer_name'] = agent_one\n",
    "so_order_data.loc[so_order_data['sales_order_so'] == special_so_three, 'customer_name'] = agent_three\n",
    "\n",
    "so_order_data.loc[:, 'indirect_direct'] = 'Indirect'\n",
    "so_order_data.loc[:, 'tier'] = 'Channel Partner'\n",
    "so_order_data.loc[:, 'tier_new'] = 'Channel Partner'\n",
    "so_order_data.loc[:, 'type'] = 'Agent'\n",
    "\n",
    "# Create a dictionary mapping sold_to_customer values to corresponding countries\n",
    "coutr = df_customers.copy()\n",
    "coutr['sold_to_customer'] = coutr['sold_to_customer'].astype(str)\n",
    "customer_country_map = coutr.set_index('sold_to_customer')['countries'].to_dict()\n",
    "\n",
    "# Fill missing values in so_order_data['countries'] using the mapping dictionary\n",
    "so_order_data['countries'] = so_order_data['sold_to_customer'].map(customer_country_map)\n",
    "\n",
    "# special case with specific cutomers for agent\n",
    "partners_data = wdf[(wdf['tier'] != 'Direct') | (wdf[exlpanrter] != 'NA')]\n",
    "agent_two = data_file.agent_two\n",
    "partners_data.loc[partners_data[exlpanrter] != 'NA', 'customer_name'] = agent_two\n",
    "partners_data = partners_data.loc[:, ['sold_to_customer', 'agent_person', 'company_code_n', 'sold_to_customer_n','customer_name', \n",
    "       'indirect_direct', 'channel', 'type', 'tier', 'tier_new', 'countries']]\n",
    "\n",
    "partners_data['sold_to_customer'] = partners_data['sold_to_customer'].astype(str)\n",
    "\n",
    "agent_partners = partners_data[partners_data['agent_person'].notna()]\n",
    "agent_partners = agent_partners[agent_partners['agent_person'] != 'None']\n",
    "# agent sales records preparation\n",
    "agents_order_data = order_data[order_data['sales_person_n'].isin(sales_person_n)]\n",
    "agents_order_data = agents_order_data.merge(agent_partners, left_on='sales_person_n', right_on='sold_to_customer_n', how='left')\n",
    "agents_order_data = agents_order_data.filter(regex='^(?!.*_y)')\n",
    "# Exclude '_x' from all column names\n",
    "agents_order_data.columns = agents_order_data.columns.str.replace('_x', '')\n",
    "agents_order_data = agents_order_data.loc[:, order_columns]\n",
    "agents_order_data['type'] = 'Agent'\n",
    "\n",
    "# Fill missing values in so_order_data['countries'] using the mapping dictionary\n",
    "agents_order_data['countries'] = agents_order_data['sold_to_customer'].map(customer_country_map)\n",
    "\n",
    "# exclude agents sales from order data not to double lines\n",
    "order_data = order_data[~order_data['sales_person_n'].isin(sales_person_n)]\n",
    "# all partners except agents data preparation\n",
    "other_order_data = order_data[order_data['sold_to_customer'].isin(partners_data['sold_to_customer'])]\n",
    "other_order_data = other_order_data.merge(partners_data, left_on='sold_to_customer', right_on='sold_to_customer', how='left')\n",
    "other_order_data = other_order_data.filter(regex='^(?!.*_y)')\n",
    "# Exclude '_x' from all column names\n",
    "other_order_data.columns = other_order_data.columns.str.replace('_x', '')\n",
    "other_order_data = other_order_data.loc[:, order_columns]\n",
    "# Update values in columns based on the specific value\n",
    "other_order_data.loc[other_order_data['indirect_direct'] == 'Direct', 'tier'] = 'Channel Partner'\n",
    "other_order_data.loc[other_order_data['indirect_direct'] == 'Direct', 'tier_new'] = 'Channel Partner'\n",
    "other_order_data.loc[other_order_data['indirect_direct'] == 'Direct', 'type'] = 'Agent'\n",
    "\n",
    "direct_order_data = order_data[~order_data['sold_to_customer'].isin(partners_data['sold_to_customer'])]\n",
    "wdf['sold_to_customer'] = wdf['sold_to_customer'].astype(str)\n",
    "direct_order_data = direct_order_data.merge(wdf, left_on='sold_to_customer', right_on='sold_to_customer', how='left')\n",
    "direct_order_data = direct_order_data.filter(regex='^(?!.*_y)')\n",
    "# Exclude '_x' from all column names\n",
    "direct_order_data.columns = direct_order_data.columns.str.replace('_x', '')\n",
    "direct_order_data = direct_order_data.loc[:, order_columns]\n",
    "\n",
    "print('should be = 0: ', len(other_order_data) + len(direct_order_data) + len(agents_order_data) + len(so_order_data) - len(dfc))\n",
    "print('should ~ 0 :', round((other_order_data.order_intake_amount_eur.sum() + direct_order_data.order_intake_amount_eur.sum() + agents_order_data.order_intake_amount_eur.sum() + so_order_data.order_intake_amount_eur.sum() - dfc.order_intake_amount_eur.sum()), 2))\n",
    "\n",
    "print('combining all the sales records ... processing...')\n",
    "\n",
    "# combining all the sales records\n",
    "full_data = pd.concat([direct_order_data, other_order_data, agents_order_data, so_order_data])\n",
    "full_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# for testing purposes I keep this lines\n",
    "full_data_df = full_data.copy()\n",
    "\n",
    "print('should ~ 0 :', round((full_data.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "print('cleaning other division products ... processing...')\n",
    "\n",
    "#clean other division products\n",
    "\n",
    "# define a list of products which I want to mark separetely\n",
    "product_list = data_file.tm_product_list\n",
    "tm_threshold = 0.9\n",
    "\n",
    "# define total sum of orders for each customer\n",
    "total_sum = full_data_df.groupby('customer_name')['order_intake_amount_eur'].sum()\n",
    "total_sum = total_sum.rename('total_OI')\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, total_sum, on='customer_name', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['total_OI'] = full_data_df['total_OI'].fillna(0)\n",
    "\n",
    "# Calculate the sum of sales for the products which I want to mark across all companies\n",
    "total_tm = full_data_df[full_data_df['bu2'].isin(product_list)].groupby('customer_name')['order_intake_amount_eur'].sum().reset_index()\n",
    "# Rename the 'order_intake_amount_eur' column to 'tm_sum'\n",
    "total_tm.rename(columns={'order_intake_amount_eur': 'tm_sum'}, inplace=True)\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, total_tm, on='customer_name', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['tm_sum'] = full_data_df['tm_sum'].fillna(0)\n",
    "\n",
    "# calculate the percentage of sales for the products in the list for each company\n",
    "full_data_df['tm_share'] = full_data_df['tm_sum'] / full_data_df['total_OI']\n",
    "full_data_df['tm_share'] = full_data_df['tm_share'].fillna(0)\n",
    "\n",
    "# label companies where the percentage of sales for all products in the list is greater than treshold value\n",
    "full_data_df['tm_check'] = 'no'\n",
    "full_data_df.loc[full_data_df['tm_share'] > tm_threshold, 'tm_check'] = 'yes'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "# marking special case\n",
    "\n",
    "special_one = data_file.special_one\n",
    "special_one_office = data_file.special_one_office\n",
    "# Filter the DataFrame based on the conditions\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] == special_one_office) , 'tm_check'] = 'no'\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] != special_one_office) , 'tier'] = 'Independent Sales Company'\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] != special_one_office) , 'tier_new'] = 'Independent Sales Company'\n",
    "full_data_df.loc[(full_data_df['customer_name'] == special_one) & (full_data_df['company_code_n'] != special_one_office) , 'type'] = 'Trading Firm'\n",
    "\n",
    "special_two = data_file.special_two\n",
    "special_two_file_name = data_file.special_two_file_name\n",
    "\n",
    "# Filter the DataFrame based on the conditions\n",
    "# Convert 'data' column to datetime format\n",
    "full_data_df['FY'] = pd.to_datetime(full_data_df['FY'])\n",
    "\n",
    "special_two_so = pd.read_excel(special_two_file_name)\n",
    "condition_a = full_data_df['sales_person_n'] != special_two\n",
    "condition_b = full_data_df['sales_person_n'] == special_two\n",
    "condition_c = full_data_df['sales_order_so'].isin(special_two_so['sales_order_so'])\n",
    "condition_d = full_data_df['FY'].dt.year > 2022\n",
    "\n",
    "full_data_df.loc[(condition_b & condition_c)| (condition_b & condition_d) , 'customer_name'] = special_two.upper()\n",
    "full_data_df.loc[(condition_b & condition_c)| (condition_b & condition_d) , 'tier_new'] = 'Channel Partner'\n",
    "full_data_df.loc[(condition_b & condition_c)| (condition_b & condition_d) , 'tier'] = 'Channel Partner'\n",
    "full_data_df.loc[(condition_b & condition_c)| (condition_b & condition_d) , 'type'] = 'Agent'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "tm_exclusion_office = data_file.tm_exclusion_office\n",
    "special_three = data_file.special_three\n",
    "special_four = data_file.special_four\n",
    "special_five = data_file.special_five\n",
    "special_six = data_file.special_six\n",
    "special_six_office = data_file.special_six_office\n",
    "special_seven = data_file.special_seven\n",
    "\n",
    "# eclusion case for t&m \n",
    "exl_condition_a = (full_data_df['FY'].dt.year == 2022) | (full_data_df['FY'].dt.year == 2021)\n",
    "exl_condition_at = full_data_df['FY'].dt.year < 2023\n",
    "exl_condition_b = full_data_df['company_code_n'] != tm_exclusion_office\n",
    "exl_condition_c = full_data_df['tm_check'] == 'yes'\n",
    "exl_condition_d = full_data_df['sold_to_customer'] == special_three\n",
    "exl_condition_e = full_data_df['customer_name'] == special_four\n",
    "exl_condition_f = full_data_df['customer_name'] == special_five\n",
    "\n",
    "exl_condition_j = full_data_df['customer_name'] == special_six\n",
    "exl_condition_i = full_data_df['company_code_n'].isin(special_six_office)\n",
    "\n",
    "exl_condition_k = full_data_df['customer_name'].isin(special_seven)\n",
    "\n",
    "full_data_df.loc[ (exl_condition_a & exl_condition_e) | (exl_condition_a & exl_condition_f) | (exl_condition_a & exl_condition_b & exl_condition_c), 'tm_check'] = 'no'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "special_eight = data_file.special_eight[0]\n",
    "exl_condition_special_eight_name = full_data_df['customer_name'] == special_eight\n",
    "exl_condition_special_eight = full_data_df['FY'].dt.year > 2022\n",
    "\n",
    "full_data_df.loc[ exl_condition_special_eight_name & exl_condition_special_eight , 'tier_new'] = 'Indirect Business Partner'\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "# Define the desired column order\n",
    "column_order = ['sold_to_customer','customer_name', 'sold_to_customer_n', 'ec_eu_customer_n' , 'ec_eu_industry_n', 'company_code_n', 'countries', 'indirect_direct', 'tier', 'tier_new', 'type', 'year_month', 'FY', \n",
    "       'bu2', 'for_bu', 'sales_order_so', 'sales_person_n','order_intake_amount_eur', 'tm_check', 'tm_share']\n",
    "\n",
    "# Reorder the columns\n",
    "full_data_df = full_data_df[column_order]\n",
    "\n",
    "# other way to indentify T&M customers\n",
    "\n",
    "print('cleaning T&M division products ... processing...')\n",
    "\n",
    "#clean other division products\n",
    "\n",
    "# define a list of products which I want to mark separetely\n",
    "product_list = data_file.tm_product_list\n",
    "pers_tm_threshold = 0.5\n",
    "\n",
    "# define total sum of orders for each customer\n",
    "person_total_sum = full_data_df.groupby('sales_person_n')['order_intake_amount_eur'].sum()\n",
    "person_total_sum = person_total_sum.rename('person_total_OI')\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, person_total_sum, on='sales_person_n', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['person_total_OI'] = full_data_df['person_total_OI'].fillna(0)\n",
    "\n",
    "# Calculate the sum of sales for the products which I want to mark across all companies\n",
    "person_total_tm = full_data_df[full_data_df['bu2'].isin(product_list)].groupby('sales_person_n')['order_intake_amount_eur'].sum().reset_index()\n",
    "# Rename the 'order_intake_amount_eur' column to 'tm_sum'\n",
    "person_total_tm.rename(columns={'order_intake_amount_eur': 'pers_tm_sum'}, inplace=True)\n",
    "# Merge with the original DataFrame to include all products and companies\n",
    "full_data_df = pd.merge(full_data_df, person_total_tm, on='sales_person_n', how='left')\n",
    "# Fill NaN values in 'sum' column with '0'\n",
    "full_data_df['pers_tm_sum'] = full_data_df['pers_tm_sum'].fillna(0)\n",
    "\n",
    "# calculate the percentage of sales for the products in the list for each company\n",
    "full_data_df['pers_tm_share'] = full_data_df['pers_tm_sum'] / full_data_df['person_total_OI']\n",
    "full_data_df['pers_tm_share'] = full_data_df['pers_tm_share'].fillna(0)\n",
    "\n",
    "# label companies where the percentage of sales for all products in the list is greater than treshold value\n",
    "full_data_df['pers_tm_check'] = 'no'\n",
    "full_data_df.loc[full_data_df['pers_tm_share'] > pers_tm_threshold, 'pers_tm_check'] = 'yes'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "# Filter companies with only 'yes' values in column P\n",
    "filtered_companies = full_data_df[full_data_df['pers_tm_check'] == 'yes']['sold_to_customer'].tolist()\n",
    "filtered_companies_no = full_data_df[full_data_df['pers_tm_check'] == 'no']['sold_to_customer'].tolist()\n",
    "filtered_companies = [x for x in filtered_companies if x not in filtered_companies_no]\n",
    "filtered_companies = list(set(filtered_companies))\n",
    "\n",
    "full_data_df['pure tm'] = 'no'\n",
    "full_data_df.loc[full_data_df['sold_to_customer'].isin(filtered_companies), 'pure tm'] = 'yes'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "special_nine = data_file.special_nine\n",
    "add_condition_a = full_data_df['sold_to_customer'] == special_nine\n",
    "\n",
    "full_data_df.loc[add_condition_a, 'tm_check'] = 'no'\n",
    "full_data_df.loc[add_condition_a, 'pure tm'] = 'no'\n",
    "\n",
    "condition_one = full_data_df['tier'] == 'Independent Sales Company'\n",
    "condition_two = full_data_df['FY'].dt.year == 2022\n",
    "\n",
    "full_data_df.loc[condition_one & condition_two, 'pure tm'] = 'no'\n",
    "\n",
    "print('should ~ 0 :', round((full_data_df.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(full_data_df) - len(df_orders))\n",
    "\n",
    "# for procuts bu which are t&m orders it is necessary to set check to 'no' just to keep them \n",
    "print('excluding netsol from t&m...')\n",
    "condition_tm_yes = (full_data_df['tm_check'] == 'yes') & (full_data_df['pure tm'] == 'yes')\n",
    "full_data_df['bu2'] = full_data_df['bu2'].astype(str)\n",
    "condition_target_bu = full_data_df['bu2'].isin(target_bu)\n",
    "\n",
    "full_data_df.loc[condition_tm_yes & condition_target_bu, ['tm_check', 'pure tm']] = 'no'\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional country data addition\n",
    "\n",
    "rs_df = pd.read_excel('data_files/rs_data.xlsx')\n",
    "# Convert the date column to datetime type\n",
    "rs_df['year_month'] = pd.to_datetime(rs_df['year_month'])\n",
    "rs_df['m_num'] = rs_df['year_month'].dt.strftime('%m')\n",
    "# Create a new column 'month_year' with the desired format \"202003\"\n",
    "rs_df['year_month'] = rs_df['year_month'].dt.strftime('%Y%m')\n",
    "rs_df['m_num'] = rs_df['m_num'].astype(int)\n",
    "\n",
    "def apply_shift(value):\n",
    "    if value >= 4:\n",
    "        return value - 3\n",
    "    else:\n",
    "        return value + 9\n",
    "    \n",
    "# Apply the shift to 'm_num 4'\n",
    "rs_df['m_num'] = rs_df['m_num'].apply(apply_shift)\n",
    "\n",
    "\n",
    "temp = full_data_df.copy()\n",
    "\n",
    "temp['year_month'] = temp['year_month'].astype(str)\n",
    "temp['m_num'] = temp['year_month'].str[-2:].astype(int)\n",
    "temp['m_num'] = temp['m_num'].apply(apply_shift)\n",
    "\n",
    "temp = pd.concat([temp, rs_df])\n",
    "\n",
    "temp = temp[['sold_to_customer', 'customer_name', 'sold_to_customer_n',\n",
    "       'ec_eu_customer_n', 'ec_eu_industry_n', 'company_code_n', 'countries', 'indirect_direct',\n",
    "       'tier_new', 'type', 'year_month', 'm_num', 'FY', 'bu2', 'for_bu',\n",
    "       'sales_order_so', 'sales_person_n', 'order_intake_amount_eur',\n",
    "       'tm_check', 'pure tm']]\n",
    "\n",
    "print('should ~ 0 :', round((temp.order_intake_amount_eur.sum() - df_orders.order_intake_amount_eur.sum() - rs_df.order_intake_amount_eur.sum()), 2))\n",
    "print('should = 0 :', len(temp) - len(df_orders) - len(rs_df))\n",
    "\n",
    "full_oi_data_df_final = temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_bu_dict_df = temp.copy()\n",
    "for_bu_dict_df = for_bu_dict_df.dropna(subset='bu2')\n",
    "\n",
    "# Create a dictionary\n",
    "mapping_dict_bu2 = {}\n",
    "\n",
    "# Group by 'for_bu' and find the most frequent 'bu2' value\n",
    "for bu, group in for_bu_dict_df.groupby('for_bu'):\n",
    "    most_frequent_bu2 = group['bu2'].value_counts().idxmax()\n",
    "    mapping_dict_bu2[bu] = most_frequent_bu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb853a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "temp = full_oi_data_df_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a45b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preparation of target values...')\n",
    "\n",
    "# add budget information\n",
    "targets = pd.read_excel('data_files/outcome/target.xlsx')\n",
    "targets['order_intake_amount_eur'] = 0\n",
    "# Convert the 'FY' column to datetime format\n",
    "targets['FY'] = pd.to_datetime(targets['FY'], format='%d-%m-%Y')\n",
    "\n",
    "b = targets['target_order_intake_amount_eur'].sum()\n",
    "\n",
    "years = targets['FY'].dt.year.unique().tolist()\n",
    "\n",
    "for year in years:\n",
    "    b = b - targets[targets['FY'].dt.year == year]['target_order_intake_amount_eur'].sum()\n",
    "    \n",
    "print('should be 0: ', b)\n",
    "\n",
    "zero_results_df = pd.DataFrame(columns=targets.columns)\n",
    "targets_without = targets.copy()\n",
    "partner_list = targets['customer_name'].unique().tolist()\n",
    "\n",
    "temp['target_order_intake_amount_eur'] = 0\n",
    "temp = pd.concat([temp, targets], ignore_index=True)\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    targets_without = targets_without.reset_index(drop=True)\n",
    "    \n",
    "    year = year - 1\n",
    "\n",
    "    # Filter dataframe for the specified year and company list\n",
    "    filtered_df = temp[(temp['FY'].dt.year == year) & (temp['customer_name'].isin(partner_list))]\n",
    "    \n",
    "    # Group by partners and sum their sales results\n",
    "    grouped = filtered_df.groupby('customer_name')['order_intake_amount_eur'].sum()\n",
    "    \n",
    "    # Identify partners with a summed sales result of 0\n",
    "    partners_with_zero_sales = grouped[grouped == 0].index.tolist()\n",
    "    \n",
    "    # in case of some partners which have several types of partnership\n",
    "    grouped_2 = filtered_df.groupby(['customer_name', 'type'])['order_intake_amount_eur'].sum()\n",
    "    double_types = grouped_2[grouped_2 == 0].index.tolist()\n",
    "    \n",
    "    double_types_companies = [d[0] for d in double_types]\n",
    "    additional_companies = [company for company in double_types_companies if company not in partners_with_zero_sales]\n",
    "    \n",
    "\n",
    "    if len(additional_companies) > 0:\n",
    "        found_additional = [tup for tup in double_types if any(element in tup for element in additional_companies)]\n",
    "\n",
    "        # Create a mask to filter rows based on the list of found_additional\n",
    "        mask = [(row['customer_name'], row['type']) in found_additional for _, row in targets_without.iterrows()]\n",
    "        additional_df = targets_without[mask]\n",
    "\n",
    "        targets_without = targets_without[~pd.Series(mask)]\n",
    "    \n",
    "    else:\n",
    "        additional_df = pd.DataFrame(columns=targets_without.columns)\n",
    "    \n",
    "    partners_with_zero_sales = partners_with_zero_sales + [p for p in partner_list if p not in filtered_df['customer_name'].unique().tolist()]\n",
    "    \n",
    "    condition1 = targets_without['customer_name'].isin(partners_with_zero_sales)\n",
    "    condition2 = targets_without['FY'].dt.year == (year+1)\n",
    "    \n",
    "    targets_mod = targets_without[condition1 & condition2]\n",
    "\n",
    "    zero_results_df = pd.concat([zero_results_df, targets_mod, additional_df], ignore_index=True)\n",
    "    \n",
    "    condition3 = targets_without['customer_name'].isin(partners_with_zero_sales)\n",
    "    \n",
    "    targets_without = targets_without[~(condition3 & condition2)]\n",
    "    \n",
    "print('should be 0:', targets['target_order_intake_amount_eur'].sum() - targets_without['target_order_intake_amount_eur'].sum() - zero_results_df['target_order_intake_amount_eur'].sum())\n",
    "\n",
    "zero_results_df.loc[zero_results_df['type'] != 'VAR', 'for_bu'] = 'Transmitters'\n",
    "zero_results_df.loc[zero_results_df['type'] == 'VAR', 'for_bu'] = 'Systems&ADS'\n",
    "\n",
    "\n",
    "bu_list = ['Flowmeters', 'Services', 'Others', 'Netsol', 'Analytics',\n",
    "       'Transmitters', 'Systems&ADS', 'T&M']\n",
    "\n",
    "# Create an empty dataframe to store updated rows\n",
    "df_targets_updated = pd.DataFrame(columns=targets.columns)\n",
    "\n",
    "# For each row in targets_without\n",
    "for index, row in targets_without.iterrows():\n",
    "    # Repeat the current row N times\n",
    "    new_rows = pd.concat([row] * len(bu_list), axis=1).transpose()\n",
    "    \n",
    "    # Replace the 'bu_n' column values with bu_n_list values\n",
    "    new_rows['for_bu'] = bu_list\n",
    "    \n",
    "    # Append these new rows to df_updated\n",
    "    df_targets_updated = pd.concat([df_targets_updated, new_rows], ignore_index=True)\n",
    "    \n",
    "for year in years:\n",
    "    list_of_types = df_targets_updated['type'].unique().tolist()\n",
    "    for typ in list_of_types:\n",
    "        list_of_partners = df_targets_updated.loc[(df_targets_updated['type'] == typ) & (df_targets_updated['FY'].dt.year == year), 'customer_name'].unique().tolist()\n",
    "        for partner in list_of_partners:\n",
    "            total_share = 0\n",
    "            for bu in bu_list:\n",
    "                result_bu = temp[(temp['type'] == typ) & (temp['customer_name'] == partner) & (temp['FY'].dt.year == (year-1)) & (temp['for_bu'] == bu)]['order_intake_amount_eur'].sum()\n",
    "                result_total = temp[(temp['type'] == typ) & (temp['customer_name'] == partner) & (temp['FY'].dt.year == (year-1))]['order_intake_amount_eur'].sum()\n",
    "                # Check for zero to avoid division by zero or NaN results\n",
    "                if result_total != 0:\n",
    "                    share = float(result_bu / result_total)\n",
    "                else:\n",
    "                    share = 0  # or whatever default value you'd like\n",
    "                total_share = total_share + share\n",
    "                current_amount = df_targets_updated.loc[(df_targets_updated['customer_name'] == partner) & (df_targets_updated['type'] == typ) & (df_targets_updated['FY'].dt.year == year) & (df_targets_updated['for_bu'] == bu), 'target_order_intake_amount_eur']\n",
    "                df_targets_updated.loc[(df_targets_updated['customer_name'] == partner) & (df_targets_updated['type'] == typ) & (df_targets_updated['FY'].dt.year == year) & (df_targets_updated['for_bu'] == bu), 'target_order_intake_amount_eur'] = current_amount * share\n",
    "            if round(total_share,0) != 1:\n",
    "                print(year, partner, total_share)\n",
    "            \n",
    "# Filter out rows where target_order_intake_amount_eur is 0\n",
    "df_targets_updated = df_targets_updated[df_targets_updated['target_order_intake_amount_eur'] != 0]\n",
    "            \n",
    "targets_final = pd.concat([df_targets_updated, zero_results_df], ignore_index=True)\n",
    "\n",
    "print('should be 0:', round((targets_final['target_order_intake_amount_eur'].sum() - targets['target_order_intake_amount_eur'].sum()), 0))\n",
    "\n",
    "# Map the values using the dictionary\n",
    "targets_final['bu2'] = targets_final['for_bu'].map(mapping_dict_bu2)\n",
    "      \n",
    "temp['target_order_intake_amount_eur'] = 0\n",
    "temp = pd.concat([temp, targets_final], ignore_index=True)\n",
    "      \n",
    "print('preparation of target values... additional numbers to initial target file')\n",
    "\n",
    "opco_list = temp['company_code_n'].unique().tolist()\n",
    "\n",
    "#result_chp_opcos = {}\n",
    "result_isc_opcos = {}\n",
    "result_ibp_opcos = {}\n",
    "\n",
    "def getresult(df, opco, bu_list):\n",
    "    bu_res_dict_isc = {}\n",
    "    bu_res_dict_ibp = {}\n",
    "    \n",
    "    for bu in bu_list:\n",
    "    \n",
    "        # addition of target numbers for two business tiers\n",
    "        #condition_chp = df['tier_new'] == 'Channel Partner'\n",
    "        condition_isc = df['tier_new'] == 'Independent Sales Company'\n",
    "        condition_ibp = df['tier_new'] == 'Indirect Business Partner'\n",
    "        condition_tm = (df['tm_check'] == 'no') & (df['pure tm'] == 'no')\n",
    "        condition_bu = df['for_bu'] == bu\n",
    "\n",
    "\n",
    "        #opco_result_chp = df[ (df['company_code_n'] == opco) & (df['FY'].dt.year == 2022) & condition_chp & condition_tm]['order_intake_amount_eur'].sum()\n",
    "        #opco_target_chp = df[ (df['company_code_n'] == opco) & (df['FY'].dt.year == 2023) & condition_chp & condition_tm]['target_order_intake_amount_eur'].sum()\n",
    "\n",
    "        #opco_target_chp_should_be_by_month = (round(opco_result_chp * 1.1, -3) - opco_target_chp) / 12\n",
    "        #opco_target_chp_should_be_by_month = round(opco_target_chp_should_be_by_month, -3)\n",
    "\n",
    "        opco_result_isc = df[ (df['company_code_n'] == opco) & (df['FY'].dt.year == 2022) & condition_isc & condition_tm & condition_bu]['order_intake_amount_eur'].sum()\n",
    "        opco_target_isc = df[ (df['company_code_n'] == opco) & (df['FY'].dt.year == 2023) & condition_isc & condition_tm & condition_bu]['target_order_intake_amount_eur'].sum()\n",
    "\n",
    "        opco_target_isc_should_be_by_month = (round(opco_result_isc * 1.1, -3) - opco_target_isc) / 12\n",
    "        opco_target_isc_should_be_by_month = round(opco_target_isc_should_be_by_month, -3)\n",
    "\n",
    "        opco_result_ibp = df[(df['company_code_n'] == opco) & (df['FY'].dt.year == 2022) & condition_ibp & condition_tm & condition_bu]['order_intake_amount_eur'].sum()\n",
    "        opco_target_ibp = df[(df['company_code_n'] == opco) & (df['FY'].dt.year == 2023) & condition_ibp & condition_tm & condition_bu]['target_order_intake_amount_eur'].sum()\n",
    "\n",
    "        opco_target_ibp_should_be_by_month = (round(opco_result_ibp * 1.1, -3) - opco_target_ibp) / 12\n",
    "        opco_target_ibp_should_be_by_month = round(opco_target_ibp_should_be_by_month, -3)\n",
    "        \n",
    "        bu_res_dict_isc[bu] = opco_target_isc_should_be_by_month\n",
    "        bu_res_dict_ibp[bu] = opco_target_ibp_should_be_by_month\n",
    "    \n",
    "    return bu_res_dict_isc, bu_res_dict_ibp # opco_target_chp_should_be_by_month, \n",
    "\n",
    "\n",
    "for opco in opco_list:\n",
    "    #result_chp_opcos[opco] = getresult(temp, opco)[0]\n",
    "    result_isc_opcos[opco] = getresult(temp, opco, bu_list)[0]\n",
    "    result_ibp_opcos[opco] = getresult(temp, opco, bu_list)[1]\n",
    "    \n",
    "fy_23 =  [202304, 202305, 202306, 202307, 202308, 202309, 202310, 202311, 202312, 202401, 202402, 202403]\n",
    "month_num =  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "list_of_df_isc = []\n",
    "\n",
    "for key, d_value in result_isc_opcos.items():\n",
    "    for sub_key, sub_value in d_value.items():\n",
    "        isc_target_df = pd.DataFrame(columns=temp.columns)\n",
    "        isc_target_df.loc[0, 'company_code_n'] = key\n",
    "        isc_target_df.loc[0, 'tier_new'] = 'Independent Sales Company'\n",
    "        isc_target_df.loc[0, 'tier'] = 'Independent Sales Company'\n",
    "        isc_target_df.loc[0, 'pure tm'] = 'no'\n",
    "        isc_target_df.loc[0, 'tm_check'] = 'no'\n",
    "        isc_target_df.loc[0, 'for_bu'] = sub_key\n",
    "        isc_target_df.loc[0, 'target_order_intake_amount_eur'] = sub_value\n",
    "        isc_target_df.loc[0, 'order_intake_amount_eur'] = 0\n",
    "        isc_target_df = pd.concat([isc_target_df] * 12, ignore_index=True)\n",
    "        isc_target_df['year_month'] = fy_23\n",
    "        isc_target_df['m_num'] = month_num\n",
    "        isc_target_df['FY'] = temp['FY'][temp['FY'].dt.year == 2023].unique()\n",
    "        list_of_df_isc.append(isc_target_df)\n",
    "\n",
    "full_isc_target_df = pd.DataFrame(columns=temp.columns)\n",
    "    \n",
    "for idf in list_of_df_isc:\n",
    "    full_isc_target_df = pd.concat([full_isc_target_df, idf], ignore_index=True)\n",
    "    \n",
    "\n",
    "list_df_ibp = []\n",
    "\n",
    "for key, d_value in result_ibp_opcos.items():\n",
    "    for sub_key, sub_value in d_value.items():\n",
    "        ibp_target_df = pd.DataFrame(columns=temp.columns)\n",
    "        ibp_target_df.loc[0, 'company_code_n'] = key\n",
    "        ibp_target_df.loc[0, 'tier_new'] = 'Indirect Business Partner'\n",
    "        ibp_target_df.loc[0, 'tier'] = 'Indirect Business Partner'\n",
    "        ibp_target_df.loc[0, 'pure tm'] = 'no'\n",
    "        ibp_target_df.loc[0, 'tm_check'] = 'no'\n",
    "        ibp_target_df.loc[0, 'for_bu'] = sub_key\n",
    "        ibp_target_df.loc[0, 'target_order_intake_amount_eur'] = sub_value\n",
    "        ibp_target_df.loc[0, 'order_intake_amount_eur'] = 0\n",
    "        ibp_target_df = pd.concat([ibp_target_df] * 12, ignore_index=True)\n",
    "        ibp_target_df['year_month'] = fy_23\n",
    "        ibp_target_df['m_num'] = month_num\n",
    "        ibp_target_df['FY'] = temp['FY'][temp['FY'].dt.year == 2023].unique()\n",
    "        list_df_ibp.append(ibp_target_df)\n",
    "\n",
    "full_ibp_target_df = pd.DataFrame(columns=temp.columns)\n",
    "    \n",
    "for idf in list_df_ibp:\n",
    "    full_ibp_target_df = pd.concat([full_ibp_target_df, idf], ignore_index=True)\n",
    "      \n",
    "#temp = pd.concat([temp, full_chp_target_df])\n",
    "\n",
    "temp = pd.concat([temp, full_isc_target_df])\n",
    "temp = pd.concat([temp, full_ibp_target_df])\n",
    "temp = temp.reset_index(drop=True)\n",
    "\n",
    "condition_tm = (temp['tm_check'] == 'no') & (temp['pure tm'] == 'no')\n",
    "\n",
    "temp = temp[['sold_to_customer', 'customer_name', 'sold_to_customer_n',\n",
    "       'ec_eu_customer_n', 'ec_eu_industry_n', 'company_code_n', 'countries', 'indirect_direct', \n",
    "       'tier_new', 'type', 'year_month', 'FY', 'bu2', 'for_bu',\n",
    "       'sales_order_so', 'sales_person_n', 'order_intake_amount_eur',\n",
    "        'target_order_intake_amount_eur', 'm_num', 'tm_check','pure tm']]\n",
    "\n",
    "# Create a pivot table from the DataFrame\n",
    "temp_b = temp.copy()\n",
    "temp_b['FY'] = temp_b['FY'].dt.year\n",
    "pivot_table1 = temp_b.pivot_table(index='tier_new', columns='FY', values='order_intake_amount_eur', aggfunc='sum')\n",
    "pivot_table2 = temp_b.pivot_table(index='tier_new', columns='FY', values='target_order_intake_amount_eur', aggfunc='sum')\n",
    "\n",
    "# Create a dictionary mapping sold_to_customer values to corresponding countries\n",
    "df_customers['sold_to_customer'] = df_customers['sold_to_customer'].astype(str)\n",
    "customer_country_map = df_customers.set_index('sold_to_customer')['countries'].to_dict()\n",
    "\n",
    "# Fill missing values in temp_df['countries'] using the mapping dictionary\n",
    "temp['countries'] = temp['countries'].fillna(temp['sold_to_customer'].map(customer_country_map))\n",
    "\n",
    "last_df = temp.copy()\n",
    "\n",
    "last_df['sold_to_customer'] = last_df['sold_to_customer'].fillna('900000000')\n",
    "last_df['customer_name'] = last_df['customer_name'].fillna('For Budget')\n",
    "\n",
    "df = temp.copy()\n",
    "# Step 1: Group by 'country_code_n' and find the most frequent country for each group\n",
    "most_frequent_countries = df.groupby('company_code_n')['countries'].agg(lambda x: x.value_counts().idxmax())\n",
    "# Step 2: Convert the pandas Series to a dictionary\n",
    "country_code_to_country = most_frequent_countries.to_dict()\n",
    "# Step 2: Fill empty values in the 'countries' column using the dictionary\n",
    "last_df['countries'] = last_df['countries'].fillna(last_df['company_code_n'].map(country_code_to_country))\n",
    "\n",
    "last_df['type'] = last_df['type'].fillna('For Budget')\n",
    "last_df['bu2'] = last_df['bu2'].fillna(last_df['for_bu'].map(mapping_dict_bu2))\n",
    "last_df['indirect_direct'] = last_df['indirect_direct'].fillna('Indirect')\n",
    "\n",
    "print('preparation of the data file with overall results for sending...')\n",
    "\n",
    "# preparation of the file with results\n",
    "condition_tm = (last_df['tm_check'] == 'no') & (last_df['pure tm'] == 'no')\n",
    "condition_date = last_df['FY'].dt.year >= 2022\n",
    "\n",
    "for_file = last_df[condition_tm & condition_date]\n",
    "for_file = for_file[['sold_to_customer', 'customer_name', 'sold_to_customer_n',\n",
    "       'ec_eu_customer_n', 'ec_eu_industry_n', 'company_code_n', 'countries', 'indirect_direct',\n",
    "       'tier_new', 'type', 'year_month', 'FY', 'bu2', 'for_bu',\n",
    "       'sales_order_so', 'sales_person_n', 'order_intake_amount_eur',\n",
    "       'target_order_intake_amount_eur', 'm_num']]\n",
    "\n",
    "# Define a mapping dictionary for month abbreviations\n",
    "month_map = {\n",
    "    1: '1-Apr', 2: '2-May', 3: '3-Jun', 4: '4-Jul',\n",
    "    5: '5-Aug', 6: '6-Sep', 7: '7-Oct', 8: '8-Nov',\n",
    "    9: '9-Dec', 10: '10-Jan', 11: '11-Feb', 12: '12-Mar'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'm_num' column\n",
    "for_file['m_num'] = for_file['m_num'].map(month_map)\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0b5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write previous pivot\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/last_pivot_{year_month}.xlsx')\n",
    "pivot_table1.to_excel(writer, sheet_name='pivot')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding difference between last data and new\n",
    "last_pivot = pd.read_excel(f'data_files/outcome/last_pivot.xlsx')\n",
    "\n",
    "last_pivot = last_pivot.set_index('tier_new')\n",
    "last_pivot= last_pivot.round(2)\n",
    "\n",
    "pivot_table = pivot_table1.reset_index()\n",
    "pivot_table = pivot_table.set_index('tier_new')\n",
    "pivot_table = pivot_table.round(2)\n",
    "\n",
    "pivot_table - last_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = last_df.copy()\n",
    "\n",
    "temp_so_checker = temp[['sales_order_so', 'sold_to_customer', 'customer_name', 'indirect_direct',\n",
    "       'tier_new', 'type', 'FY', 'order_intake_amount_eur', 'company_code_n', 'countries']]\n",
    "\n",
    "temp_so_checker = temp_so_checker[temp_so_checker['sold_to_customer'] != 999999999]\n",
    "temp_so_checker['sum_column'] = temp_so_checker.groupby(['sales_order_so' , 'tier_new'])['order_intake_amount_eur'].transform('sum')\n",
    "temp_so_checker = temp_so_checker.sort_values(by=['FY','sum_column'], ascending=[False, False])\n",
    "temp_so_checker = temp_so_checker.reset_index(drop='True')\n",
    "temp_so_checker = temp_so_checker.drop_duplicates(subset='sales_order_so', keep='first')\n",
    "\n",
    "# Step 1: Count unique values in the column\n",
    "value_counts = temp_so_checker['sales_order_so'].value_counts()\n",
    "\n",
    "# Step 2: Filter values that occur more than once\n",
    "values_gt_one = value_counts[value_counts > 1]\n",
    "\n",
    "print('should be empty', values_gt_one)\n",
    "\n",
    "temp_so_checker = temp_so_checker[['sales_order_so', 'sold_to_customer', 'customer_name', 'indirect_direct', 'tier_new', 'type', 'company_code_n', 'countries']]\n",
    "\n",
    "temp_so_checker = temp_so_checker.dropna(subset='sales_order_so')\n",
    "\n",
    "# Group by 'sales_order_so' and select the first occurrence of each column within each group\n",
    "mapped_data = temp.groupby('sales_order_so').agg({\n",
    "    'sold_to_customer': 'first',\n",
    "    'customer_name': 'first',\n",
    "    'company_code_n': 'first',\n",
    "    'countries': 'first',\n",
    "    'indirect_direct': 'first',\n",
    "    'tier_new': 'first',\n",
    "    'type': 'first', 'tm_check': 'first', 'pure tm': 'first'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3c6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn3 = sqlite3.connect('data_files/sales_database.db')\n",
    "query = \"SELECT * FROM sales\"\n",
    "df_sales = pd.read_sql_query(query, conn3)\n",
    "conn3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc36b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_mapped_df = df_sales.merge(mapped_data, on='sales_order_so', how='left', suffixes=('_X', ''))\n",
    "\n",
    "sales_mapped = sales_mapped_df[~sales_mapped_df['sold_to_customer'].isna()]\n",
    "sales_not_mapped = sales_mapped_df[sales_mapped_df['sold_to_customer'].isna()]\n",
    "\n",
    "print('Should be 0:', len(df_sales) - len(sales_mapped) - len(sales_not_mapped))\n",
    "\n",
    "sales_not_mapped = sales_not_mapped[['fiscal_year', 'year_month', 'company_code_n_X', 'sales_order_so', 'bu',\n",
    "       'bu_n', 'sales_person', 'sales_person_n', 'sold_to_customer_n_latest',\n",
    "       'sold_to_customer_X', 'sold_to_customer_n', 'sold_to_country_n',\n",
    "       'ec_eu_customer', 'ec_eu_customer_n', 'ec_eu_country_n',\n",
    "       'eu_industry_segment_n_latest', 'ship_to_customer', 'ship_to_customer_n',\n",
    "       'ship_to_country_n', 'ST', 'GP', 'Source']]\n",
    "\n",
    "\n",
    "sales_not_mapped['pure tm'] = 'no'\n",
    "sales_not_mapped.loc[sales_not_mapped['sold_to_customer_X'].isin(filtered_companies), 'pure tm'] = 'yes'\n",
    "sales_not_mapped['tm_check'] = 'no'\n",
    "\n",
    "sales_not_mapped = sales_not_mapped.dropna(subset='sold_to_customer_X')\n",
    "sales_not_mapped = sales_not_mapped.rename(columns={'sold_to_customer_X': 'sold_to_customer'})\n",
    "sales_not_mapped['sold_to_customer'] = sales_not_mapped['sold_to_customer'].astype(int)\n",
    "sales_not_mapped['sold_to_customer'] = sales_not_mapped['sold_to_customer'].astype(str)\n",
    "\n",
    "wdf_copy = wdf[['sold_to_customer', 'company_code_n',\n",
    "        'customer_name', \n",
    "       'indirect_direct', 'channel', 'type', 'Horn', \n",
    "       'tier_new', 'countries']]\n",
    "\n",
    "sales_not_mapped_merged = sales_not_mapped.merge(wdf_copy, on='sold_to_customer', how='inner', suffixes=('_X', ''))\n",
    "sales_not_mapped_out = sales_not_mapped.merge(wdf_copy, on='sold_to_customer', how='outer', suffixes=('_X', ''), indicator=True)\n",
    "\n",
    "print('lost lines:', len(sales_not_mapped) - len(sales_not_mapped_merged), 'lost sum', sales_not_mapped_out[sales_not_mapped_out['_merge'] == 'left_only']['ST'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c49f2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "comp_temp = sales_not_mapped_out[sales_not_mapped_out['_merge'] == 'left_only']\n",
    "\n",
    "# write previous pivot\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/comp_temp_{year_month}.xlsx')\n",
    "comp_temp.to_excel(writer, sheet_name='comp_temp')\n",
    "writer.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4661327",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_not_mapped = sales_not_mapped_merged.copy()\n",
    "\n",
    "sales_mapped['FY'] = pd.to_datetime(sales_mapped['fiscal_year'], format='%Y')   \n",
    "#sales_mapped['m_num'] = sales_mapped['FY'].dt.month\n",
    "sales_mapped['bu2'] = sales_mapped['bu'].astype(str)\n",
    "sales_mapped['bu2'] = sales_mapped['bu2'].str.strip()\n",
    "sales_mapped = sales_mapped.merge(bu_defin, how='left' )\n",
    "sales_mapped = sales_mapped[['sold_to_customer', 'customer_name', 'sold_to_customer_n',\n",
    "       'ec_eu_customer_n', 'eu_industry_segment_n_latest', 'company_code_n', 'countries', 'indirect_direct',\n",
    "       'tier_new', 'type', 'year_month', 'FY', 'bu2', 'for_bu',\n",
    "       'sales_order_so', 'sales_person_n', 'ST', 'GP', 'tm_check', 'pure tm']]\n",
    "\n",
    "\n",
    "sales_not_mapped['FY'] = pd.to_datetime(sales_not_mapped['fiscal_year'], format='%Y')\n",
    "#sales_not_mapped['m_num'] = sales_not_mapped['FY'].dt.month\n",
    "sales_not_mapped['bu2'] = sales_not_mapped['bu'].astype(str)\n",
    "sales_not_mapped['bu2'] = sales_not_mapped['bu2'].str.strip()\n",
    "sales_not_mapped = sales_not_mapped.merge(bu_defin, how='left' )\n",
    "sales_not_mapped = sales_not_mapped[['sold_to_customer', 'customer_name', 'sold_to_customer_n',\n",
    "       'ec_eu_customer_n', 'eu_industry_segment_n_latest', 'company_code_n', 'countries', 'indirect_direct',\n",
    "       'tier_new', 'type', 'year_month', 'FY', 'bu2', 'for_bu',\n",
    "       'sales_order_so', 'sales_person_n', 'ST', 'GP', 'tm_check', 'pure tm']]\n",
    "\n",
    "\n",
    "sales_mapped_df = pd.concat([sales_mapped, sales_not_mapped], ignore_index=True)\n",
    "\n",
    "def apply_shift(value):\n",
    "    if value >= 4:\n",
    "        return value - 3\n",
    "    else:\n",
    "        return value + 9\n",
    "    \n",
    "sales_mapped_df['m_num'] = sales_mapped_df['year_month'].astype(str)\n",
    "sales_mapped_df['m_num'] = sales_mapped_df['m_num'].str[-2:].astype(int)\n",
    "sales_mapped_df['m_num'] = sales_mapped_df['m_num'].apply(apply_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3383952",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_mapped_df_save = sales_mapped_df.copy()\n",
    "last_df_save = last_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d22f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "slsdf = sales_mapped_df_save.copy()\n",
    "ordf = last_df_save.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c503f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION OF THE DATA FILE WITH INDUSTRIES\n",
    "so_industries_init = pd.read_excel('data_files/industries.xlsx')\n",
    "\n",
    "so_industries = so_industries_init.copy()\n",
    "\n",
    "so_industries.columns = ['sales_order_so', 'industry', 'segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72593154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ordf['sales_order_so'] = ordf['sales_order_so'].apply(lambda x: \"{:.0f}\".format(x))\n",
    "ordf['sales_order_so'] = ordf['sales_order_so'].astype(str)\n",
    "slsdf['sales_order_so'] = slsdf['sales_order_so'].apply(lambda x: \"{:.0f}\".format(x))\n",
    "slsdf['sales_order_so'] = slsdf['sales_order_so'].astype(str)\n",
    "\n",
    "so_industries['sales_order_so'] = so_industries['sales_order_so'].astype(str)\n",
    "\n",
    "last_df_m = ordf.merge(so_industries, how='left')\n",
    "print(len(last_df) - len(last_df_m))\n",
    "sales_mapped_df_m = slsdf.merge(so_industries, how='left')\n",
    "print(len(sales_mapped_df) - len(sales_mapped_df_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "445855e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_df_m['bu2'] = last_df_m['bu2'].astype(str)\n",
    "last_df_m = last_df_m[last_df_m['bu2'].isin(target_bu)]\n",
    "last_df_m = last_df_m[last_df_m['FY'].dt.year >= 2020]\n",
    "\n",
    "sales_mapped_df_m['bu2'] = sales_mapped_df_m['bu2'].astype(str)\n",
    "sales_mapped_df_m = sales_mapped_df_m[sales_mapped_df_m['bu2'].isin(target_bu)]\n",
    "sales_mapped_df_m = sales_mapped_df_m[sales_mapped_df_m['FY'].dt.year >= 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ce71d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write previous pivot\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/df_with_industries_{year_month}.xlsx')\n",
    "last_df_m.to_excel(writer, sheet_name='orders')\n",
    "sales_mapped_df_m.to_excel(writer, sheet_name='sales')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff504e9",
   "metadata": {},
   "source": [
    "Making file for Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3dc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_tm = (sales_mapped_df['tm_check'] == 'no') & (sales_mapped_df['pure tm'] == 'no')\n",
    "sales_mapped_df = sales_mapped_df[condition_tm]\n",
    "\n",
    "df = last_df.copy()\n",
    "condition_tm = (df['tm_check'] == 'no') & (df['pure tm'] == 'no')\n",
    "df = df[condition_tm]\n",
    "\n",
    "# Group by the relevant columns and aggregate the sum values\n",
    "grouped_df = df.groupby(['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu']) \\\n",
    "                    .agg(order_intake_amount_eur=('order_intake_amount_eur', 'sum'),\n",
    "                         target_order_intake_amount_eur=('target_order_intake_amount_eur', 'sum')) \\\n",
    "                    .reset_index()\n",
    "\n",
    "# Create the new DataFrame with the specified columns\n",
    "new_df = grouped_df[['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'order_intake_amount_eur', 'target_order_intake_amount_eur']]\n",
    "\n",
    "# Group by the relevant columns and aggregate the sum values\n",
    "grouped_df_2 = sales_mapped_df.groupby(['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu']) \\\n",
    "                    .agg(sales_amount_eur=('ST', 'sum'),\n",
    "                         gross_profit_amount_eur=('GP', 'sum')) \\\n",
    "                    .reset_index()\n",
    "\n",
    "# Create the new DataFrame with the specified columns\n",
    "new_df_2 = grouped_df_2[['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'sales_amount_eur', 'gross_profit_amount_eur']]\n",
    "\n",
    "full_results_dataframe = pd.concat([new_df, new_df_2], ignore_index=True)\n",
    "\n",
    "# Columns to fill with NaN values\n",
    "columns_to_fill = ['order_intake_amount_eur', 'target_order_intake_amount_eur', 'sales_amount_eur', 'gross_profit_amount_eur']\n",
    "\n",
    "# Fill NaN values in the specified columns with 0\n",
    "full_results_dataframe[columns_to_fill] = full_results_dataframe[columns_to_fill].fillna(0)\n",
    "\n",
    "full_results_dataframe = full_results_dataframe.rename(columns={'sold_to_customer': 'ID', 'company_code_n':'OPCO', 'customer_name':'Partner Name', 'tier_new':'Tier','type':'Type', 'countries':'Country', \n",
    "                                                                'order_intake_amount_eur':'Order Intake',\n",
    "                                                               'target_order_intake_amount_eur':'Target Order Intake',\n",
    "                                                               'sales_amount_eur': 'Sales',\n",
    "                                                               'gross_profit_amount_eur': 'Gross Profit'})\n",
    "\n",
    "\n",
    "countries_to_exclude = ['New Caledonia', 'Brazil', 'Singapore', 'Utd.Arab Emir.', 'USA', 'China']\n",
    "full_results_dataframe = full_results_dataframe[~full_results_dataframe['Country'].isin(countries_to_exclude)]\n",
    "\n",
    "full_results_dataframe = full_results_dataframe[full_results_dataframe['OPCO'] != 'RYG']\n",
    "\n",
    "full_results_dataframe.loc[full_results_dataframe['Country'] == 'Bosnia-Herz.', 'Country'] = 'Bosnia-Herzegovina'\n",
    "full_results_dataframe.loc[full_results_dataframe['Country'] == 'Bosnia', 'Country'] = 'Bosnia-Herzegovina'\n",
    "\n",
    "full_results_dataframe['year_month'] = full_results_dataframe['year_month'].astype(str)\n",
    "\n",
    "full_results_dataframe['temp'] = pd.to_datetime(full_results_dataframe['year_month'], format='%Y%m')\n",
    "\n",
    "# Shift the dates back by three months using the pandas DateOffset\n",
    "full_results_dataframe['temp'] = full_results_dataframe['temp'] - pd.DateOffset(months=3)\n",
    "\n",
    "full_results_dataframe['temp'] = pd.to_datetime(full_results_dataframe['temp'], format='%Y-%m-%d')\n",
    "full_results_dataframe['FY'] = full_results_dataframe['temp']\n",
    "\n",
    "full_results_dataframe.drop('temp', axis=1, inplace=True)\n",
    "\n",
    "# Group the DataFrame by the specified columns and calculate the sum for the desired columns\n",
    "grouped_df = full_results_dataframe.groupby(by=['OPCO', 'Partner Name', 'Country', 'Tier', 'Type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu'])[['Order Intake',\n",
    "                                                                    'Target Order Intake',\n",
    "                                                                    'Sales',\n",
    "                                                                    'Gross Profit']].sum().reset_index()\n",
    "\n",
    "# Filter the DataFrame to keep only rows with 'Tier' = 'Direct'\n",
    "direct_df = grouped_df[grouped_df['Tier'] == 'Direct']\n",
    "indirect_df = grouped_df[~(grouped_df['Tier'] == 'Direct')]\n",
    "\n",
    "# for additional list direct customers\n",
    "direct_df_ad = direct_df.copy()\n",
    "direct_df_ad['FY'] = direct_df_ad['FY'].dt.year\n",
    "\n",
    "direct_df_for_the_list = direct_df_ad.groupby(by=['OPCO', 'Partner Name', 'Country', 'Type', 'FY'])['Order Intake'].sum().reset_index()\n",
    "# Sort the DataFrame\n",
    "direct_df_for_the_list = direct_df_for_the_list.sort_values(by=['FY', 'Order Intake'], ascending=[False, False])\n",
    "\n",
    "# Drop duplicates based on the specified columns and keep the first occurrence\n",
    "direct_df_for_the_list = direct_df_for_the_list.drop_duplicates(subset=['OPCO', 'Partner Name', 'Country', 'Type'], keep='first')\n",
    "direct_df_for_the_list = direct_df_for_the_list[['OPCO', 'Partner Name', 'Country', 'Type']]\n",
    "# Calculate the quantity of rows in the DataFrame\n",
    "num_rows = len(direct_df_for_the_list)\n",
    "# Create a new column with values 1, 2, 3, 4\n",
    "direct_df_for_the_list['Number'] = range(1, num_rows + 1)\n",
    "\n",
    "# Group the 'direct_df' by the specified columns and calculate the sum for the desired columns\n",
    "direct_grouped_df = direct_df.groupby(['OPCO', 'Country', 'FY', 'year_month', 'm_num','bu2','for_bu']).agg({\n",
    "    'Order Intake': 'sum',\n",
    "    'Target Order Intake': 'sum',\n",
    "    'Sales': 'sum',\n",
    "    'Gross Profit': 'sum',\n",
    "    'Partner Name': lambda x: 'Direct_customers',  # Set 'Direct_name' for all 'Partner Name's\n",
    "    'Type': lambda x: 'Direct_type',           # Set 'Direct_name' for all 'Type's\n",
    "\n",
    "    'Tier': lambda x: 'Direct'\n",
    "}).reset_index()\n",
    "\n",
    "#'bu2': lambda x: 'combined',\n",
    "\n",
    "\n",
    "tableau_df = pd.concat([direct_grouped_df, indirect_df], ignore_index=True)\n",
    "\n",
    "tableau_df = tableau_df[['OPCO', 'Partner Name', 'Country', 'Tier', 'Type', 'FY',\n",
    "       'year_month', 'm_num', 'bu2', 'for_bu', 'Order Intake',\n",
    "       'Target Order Intake', 'Sales', 'Gross Profit']]\n",
    "\n",
    "\n",
    "# Define a mapping dictionary for month abbreviations\n",
    "month_map = {\n",
    "    1: '1-Apr', 2: '2-May', 3: '3-Jun', 4: '4-Jul',\n",
    "    5: '5-Aug', 6: '6-Sep', 7: '7-Oct', 8: '8-Nov',\n",
    "    9: '9-Dec', 10: '10-Jan', 11: '11-Feb', 12: '12-Mar'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'm_num' column\n",
    "tableau_df['m_num'] = tableau_df['m_num'].map(month_map)\n",
    "\n",
    "# Define the list of columns for which all values should be equal to 0\n",
    "columns_to_check = ['Order Intake', 'Target Order Intake', 'Sales', 'Gross Profit']\n",
    "\n",
    "# Use boolean indexing to filter out the rows where all the specified columns have 0 values\n",
    "tableau_df = tableau_df[~(tableau_df[columns_to_check] == 0).all(axis=1)]\n",
    "\n",
    "print(len(tableau_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb8914b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is some partners with double opcos, it is necessary to correct them\n",
    "final_r = data_file.final_r\n",
    "final_b = data_file.final_b\n",
    "# change BG\n",
    "tableau_df.loc[tableau_df['OPCO'] == final_b, 'OPCO'] = final_r\n",
    "\n",
    "for_types_changes = tableau_df[tableau_df['Tier'] == 'Channel Partner']\n",
    "# Group by 'Partner Name' and filter groups with count greater than 1 in 'OPCO'\n",
    "result = for_types_changes.groupby('Partner Name').filter(lambda x: len(x['OPCO'].unique()) > 1)\n",
    "# Get the unique companies from the result\n",
    "unique_companies = result['Partner Name'].unique()\n",
    "for_changing = for_types_changes[for_types_changes['Partner Name'].isin(unique_companies)]\n",
    "for_changing = for_changing[for_changing['FY'].dt.year > 2021]\n",
    "\n",
    "# Group by 'Partner Name' and 'OPCO', aggregate the sum of 'Order Intake'\n",
    "opco_sum = for_changing.groupby(['Partner Name', 'OPCO'])['Order Intake'].sum().reset_index()\n",
    "\n",
    "# Find the index of the maximum 'Order Intake' sum for each 'Partner Name'\n",
    "idx = opco_sum.groupby('Partner Name')['Order Intake'].idxmax()\n",
    "\n",
    "# Select the corresponding rows from 'opco_sum'\n",
    "max_opco_per_partner = opco_sum.loc[idx]\n",
    "\n",
    "# Create the new DataFrame with 'Partner Name' and the corresponding 'OPCO'\n",
    "result_df = max_opco_per_partner[['Partner Name', 'OPCO']]\n",
    "\n",
    "# Creating the mapping dictionary\n",
    "mapping_dict_opcos = {}\n",
    "for index, row in result_df.iterrows():\n",
    "    mapping_dict_opcos[row['Partner Name']] = row['OPCO']\n",
    "    \n",
    "# Update 'OPCO' column based on conditions and mapping dictionary\n",
    "for partner, opco in mapping_dict_opcos.items():\n",
    "    tableau_df.loc[(tableau_df['Partner Name'] == partner) & (tableau_df['Tier'] == 'Channel Partner'), 'OPCO'] = opco\n",
    "    \n",
    "final_c_one = data_file.final_c_one\n",
    "final_c = data_file.final_c\n",
    "final_t_one = data_file.final_t_one\n",
    "final_t = data_file.final_t\n",
    "final_nl_one = data_file.final_nl_one\n",
    "final_nl = data_file.final_nl\n",
    "\n",
    "final_p_one = data_file.final_p_one\n",
    "final_p = data_file.final_p\n",
    "\n",
    "condition_c = tableau_df['Partner Name'] == final_c_one\n",
    "condition_t = tableau_df['Partner Name'] == final_t_one\n",
    "condition_p = tableau_df['Partner Name'] == final_p_one\n",
    "condition_nl = tableau_df['Partner Name'] == final_nl_one\n",
    "\n",
    "tableau_df.loc[condition_c, 'OPCO'] = final_c\n",
    "tableau_df.loc[condition_t, 'OPCO'] = final_t\n",
    "tableau_df.loc[condition_p, 'OPCO'] = final_p\n",
    "tableau_df.loc[condition_nl, 'OPCO'] = final_nl\n",
    "\n",
    "# write tableau_df\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/Indirect Business Data Set.xlsx')\n",
    "tableau_df.to_excel(writer, sheet_name='full', index=False)\n",
    "direct_df_for_the_list.to_excel(writer, sheet_name='direct', index=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d7230c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time, minutes: -16.4\n"
     ]
    }
   ],
   "source": [
    "print('process time, minutes:', round((now - datetime.now()).total_seconds() / 60,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21a3375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_date = tableau_df['FY'].dt.year >= 2022\n",
    "\n",
    "tableau_df_for_file = tableau_df[condition_date]\n",
    "\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/results_{year_month}.xlsx')\n",
    "# Save each DataFrame to a separate sheet in the same file\n",
    "for_file.to_excel(writer, sheet_name='results', index=False)\n",
    "tableau_df_for_file.to_excel(writer, sheet_name='tableau', index=False)\n",
    "#pivot_table1.to_excel(writer, sheet_name='pivot')\n",
    "#pivot_table2.to_excel(writer, sheet_name='pivot2')\n",
    "# Save the file\n",
    "writer.close()\n",
    "\n",
    "# automated sending the data\n",
    "output_file_path = data_file.output_file_path\n",
    "send_to = data_file.send_to \n",
    "send_to = \"; \".join(send_to)\n",
    "\n",
    "\n",
    "output_file = output_file_path + r'\\results_' + str(year_month) + '.xlsx'\n",
    "\n",
    "# Get today's date\n",
    "current_date = date.today()\n",
    "\n",
    "# Convert date object to string\n",
    "date = str(current_date)\n",
    "\n",
    "#----------------------------------\n",
    "#Sending the email\n",
    "#Below all is to send email\n",
    "#construct outlook application instance\n",
    "olApp = win32.Dispatch('Outlook.Application')\n",
    "olNS = olApp.GetNamespace('MAPI')\n",
    "\n",
    "#construct the email item object\n",
    "mailItem = olApp.CreateItem(0)\n",
    "mailItem.Subject = date + \" Result Report\"\n",
    "mailItem.BodyFormat = 1\n",
    "mailItem.Body = \"Dear John,\\nWith this letter, I am sending the results data in an Excel table, updated as of today. This dataset is the basis of our Dashboard. Also, please note that this letter has been generated automatically.\\nBest Regards, Alexey Gukov\"\n",
    "mailItem.To = send_to\n",
    "mailItem.Attachments.Add(output_file)\n",
    "#Show email\n",
    "mailItem.Display()\n",
    "\n",
    "#Execute to send email\n",
    "mailItem.Send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2df84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_file_to_folders(source_file, target_folders):\n",
    "    for folder in target_folders:\n",
    "        destination = os.path.join(folder, os.path.basename(source_file))\n",
    "        shutil.copy2(source_file, destination)\n",
    "        print(f\"File '{source_file}' copied to '{destination}'\")\n",
    "\n",
    "# Example usage\n",
    "source_folder = 'data_files/outcome/'\n",
    "source_file = os.path.join(source_folder, 'Indirect Business Data Set.xlsx')\n",
    "\n",
    "print(source_file)\n",
    "\n",
    "target_folders = [\n",
    "    'Z:',\n",
    "]\n",
    "\n",
    "\n",
    "copy_file_to_folders(source_file, target_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLEAU WITH INDUSTRIES only for KEY BU\n",
    "\n",
    "sales_mapped_df = sales_mapped_df_m.copy()\n",
    "\n",
    "condition_tm = (sales_mapped_df['tm_check'] == 'no') & (sales_mapped_df['pure tm'] == 'no')\n",
    "sales_mapped_df['bu2'] = sales_mapped_df['bu2'].astype(str)\n",
    "sales_mapped_df = sales_mapped_df[sales_mapped_df['bu2'].isin(target_bu)]\n",
    "sales_mapped_df = sales_mapped_df[condition_tm]\n",
    "\n",
    "df = last_df_m.copy()\n",
    "df['bu2'] = df['bu2'].astype(str)\n",
    "df = df[df['bu2'].isin(target_bu)]\n",
    "condition_tm = (df['tm_check'] == 'no') & (df['pure tm'] == 'no')\n",
    "df = df[condition_tm]\n",
    "\n",
    "# Group by the relevant columns and aggregate the sum values\n",
    "grouped_df = df.groupby(['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment']) \\\n",
    "                    .agg(order_intake_amount_eur=('order_intake_amount_eur', 'sum'),\n",
    "                         target_order_intake_amount_eur=('target_order_intake_amount_eur', 'sum')) \\\n",
    "                    .reset_index()\n",
    "\n",
    "# Create the new DataFrame with the specified columns\n",
    "new_df = grouped_df[['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment', 'order_intake_amount_eur', 'target_order_intake_amount_eur']]\n",
    "\n",
    "# Group by the relevant columns and aggregate the sum values\n",
    "grouped_df_2 = sales_mapped_df.groupby(['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment']) \\\n",
    "                    .agg(sales_amount_eur=('ST', 'sum'),\n",
    "                         gross_profit_amount_eur=('GP', 'sum')) \\\n",
    "                    .reset_index()\n",
    "\n",
    "# Create the new DataFrame with the specified columns\n",
    "new_df_2 = grouped_df_2[['company_code_n', 'sold_to_customer', 'customer_name', 'countries', 'tier_new', 'type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment', 'sales_amount_eur', 'gross_profit_amount_eur']]\n",
    "\n",
    "full_results_dataframe = pd.concat([new_df, new_df_2], ignore_index=True)\n",
    "\n",
    "# Columns to fill with NaN values\n",
    "columns_to_fill = ['order_intake_amount_eur', 'target_order_intake_amount_eur', 'sales_amount_eur', 'gross_profit_amount_eur']\n",
    "\n",
    "# Fill NaN values in the specified columns with 0\n",
    "full_results_dataframe[columns_to_fill] = full_results_dataframe[columns_to_fill].fillna(0)\n",
    "\n",
    "full_results_dataframe = full_results_dataframe.rename(columns={'sold_to_customer': 'ID', 'company_code_n':'OPCO', 'customer_name':'Partner Name', 'tier_new':'Tier','type':'Type', 'countries':'Country', \n",
    "                                                                'order_intake_amount_eur':'Order Intake',\n",
    "                                                               'target_order_intake_amount_eur':'Target Order Intake',\n",
    "                                                               'sales_amount_eur': 'Sales',\n",
    "                                                               'gross_profit_amount_eur': 'Gross Profit'})\n",
    "\n",
    "\n",
    "countries_to_exclude = ['New Caledonia', 'Brazil', 'Singapore', 'Utd.Arab Emir.', 'USA', 'China']\n",
    "full_results_dataframe = full_results_dataframe[~full_results_dataframe['Country'].isin(countries_to_exclude)]\n",
    "\n",
    "full_results_dataframe = full_results_dataframe[full_results_dataframe['OPCO'] != 'RYG']\n",
    "\n",
    "full_results_dataframe.loc[full_results_dataframe['Country'] == 'Bosnia-Herz.', 'Country'] = 'Bosnia-Herzegovina'\n",
    "full_results_dataframe.loc[full_results_dataframe['Country'] == 'Bosnia', 'Country'] = 'Bosnia-Herzegovina'\n",
    "\n",
    "full_results_dataframe['year_month'] = full_results_dataframe['year_month'].astype(str)\n",
    "\n",
    "full_results_dataframe['temp'] = pd.to_datetime(full_results_dataframe['year_month'], format='%Y%m')\n",
    "\n",
    "# Shift the dates back by three months using the pandas DateOffset\n",
    "full_results_dataframe['temp'] = full_results_dataframe['temp'] - pd.DateOffset(months=3)\n",
    "\n",
    "full_results_dataframe['temp'] = pd.to_datetime(full_results_dataframe['temp'], format='%Y-%m-%d')\n",
    "full_results_dataframe['FY'] = full_results_dataframe['temp']\n",
    "\n",
    "full_results_dataframe.drop('temp', axis=1, inplace=True)\n",
    "\n",
    "# Group the DataFrame by the specified columns and calculate the sum for the desired columns\n",
    "grouped_df = full_results_dataframe.groupby(by=['OPCO', 'Partner Name', 'Country', 'Tier', 'Type', 'FY', 'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment'])[['Order Intake',\n",
    "                                                                    'Target Order Intake',\n",
    "                                                                    'Sales',\n",
    "                                                                    'Gross Profit']].sum().reset_index()\n",
    "\n",
    "# Filter the DataFrame to keep only rows with 'Tier' = 'Direct'\n",
    "direct_df = grouped_df[grouped_df['Tier'] == 'Direct']\n",
    "indirect_df = grouped_df[~(grouped_df['Tier'] == 'Direct')]\n",
    "\n",
    "# Group the 'direct_df' by the specified columns and calculate the sum for the desired columns\n",
    "direct_grouped_df = direct_df.groupby(['OPCO', 'Country', 'FY', 'year_month', 'm_num','bu2','for_bu', 'industry', 'segment']).agg({\n",
    "    'Order Intake': 'sum',\n",
    "    'Target Order Intake': 'sum',\n",
    "    'Sales': 'sum',\n",
    "    'Gross Profit': 'sum',\n",
    "    'Partner Name': lambda x: 'Direct_customers',  # Set 'Direct_name' for all 'Partner Name's\n",
    "    'Type': lambda x: 'Direct_type',           # Set 'Direct_name' for all 'Type's\n",
    "\n",
    "    'Tier': lambda x: 'Direct'\n",
    "}).reset_index()\n",
    "\n",
    "#'bu2': lambda x: 'combined',\n",
    "\n",
    "\n",
    "tableau_df = pd.concat([direct_grouped_df, indirect_df], ignore_index=True)\n",
    "\n",
    "tableau_df = tableau_df[['OPCO', 'Partner Name', 'Country', 'Tier', 'Type', 'FY',\n",
    "       'year_month', 'm_num', 'bu2', 'for_bu', 'industry', 'segment', 'Order Intake',\n",
    "       'Target Order Intake', 'Sales', 'Gross Profit']]\n",
    "\n",
    "\n",
    "# Define a mapping dictionary for month abbreviations\n",
    "month_map = {\n",
    "    1: '1-Apr', 2: '2-May', 3: '3-Jun', 4: '4-Jul',\n",
    "    5: '5-Aug', 6: '6-Sep', 7: '7-Oct', 8: '8-Nov',\n",
    "    9: '9-Dec', 10: '10-Jan', 11: '11-Feb', 12: '12-Mar'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'm_num' column\n",
    "tableau_df['m_num'] = tableau_df['m_num'].map(month_map)\n",
    "\n",
    "# Define the list of columns for which all values should be equal to 0\n",
    "columns_to_check = ['Order Intake', 'Target Order Intake', 'Sales', 'Gross Profit']\n",
    "\n",
    "# Use boolean indexing to filter out the rows where all the specified columns have 0 values\n",
    "tableau_df = tableau_df[~(tableau_df[columns_to_check] == 0).all(axis=1)]\n",
    "\n",
    "print(len(tableau_df))\n",
    "\n",
    "# there is some partners with double opcos, it is necessary to correct them\n",
    "final_r = data_file.final_r\n",
    "final_b = data_file.final_b\n",
    "# change BG\n",
    "tableau_df.loc[tableau_df['OPCO'] == final_b, 'OPCO'] = final_r\n",
    "\n",
    "for_types_changes = tableau_df[tableau_df['Tier'] == 'Channel Partner']\n",
    "# Group by 'Partner Name' and filter groups with count greater than 1 in 'OPCO'\n",
    "result = for_types_changes.groupby('Partner Name').filter(lambda x: len(x['OPCO'].unique()) > 1)\n",
    "# Get the unique companies from the result\n",
    "unique_companies = result['Partner Name'].unique()\n",
    "for_changing = for_types_changes[for_types_changes['Partner Name'].isin(unique_companies)]\n",
    "for_changing = for_changing[for_changing['FY'].dt.year > 2021]\n",
    "\n",
    "# Group by 'Partner Name' and 'OPCO', aggregate the sum of 'Order Intake'\n",
    "opco_sum = for_changing.groupby(['Partner Name', 'OPCO'])['Order Intake'].sum().reset_index()\n",
    "\n",
    "# Find the index of the maximum 'Order Intake' sum for each 'Partner Name'\n",
    "idx = opco_sum.groupby('Partner Name')['Order Intake'].idxmax()\n",
    "\n",
    "# Select the corresponding rows from 'opco_sum'\n",
    "max_opco_per_partner = opco_sum.loc[idx]\n",
    "\n",
    "# Create the new DataFrame with 'Partner Name' and the corresponding 'OPCO'\n",
    "result_df = max_opco_per_partner[['Partner Name', 'OPCO']]\n",
    "\n",
    "# Creating the mapping dictionary\n",
    "mapping_dict_opcos = {}\n",
    "for index, row in result_df.iterrows():\n",
    "    mapping_dict_opcos[row['Partner Name']] = row['OPCO']\n",
    "    \n",
    "# Update 'OPCO' column based on conditions and mapping dictionary\n",
    "for partner, opco in mapping_dict_opcos.items():\n",
    "    tableau_df.loc[(tableau_df['Partner Name'] == partner) & (tableau_df['Tier'] == 'Channel Partner'), 'OPCO'] = opco\n",
    "    \n",
    "final_c_one = data_file.final_c_one\n",
    "final_c = data_file.final_c\n",
    "final_t_one = data_file.final_t_one\n",
    "final_t = data_file.final_t\n",
    "final_nl_one = data_file.final_nl_one\n",
    "final_nl = data_file.final_nl\n",
    "\n",
    "final_p_one = data_file.final_p_one\n",
    "final_p = data_file.final_p\n",
    "\n",
    "condition_c = tableau_df['Partner Name'] == final_c_one\n",
    "condition_t = tableau_df['Partner Name'] == final_t_one\n",
    "condition_p = tableau_df['Partner Name'] == final_p_one\n",
    "condition_nl = tableau_df['Partner Name'] == final_nl_one\n",
    "\n",
    "tableau_df.loc[condition_c, 'OPCO'] = final_c\n",
    "tableau_df.loc[condition_t, 'OPCO'] = final_t\n",
    "tableau_df.loc[condition_p, 'OPCO'] = final_p\n",
    "tableau_df.loc[condition_nl, 'OPCO'] = final_nl\n",
    "\n",
    "# write tableau_df\n",
    "writer = pd.ExcelWriter(f'data_files/outcome/Indirect Business Data Set with Industires.xlsx')\n",
    "tableau_df.to_excel(writer, sheet_name='full', index=False)\n",
    "direct_df_for_the_list.to_excel(writer, sheet_name='direct', index=False)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
