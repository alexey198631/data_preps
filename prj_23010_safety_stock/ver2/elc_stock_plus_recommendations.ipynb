{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d87bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read elc stock data into a dataframe\n",
    "elc_stock_df = pd.read_excel('data_files/elc_stock.xlsx')\n",
    "\n",
    "# manufacturing information\n",
    "manuf = pd.read_excel('data_files/manuf.xlsx')\n",
    "manuf['Model Number'] = manuf['Model Number'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3a6f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_reserve = elc_stock_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "532f7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df = elc_stock_df_reserve.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e16155ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df['MS Code'] = elc_stock_df['MS Code'].fillna(elc_stock_df['Material'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f9ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where column MS Code is NaN\n",
    "elc_stock_df = elc_stock_df.dropna(subset=['MS Code'])\n",
    "elc_stock_df['MS Code'] = elc_stock_df['MS Code'].astype(str)\n",
    "elc_stock_df['Material'] = elc_stock_df['Material'].astype(str)\n",
    "elc_stock_df['BU'] = elc_stock_df['Product hierarchy'].str.slice(stop=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "152c1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df = elc_stock_df.merge(manuf, left_on='Material', right_on='Model Number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca10b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df = elc_stock_df[elc_stock_df['Material'].str.contains('_00') | (elc_stock_df['Current Free Stock for Ordering OpCo'] != 0) | (elc_stock_df['Safety Stock'] != 0)]\n",
    "\n",
    "\n",
    "elc_stock_df_l = elc_stock_df.loc[:, ['MS Code', 'Manuf.', 'BU', 'Current Free Stock for Ordering OpCo', 'Safety Stock']]\n",
    "#elc_stock_df_l = elc_stock_df_l.loc[(elc_stock_df_l['Current Free Stock for Ordering OpCo'] != 0) | (elc_stock_df_l['Safety Stock'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9645b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where column MS Code is NaN\n",
    "elc_stock_df_l = elc_stock_df_l.dropna(subset=['MS Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c5af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_bu = ['YY112', 'YY113', 'YY114', 'YY115', 'YY116', 'YY117','YY118', 'YY119', 'YY138']\n",
    "\n",
    "elc_stock_df_l = elc_stock_df_l[elc_stock_df_l['BU'].isin(key_bu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ad196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l = elc_stock_df_l[~elc_stock_df_l['MS Code'].str.contains('BOP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837b814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l = elc_stock_df_l.sort_values(by='Safety Stock', ascending=False)\n",
    "elc_stock_df_l = elc_stock_df_l.drop_duplicates(subset='MS Code', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d526f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to an Excel file\n",
    "elc_stock_df_l.to_excel('data_files/output3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58be23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read orders data\n",
    "orders = pd.read_excel('data_files/orders_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e480e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff4e4b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "530636"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2e206f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'ms_code' contains text with 'BOP'\n",
    "orders_df['ms_code'] = orders_df['ms_code'].astype(str)\n",
    "orders_df = orders_df[~orders_df['ms_code'].str.contains('BOP')]\n",
    "\n",
    "# Delete rows where 'ms_code' contains text with 'ENT'\n",
    "orders_df['ms_code'] = orders_df['ms_code'].astype(str)\n",
    "orders_df = orders_df[~orders_df['ms_code'].str.contains('ENT')]\n",
    "\n",
    "# Delete rows where both column 'a' and column 'b' values are 0\n",
    "#orders_df = orders_df.loc[(orders_df['order_intake_quantity'] != 0) | (orders_df['order_intake_EUR'] != 0)]\n",
    "\n",
    "#key_opcos = ['YEF-G', 'YEF-A', 'YEF-CH']\n",
    "key_bu = ['YY112', 'YY113', 'YY114', 'YY115', 'YY116', 'YY117','YY118', 'YY119', 'YY138']\n",
    "\n",
    "# Keep rows where column 'd' values match the list of values\n",
    "#orders_df = orders_df[orders_df['company_code_n'].isin(key_opcos)]\n",
    "\n",
    "# Keep rows where column 'd' values match the list of values\n",
    "orders_df = orders_df[orders_df['bu'].isin(key_bu)]\n",
    "orders_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc2230bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add grouping tag for 5 month\n",
    "\n",
    "monthes = [201804, 201805, 201806, 201807,\n",
    "       201808, 201809, 201810, 201811, 201812, 201901, 201902, 201903,\n",
    "       201904, 201905, 201906, 201907, 201908, 201909, 201910, 201911,\n",
    "       201912, 202001, 202002, 202003, 202004, 202005, 202006, 202007,\n",
    "       202008, 202009, 202010, 202011, 202012, 202101, 202102, 202103,\n",
    "       202104, 202105, 202106, 202107, 202108, 202212, 202204, 202112,\n",
    "       202109, 202303, 202210, 202203, 202211, 202207, 202208, 202205,\n",
    "       202209, 202111, 202301, 202206, 202201, 202202, 202110, 202302]\n",
    "\n",
    "monthes = sorted(monthes)\n",
    "\n",
    "orders_df_for_five = orders_df[orders_df['year_month'].isin(monthes)]\n",
    "# Sort the column in ascending order\n",
    "orders_df_for_five = orders_df_for_five.sort_values('year_month')\n",
    "# Map each month to its group\n",
    "month_to_group = {month: (i // 5) + 1 for i, month in enumerate(monthes)}\n",
    "# Assign groups to 'monthes' in the DataFrame\n",
    "orders_df_for_five['5_month'] = orders_df_for_five['year_month'].map(month_to_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "359f0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ analysis\n",
    "\n",
    "def mean_std_from_first_nonzero(row):\n",
    "    # Find the index of the first non-zero value in the row\n",
    "    nonzero_indices = np.nonzero(row.values[1:])[0]\n",
    "    if len(nonzero_indices) > 0:\n",
    "        first_nonzero_index = nonzero_indices[0] + 1  # Add 1 to account for the fact that we started at the second column\n",
    "        mean = row.iloc[first_nonzero_index:].mean()  # Calculate the mean of the remaining values\n",
    "        std = row.iloc[first_nonzero_index:].std()  # Calculate the standard deviation of the remaining values\n",
    "        return pd.Series({'Mean': mean, 'Std': std})  # Return the mean and standard deviation as a Series\n",
    "    else:\n",
    "        return pd.Series({'Mean': 0, 'Std': 0})  # If all values are zero, return 0 for mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2803feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table for ms_code for each month with NaN values filled with 0\n",
    "pivot_table_month = pd.pivot_table(orders_df, values='order_intake_quantity', index='ms_code', columns='year_month_date', aggfunc='sum', fill_value=0) # margins=True , fill_value=0\n",
    "pivot_table_month.reset_index(inplace=True)\n",
    "# sort the pivot table by the total column in descending order\n",
    "#pivot_table_month = pivot_table_month.sort_values(by='All', ascending=False)\n",
    "\n",
    "pivot_table_half_year = pd.pivot_table(orders_df, values='order_intake_quantity', index='ms_code', columns=['FY', 'half_year'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_year.reset_index(inplace=True)\n",
    "\n",
    "pivot_table_half_quarter = pd.pivot_table(orders_df, values='order_intake_quantity', index='ms_code', columns=['FY', 'quarter'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_quarter.reset_index(inplace=True)\n",
    "\n",
    "pivot_table_five_month = pd.pivot_table(orders_df_for_five, values='order_intake_quantity', index='ms_code', columns=['5_month'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_five_month.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Calculate the sum of the last year for different pivots\n",
    "last_12_sum = pivot_table_month.iloc[:, -12:].sum(axis=1)\n",
    "last_2_sum = pivot_table_half_year.iloc[:, -2:].sum(axis=1)\n",
    "last_4_sum = pivot_table_half_quarter.iloc[:, -4:].sum(axis=1)\n",
    "last_f5_sum = pivot_table_five_month.iloc[:, -2:].sum(axis=1)\n",
    "\n",
    "\n",
    "# Select the rows where the sum is greater than 0\n",
    "pivot_table_month = pivot_table_month[last_12_sum > 0]\n",
    "pivot_table_month.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year[last_2_sum > 0]\n",
    "pivot_table_half_year.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter[last_4_sum > 0]\n",
    "pivot_table_half_quarter.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_five_month = pivot_table_five_month[last_f5_sum > 0]\n",
    "pivot_table_five_month.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# calculate mean and std deviation for each product from the first month where it was sold\n",
    "# Apply the function to each row of the dataframe, and store the results in new columns\n",
    "pivot_table_month[['Mean_from_first', 'Std_from_first']] = pivot_table_month.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_year[['Mean_from_first_hy', 'Std_from_first_hy']] = pivot_table_half_year.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_quarter[['Mean_from_first_q', 'Std_from_first_q']] = pivot_table_half_quarter.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_five_month[['Mean_from_first_5m', 'Std_from_first_5m']] = pivot_table_five_month.apply(mean_std_from_first_nonzero, axis=1)\n",
    "\n",
    "\n",
    "# calculate mean and std deviation for each product\n",
    "df_mean = pivot_table_month.iloc[:, 1:].mean(axis=1)\n",
    "df_std = pivot_table_month.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_h = pivot_table_half_year.iloc[:, 1:].mean(axis=1)\n",
    "df_std_h = pivot_table_half_year.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_q = pivot_table_half_quarter.iloc[:, 1:].mean(axis=1)\n",
    "df_std_q = pivot_table_half_quarter.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_5m = pivot_table_five_month.iloc[:, 1:].mean(axis=1)\n",
    "df_std_5m = pivot_table_five_month.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "\n",
    "# categorize products based on std deviation\n",
    "df_category = pd.cut(df_std, bins=[-float('inf'), 0.5*pivot_table_month['Mean_from_first'].mean(), pivot_table_month['Mean_from_first'].mean(), float('inf')], labels=['Z', 'Y', 'X'])\n",
    "df_category_h = pd.cut(df_std_h, bins=[-float('inf'), 0.5*pivot_table_half_year['Mean_from_first_hy'].mean(), pivot_table_half_year['Mean_from_first_hy'].mean(), float('inf')], labels=['ZH', 'YH', 'XH'])\n",
    "df_category_q = pd.cut(df_std_q, bins=[-float('inf'), 0.5*pivot_table_half_quarter['Mean_from_first_q'].mean(), pivot_table_half_quarter['Mean_from_first_q'].mean(), float('inf')], labels=['ZQ', 'YQ', 'XQ'])\n",
    "df_category_5m = pd.cut(df_std_5m, bins=[-float('inf'), 0.5*pivot_table_five_month['Mean_from_first_5m'].mean(), pivot_table_five_month['Mean_from_first_5m'].mean(), float('inf')], labels=['Z5M', 'Y5M', 'X5M'])\n",
    "\n",
    "\n",
    "# add new columns to the original dataframe\n",
    "pivot_table_month = pivot_table_month.assign(Mean=df_mean, Std=df_std, Category=df_category)\n",
    "pivot_table_month = pivot_table_month.loc[:,['ms_code','Mean_from_first', 'Std_from_first', 'Mean', 'Std', 'Category']]\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year.assign(Mean_hy=df_mean_h, Std_hy=df_std_h, Category_hy=df_category_h)\n",
    "pivot_table_half_year = pivot_table_half_year.loc[:,['ms_code','Mean_from_first_hy', 'Std_from_first_hy', 'Mean_hy', 'Std_hy', 'Category_hy']]\n",
    "pivot_table_half_year = pivot_table_half_year.reset_index(level=0, drop=True)\n",
    "pivot_table_half_year.columns = pivot_table_half_year.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "pivot_table_five_month = pivot_table_five_month.assign(Mean_5m=df_mean_5m, Std_5m=df_std_5m, Category_5m=df_category_5m)\n",
    "pivot_table_five_month = pivot_table_five_month.loc[:,['ms_code','Mean_from_first_5m', 'Std_from_first_5m', 'Mean_5m', 'Std_5m', 'Category_5m']]\n",
    "pivot_table_five_month = pivot_table_five_month.reset_index(level=0, drop=True)\n",
    "pivot_table_five_month.columns = pivot_table_five_month.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.assign(Mean_q=df_mean_q, Std_q=df_std_q, Category_q=df_category_q)\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.loc[:,['ms_code','Mean_from_first_q', 'Std_from_first_q', 'Mean_q', 'Std_q', 'Category_q']]\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.reset_index(level=0, drop=True)\n",
    "pivot_table_half_quarter.columns = pivot_table_half_quarter.columns.get_level_values(0)\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/order_data_XYZ.xlsx')\n",
    "pivot_table_month.to_excel(writer, sheet_name='month')\n",
    "pivot_table_half_year.to_excel(writer, sheet_name='half year')\n",
    "pivot_table_half_quarter.to_excel(writer, sheet_name='quarter')\n",
    "pivot_table_five_month.to_excel(writer, sheet_name='5months')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e13b0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read price data\n",
    "prices = pd.read_excel('data_files/priced_positions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d8ef93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices= prices.loc[:, ['Model', 'COGS', 'Chk']]\n",
    "orders_df = orders_df.merge(prices, left_on='ms_code', right_on='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a0cdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_opt = orders_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ba095f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty dataframe\n",
    "final_df = pd.DataFrame()\n",
    "column_A = 'ABC_Group'\n",
    "value_A = 'A'\n",
    "column_x = 'Category_XYZ_5M' #Category_XYZ_HY\n",
    "value_X = 'X5M' #XH\n",
    "\n",
    "\n",
    "# ABC + XYZ analysis per bu\n",
    "\n",
    "# Create a new Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/order_data_ABC_XYZ_per_bu.xlsx')\n",
    "\n",
    "# Get a list of the unique 'bu' values\n",
    "bu_values = sorted(orders_data_opt['bu'].unique())\n",
    "\n",
    "# Loop over each 'bu' value\n",
    "for bu in bu_values:\n",
    "\n",
    "    # Filter the data for the current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu]\n",
    "    \n",
    "    # prices \n",
    "    \n",
    "    indexed_df = bu_df.set_index('ms_code')\n",
    "    ms_code_price = indexed_df['COGS'].to_dict()\n",
    "    ms_code_priced = pd.Series(ms_code_price)\n",
    "    \n",
    "    indexed_df_status = bu_df.set_index('ms_code')\n",
    "    ms_code_status = indexed_df['Chk'].to_dict()\n",
    "    ms_code_statused = pd.Series(ms_code_status)\n",
    "\n",
    "    # Group by 'ms_code' and calculate the total 'order_intake_EUR'\n",
    "    total_eur = bu_df.groupby('ms_code')['order_intake_EUR'].sum()\n",
    "    total_quant = bu_df.groupby('ms_code')['order_intake_quantity'].sum()\n",
    "\n",
    "    # Calculate the share of 'order_intake_EUR' for each 'ms_code'\n",
    "    eur_share = total_eur / total_eur.sum()\n",
    "\n",
    "    # Sort the 'ms_code' by descending 'order_intake_EUR'\n",
    "    sorted_ms = total_eur.sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted 'order_intake_EUR'\n",
    "    cumulative_sum = sorted_ms.cumsum()\n",
    "\n",
    "    # Calculate the percentage of the cumulative sum\n",
    "    cumulative_percent = cumulative_sum / total_eur.sum() * 100\n",
    "\n",
    "    # Categorize the 'ms_code' into ABC groups based on the cumulative percentage\n",
    "    abc_group = pd.cut(cumulative_percent, bins=[0, 70, 90, 100], labels=['A', 'B', 'C'])\n",
    "\n",
    "    # Create a new dataframe with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Total_EUR': total_eur,\n",
    "        'Share': eur_share,\n",
    "        'Cumulative_Sum_EUR': cumulative_sum,\n",
    "        'Cumulative_Percent': cumulative_percent,\n",
    "        'ABC_Group': abc_group,\n",
    "        'Quantity': total_quant,\n",
    "        'COGS': ms_code_priced,\n",
    "        'Status': ms_code_statused\n",
    "    })\n",
    "    \n",
    "\n",
    "    # Write the results to a new sheet in the Excel file\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df = results_df.rename(columns={'index': 'ms_code'})\n",
    "    results_df = results_df.merge(pivot_table_month[['ms_code', 'Mean_from_first', 'Std_from_first', 'Category']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df= results_df.merge(pivot_table_half_quarter[['ms_code', 'Mean_from_first_q', 'Std_from_first_q', 'Category_q']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df = results_df.merge(pivot_table_half_year[['ms_code', 'Mean_from_first_hy', 'Std_from_first_hy', 'Category_hy']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df = results_df.merge(pivot_table_five_month[['ms_code', 'Mean_from_first_5m', 'Std_from_first_5m', 'Category_5m']],\n",
    "                       on='ms_code', how='left')\n",
    "    \n",
    "    \n",
    "    abc_xyz = results_df.loc[:,['ms_code', 'Total_EUR', 'ABC_Group',  'Category', 'Quantity', 'Mean_from_first',\n",
    "       'Category_q', 'Mean_from_first_q', 'Category_hy', 'Mean_from_first_hy', 'Mean_from_first_5m', 'Std_from_first_5m', 'Category_5m', 'COGS', 'Status']]\n",
    "    \n",
    "    abc_xyz = abc_xyz.rename(columns={\n",
    "        'ms_code': 'Model',\n",
    "        'Mean_from_first': 'Mean',\n",
    "        'Category': 'Category_XYZ',\n",
    "        'Mean_from_first_q': 'Mean_Q',\n",
    "        'Category_q': 'Category_XYZ_Q',\n",
    "        'Mean_from_first_hy': 'Mean_HY',\n",
    "        'Category_hy': 'Category_XYZ_HY',\n",
    "        'Mean_from_first_5m': 'Mean_5M', \n",
    "         'Category_5m': 'Category_XYZ_5M',\n",
    "        'Std_from_first_5m': 'Std_dev_5M'\n",
    "    })\n",
    "    \n",
    "    abc_xyz['Quantity'] = abc_xyz['Quantity'].round(0)\n",
    "    abc_xyz['Mean'] = abc_xyz['Mean'].round(0)\n",
    "    abc_xyz['Mean_Q'] = abc_xyz['Mean_Q'].round(0)\n",
    "    abc_xyz['Mean_HY'] = abc_xyz['Mean_HY'].round(0)\n",
    "    abc_xyz['Mean_5M'] = abc_xyz['Mean_5M'].round(0)\n",
    "    abc_xyz['Std_dev_5M'] = abc_xyz['Std_dev_5M'].round(3)\n",
    "    \n",
    "    abc_xyz = abc_xyz.sort_values(by=['ABC_Group', 'Category_XYZ', 'Total_EUR', 'Quantity'], ascending=[True, False, False, False])\n",
    "    \n",
    "    abc_xyz['sum'] = 0  # initialize 'sum' column to 0\n",
    "    \n",
    "    mask = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ'] == 'X')  # create a boolean mask for the rows to multiply\n",
    "    mask_q = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ_Q'] == 'XQ')\n",
    "    mask_hy = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ_HY'] == 'XH')\n",
    "    mask_5m = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ_5M'] == 'X5M')\n",
    "    \n",
    "    mask2 = (abc_xyz['Status'] == 1)\n",
    "    abc_xyz.loc[mask2, 'COGS'] = ((abc_xyz.loc[mask2, 'Total_EUR'])* 0.7 / abc_xyz.loc[mask2, 'Quantity'])\n",
    "    \n",
    "\n",
    "    abc_xyz.loc[mask, 'sum'] = abc_xyz.loc[mask, 'COGS'] * abc_xyz.loc[mask, 'Mean']  # multiply the selected rows and assign to 'sum' column\n",
    "    abc_xyz.loc[mask_q, 'sum_q'] = abc_xyz.loc[mask_q, 'COGS'] * abc_xyz.loc[mask_q, 'Mean_Q']\n",
    "    abc_xyz.loc[mask_hy, 'sum_hy'] = abc_xyz.loc[mask_hy, 'COGS'] * abc_xyz.loc[mask_hy, 'Mean_HY']\n",
    "    abc_xyz.loc[mask_5m, 'sum_5m'] = abc_xyz.loc[mask_5m, 'COGS'] * abc_xyz.loc[mask_5m, 'Mean_5M']\n",
    "    \n",
    "    a_x_df = abc_xyz[(abc_xyz[column_A] == value_A)  & (abc_xyz['Category_XYZ'] == 'X')] #& (abc_xyz[column_x] == value_X)\n",
    "    \n",
    "    final_df = pd.concat([final_df, a_x_df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    abc_xyz.to_excel(writer, sheet_name=bu)\n",
    "\n",
    "# Save and close the Excel writer object\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6efdf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/axfile.xlsx')\n",
    "final_df.to_excel(writer, sheet_name='full')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "396692d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l_r = elc_stock_df_l.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c2d77535",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l = elc_stock_df_l_r.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b23a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_addition = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37fa1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_addition = elc_addition.rename(columns={'Model':'MS Code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b470a663",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_addition = elc_addition.loc[:, ['MS Code', 'Mean', 'Std_dev_5M', 'COGS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7647d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l = elc_stock_df_l.merge(elc_addition, on='MS Code', how='outer', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdcc4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['New safety stock level'] = np.round(elc_stock_df_l['Std_dev_5M'] * 1.65* np.sqrt(5), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4b45d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['COGS'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "866a55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['COGS'] = elc_stock_df_l['COGS'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8aa52573",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['New safety stock level'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85808c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['Mean'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3be5c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['Current Free Stock for Ordering OpCo'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dc4b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['Initial Order'] = elc_stock_df_l['New safety stock level'] +  5 * elc_stock_df_l['Mean'] - elc_stock_df_l['Current Free Stock for Ordering OpCo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6412e54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['Budget Estimation'] = 1.104 * elc_stock_df_l['COGS'] * elc_stock_df_l['Initial Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "247e086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l['Budget Estimation'] = elc_stock_df_l['Budget Estimation'].apply(lambda x: round(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e0680e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_five_month = pd.pivot_table(orders_df_for_five, values='order_intake_quantity', index='ms_code', columns=['5_month'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_five_month.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc1cd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = month_to_group.copy()\n",
    "\n",
    "# Group the keys by values\n",
    "groups = {}\n",
    "for key, value in data.items():\n",
    "    if value not in groups:\n",
    "        groups[value] = []\n",
    "    groups[value].append(key)\n",
    "\n",
    "# Connect the first and last keys for each value as a string\n",
    "result = {}\n",
    "for value, keys in groups.items():\n",
    "    first_key = keys[0]\n",
    "    last_key = keys[-1]\n",
    "    result[value] = str(first_key) + \"-\" + str(last_key)\n",
    "\n",
    "pivot_table_five_month = pivot_table_five_month.rename(columns=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4f7edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_stock_df_l = elc_stock_df_l.merge(pivot_table_five_month, left_on='MS Code', right_on='ms_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5cc24104",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/plus.xlsx')\n",
    "elc_stock_df_l.to_excel(writer, sheet_name='elc+')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ac732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
