{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92f9ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read Data1.xlsx into a dataframe\n",
    "orders_data_fy17_fy21 = pd.read_excel('data_files/Data1.xlsx')\n",
    "\n",
    "# Read Data2.xlsx into a dataframe\n",
    "orders_data_fy21_fy22 = pd.read_excel('data_files/Data2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29ba4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep desired columns\n",
    "temp_df = orders_data_fy17_fy21[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'order intake EUR']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df['year_month_date'] = pd.to_datetime(temp_df['year_month'], format='%Y%m')\n",
    "temp_df['FY'] = np.where(temp_df['year_month_date'].dt.month >= 4, temp_df['year_month_date'].dt.year, temp_df['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df['quarter'] = temp_df['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df['half_year'] = np.where(temp_df['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df = temp_df.rename(columns={'sold_to_customer_n_latest': 'customer', 'order intake EUR': 'order_intake_EUR'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "270fd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df\n",
    "new_df.to_excel('data_files/new_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4716de",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df2 = orders_data_fy21_fy22[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'Order Intake Euro']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df2['year_month_date'] = pd.to_datetime(temp_df2['year_month'], format='%Y%m')\n",
    "temp_df2['FY'] = np.where(temp_df2['year_month_date'].dt.month >= 4, temp_df2['year_month_date'].dt.year, temp_df2['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df2['quarter'] = temp_df2['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df2['half_year'] = np.where(temp_df2['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df2 = temp_df2.rename(columns={'sold_to_customer_n_latest': 'customer', 'Order Intake Euro': 'order_intake_EUR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ee4045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df2\n",
    "temp_df2.to_excel('data_files/new_file2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb20fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two prepared df\n",
    "orders_data = pd.concat([temp_df, temp_df2], ignore_index=True)\n",
    "# Check sales_data\n",
    "orders_data.to_excel('data_files/orders_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abbf8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns were changed to categorical data type: \n",
      "company_code_n\n",
      "bu\n",
      "bu_n\n",
      "FY\n",
      "quarter\n",
      "half_year\n"
     ]
    }
   ],
   "source": [
    "orders_data_opt = orders_data.copy()\n",
    "# Reduce the memory usage of the dataframe and improve performance\n",
    "def check_unique_values(df):\n",
    "    changed_columns = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values < 50:\n",
    "            df[col] = df[col].astype('category')\n",
    "            changed_columns.append(col)\n",
    "    if len(changed_columns) > 0:\n",
    "        print(\"The following columns were changed to categorical data type: \")\n",
    "        for col in changed_columns:\n",
    "            print(col)\n",
    "    else:\n",
    "        print(\"No columns were changed to categorical data type.\")\n",
    "        \n",
    "check_unique_values(orders_data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80de3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'ms_code' contains text with 'BOP'\n",
    "orders_data_opt['ms_code'] = orders_data_opt['ms_code'].astype(str)\n",
    "orders_data_opt = orders_data_opt[~orders_data_opt['ms_code'].str.contains('BOP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8dd88684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_amount.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['ms_code', 'order_intake_EUR']]\n",
    "    \n",
    "    # Group by ms_code and sum order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_EUR', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3542a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_quantity_per_month.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['year_month_date', 'ms_code', 'order_intake_quantity']]\n",
    "    \n",
    "    # Group by month and ms_code and sum order_intake_quantity and order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['year_month_date', 'ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_quantity', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3a6d5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC analysis per bu\n",
    "# Create a new Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/order_data_ABC_per_bu.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Get a list of the unique 'bu' values\n",
    "bu_values = orders_data_opt['bu'].unique()\n",
    "\n",
    "# Loop over each 'bu' value\n",
    "for bu in bu_values:\n",
    "\n",
    "    # Filter the data for the current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu]\n",
    "\n",
    "    # Group by 'ms_code' and calculate the total 'order_intake_EUR'\n",
    "    total_eur = bu_df.groupby('ms_code')['order_intake_EUR'].sum()\n",
    "\n",
    "    # Calculate the share of 'order_intake_EUR' for each 'ms_code'\n",
    "    eur_share = total_eur / total_eur.sum()\n",
    "\n",
    "    # Sort the 'ms_code' by descending 'order_intake_EUR'\n",
    "    sorted_ms = total_eur.sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted 'order_intake_EUR'\n",
    "    cumulative_sum = sorted_ms.cumsum()\n",
    "\n",
    "    # Calculate the percentage of the cumulative sum\n",
    "    cumulative_percent = cumulative_sum / total_eur.sum() * 100\n",
    "\n",
    "    # Categorize the 'ms_code' into ABC groups based on the cumulative percentage\n",
    "    abc_group = pd.cut(cumulative_percent, bins=[0, 70, 90, 100], labels=['A', 'B', 'C'])\n",
    "\n",
    "    # Create a new dataframe with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Total_EUR': total_eur,\n",
    "        'Share': eur_share,\n",
    "        'Cumulative_Sum_EUR': cumulative_sum,\n",
    "        'Cumulative_Percent': cumulative_percent,\n",
    "        'ABC_Group': abc_group\n",
    "    })\n",
    "\n",
    "    # Write the results to a new sheet in the Excel file\n",
    "    results_df.to_excel(writer, sheet_name=bu)\n",
    "\n",
    "# Save and close the Excel writer object\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c92dc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from 'year_month' column\n",
    "df = orders_data_opt.copy()\n",
    "df['year_month'] = pd.to_datetime(df['year_month'], format='%Y%m')\n",
    "df['year'] = df['year_month'].dt.year\n",
    "df['month'] = df['year_month'].dt.month\n",
    "\n",
    "# Create a new Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/stock_XYZ.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Get a list of the unique 'bu' values\n",
    "bu_values = df['bu'].unique()\n",
    "\n",
    "# Loop over each 'bu' value\n",
    "for bu in bu_values:\n",
    "\n",
    "    # Filter the data for the current 'bu' value\n",
    "    bu_df = df[df['bu'] == bu]\n",
    "    \n",
    "    orders = bu_df.groupby('ms_code')['order_intake_quantity'].sum()\n",
    "    orders = orders.reset_index()\n",
    "    df_monthly_orders = bu_df.groupby(['ms_code', pd.Grouper(key='year_month', freq='M')])['order_intake_quantity'].sum()\n",
    "    df_mean_std = df_monthly_orders.groupby('ms_code').agg(['mean', 'std']).fillna(0)\n",
    "    df_mean_std.reset_index()\n",
    "    \n",
    "    # Merge the 'ms_stats' DataFrame with the 'total_qty' DataFrame\n",
    "    orders = orders.merge(df_mean_std, on='ms_code')\n",
    "    \n",
    "    orders.to_excel(writer, sheet_name=bu)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Group by 'year_month' and 'ms_code' and calculate the total 'order_intake_quantity'\n",
    "    total_qty = bu_df.groupby(['year_month', 'ms_code'])['order_intake_quantity'].sum()\n",
    "\n",
    "    # Reset the index to turn 'year_month' and 'ms_code' back into columns\n",
    "    total_qty = total_qty.reset_index()\n",
    "    \n",
    "    # Group by 'ms_code' and calculate the mean and standard deviation of 'order_intake_quantity'\n",
    "    ms_stats = total_qty.groupby('ms_code')['order_intake_quantity'].agg(['mean', 'std']).fillna(0)\n",
    "\n",
    "\n",
    "# assuming your data is in a DataFrame called 'df'\n",
    "df['year_month'] = pd.to_datetime(df['year_month']) # convert year_month column to datetime format\n",
    "df_monthly_sales = df.groupby(['ms_code', pd.Grouper(key='year_month', freq='M')])['order_intake_quantity'].sum()\n",
    "df_mean_std = df_monthly_sales.groupby('ms_code').agg(['mean', 'std'])\n",
    "    \n",
    "\n",
    "    # Calculate the frequency of ordering for each 'ms_code' within each 'year_month'\n",
    "    ms_order_count = total_qty.groupby('ms_code')['order_intake_quantity'].count()\n",
    "    ms_order_count_mean = ms_order_count.mean()\n",
    "    ms_order_count_std = ms_order_count.std()\n",
    "    ms_order_count = ms_order_count.fillna(0)  # Replace NaN values with 0\n",
    "    if np.isnan(ms_order_count_std):\n",
    "        ms_order_count_std = 1\n",
    "    #x_group = pd.cut(ms_order_count, bins=[-1, ms_order_count_mean - ms_order_count_std, ms_order_count_mean + ms_order_count_std, ms_order_count.max()], labels=['X', 'Y', 'Z'])\n",
    "    \n",
    "    # Sort the bin edges in ascending order\n",
    "    bins = sorted([-1, ms_order_count_mean - ms_order_count_std, ms_order_count_mean + ms_order_count_std, ms_order_count.max()])\n",
    "\n",
    "    # Use the sorted bin edges to create the XYZ groups\n",
    "    x_group = pd.cut(ms_order_count, bins=bins, labels=['X', 'Y', 'Z'])\n",
    "\n",
    "    # Calculate the total 'order_intake_EUR' for each 'ms_code'\n",
    "    total_eur = bu_df.groupby('ms_code')['order_intake_EUR'].sum()\n",
    "\n",
    "    # Calculate the share of 'order_intake_EUR' for each 'ms_code'\n",
    "    eur_share = total_eur / total_eur.sum()\n",
    "\n",
    "    # Sort the 'ms_code' by descending 'order_intake_EUR'\n",
    "    sorted_ms = total_eur.sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted 'order_intake_EUR'\n",
    "    cumulative_sum = sorted_ms.cumsum()\n",
    "\n",
    "    # Calculate the percentage of the cumulative sum\n",
    "    cumulative_percent = cumulative_sum / total_eur.sum() * 100\n",
    "\n",
    "    # Categorize the 'ms_code' into ABC groups based on the cumulative percentage\n",
    "    abc_group = pd.cut(cumulative_percent, bins=[0, 70, 90, 100], labels=['A', 'B', 'C']) \n",
    "\n",
    "    # Create a new dataframe with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Total_EUR': total_eur,\n",
    "        'Share': eur_share,\n",
    "        'Cumulative_Sum_EUR': cumulative_sum,\n",
    "        'Cumulative_Percent': cumulative_percent,\n",
    "        'ABC_Group': abc_group,\n",
    "        'Order_Count': ms_order_count,\n",
    "        'XYZ_Group': x_group,\n",
    "        'Order_Count_Mean': total_qty['mean'],\n",
    "         'Order_Count_STD': total_qty['std']\n",
    "    })\n",
    "\n",
    "    # Write the results to a new sheet in the Excel file\n",
    "    results_df.to_excel(writer, sheet_name=bu)\"\"\"\n",
    "    \n",
    "\n",
    "# Save and close\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ff8cd0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ms_code           year_month\n",
       "COMRDS/Z          2021-09-30    16.0\n",
       "                  2021-11-30     0.0\n",
       "                  2021-12-31     0.0\n",
       "                  2022-01-31     0.0\n",
       "                  2022-02-28     0.0\n",
       "                                ... \n",
       "XS770A-A2K2-A1CA  2022-11-30    16.0\n",
       "                  2022-12-31    80.0\n",
       "                  2023-01-31     2.0\n",
       "                  2023-02-28     2.0\n",
       "                  2023-03-31     0.0\n",
       "Name: order_intake_quantity, Length: 486, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monthly_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2d7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
