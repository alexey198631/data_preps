{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdcdb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read Data1.xlsx into a dataframe\n",
    "orders_data_fy17_fy21 = pd.read_excel('data_files/Data1.xlsx')\n",
    "\n",
    "# Read Data2.xlsx into a dataframe\n",
    "orders_data_fy21_fy22 = pd.read_excel('data_files/Data2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e0d6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep desired columns\n",
    "temp_df = orders_data_fy17_fy21[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'order intake EUR']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df['year_month_date'] = pd.to_datetime(temp_df['year_month'], format='%Y%m')\n",
    "temp_df['FY'] = np.where(temp_df['year_month_date'].dt.month >= 4, temp_df['year_month_date'].dt.year, temp_df['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df['quarter'] = temp_df['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df['half_year'] = np.where(temp_df['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df = temp_df.rename(columns={'sold_to_customer_n_latest': 'customer', 'order intake EUR': 'order_intake_EUR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "811d69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df\n",
    "new_df.to_excel('data_files/new_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df2 = orders_data_fy21_fy22[['year_month', 'company_code_n', 'sold_to_customer_n_latest', 'bu', 'bu_n', 'material', 'ms_code', 'order_intake_quantity', 'Order Intake Euro']]\n",
    "\n",
    "# Parse 'year_month' column and create 'FY' column. FY start from 4 month\n",
    "temp_df2['year_month_date'] = pd.to_datetime(temp_df2['year_month'], format='%Y%m')\n",
    "temp_df2['FY'] = np.where(temp_df2['year_month_date'].dt.month >= 4, temp_df2['year_month_date'].dt.year, temp_df2['year_month_date'].dt.year - 1)\n",
    "\n",
    "# Create fiscal 'quarter' column\n",
    "quarter_dict = {1: 'Q4', 2: 'Q4', 3: 'Q4', 4: 'Q1', 5: 'Q1', 6: 'Q1', 7: 'Q2', 8: 'Q2', 9: 'Q2', 10: 'Q3', 11: 'Q3', 12: 'Q3'}\n",
    "temp_df2['quarter'] = temp_df2['year_month_date'].dt.month.map(quarter_dict)\n",
    "\n",
    "# Create 'half_year' column\n",
    "temp_df2['half_year'] = np.where(temp_df2['year_month_date'].dt.month.between(4, 9), 'HY1', 'HY2')\n",
    "\n",
    "# Rename columns\n",
    "temp_df2 = temp_df2.rename(columns={'sold_to_customer_n_latest': 'customer', 'Order Intake Euro': 'order_intake_EUR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "781e2e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_df2\n",
    "temp_df2.to_excel('data_files/new_file2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ea3a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine two prepared df\n",
    "orders_data = pd.concat([temp_df, temp_df2], ignore_index=True)\n",
    "# Check sales_data\n",
    "orders_data.to_excel('data_files/orders_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e648ed9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns were changed to categorical data type: \n",
      "company_code_n\n",
      "bu\n",
      "bu_n\n",
      "FY\n",
      "quarter\n",
      "half_year\n"
     ]
    }
   ],
   "source": [
    "orders_data_opt = orders_data.copy()\n",
    "# Reduce the memory usage of the dataframe and improve performance\n",
    "def check_unique_values(df):\n",
    "    changed_columns = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].nunique()\n",
    "        if unique_values < 50:\n",
    "            df[col] = df[col].astype('category')\n",
    "            changed_columns.append(col)\n",
    "    if len(changed_columns) > 0:\n",
    "        print(\"The following columns were changed to categorical data type: \")\n",
    "        for col in changed_columns:\n",
    "            print(col)\n",
    "    else:\n",
    "        print(\"No columns were changed to categorical data type.\")\n",
    "        \n",
    "check_unique_values(orders_data_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd33fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where 'ms_code' contains text with 'BOP'\n",
    "orders_data_opt['ms_code'] = orders_data_opt['ms_code'].astype(str)\n",
    "orders_data_opt = orders_data_opt[~orders_data_opt['ms_code'].str.contains('BOP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fdf0aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total amount of orders per ms_code in eur\n",
    "\n",
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_amount.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['ms_code', 'order_intake_EUR']]\n",
    "    \n",
    "    # Group by ms_code and sum order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_EUR', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1518164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total quantity of ms_codes per month\n",
    "\n",
    "# Create Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/sales_data_bu_sheets_total_quantity_per_month.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Loop over unique values in 'bu' column\n",
    "for bu in orders_data_opt['bu'].unique():\n",
    "    # Create new dataframe for current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu][['year_month_date', 'ms_code', 'order_intake_quantity']]\n",
    "    \n",
    "    # Group by month and ms_code and sum order_intake_quantity and order_intake_EUR\n",
    "    bu_df = bu_df.groupby(['year_month_date', 'ms_code']).sum().reset_index()\n",
    "    bu_df = bu_df.sort_values('order_intake_quantity', ascending=False)\n",
    "    \n",
    "    # Write dataframe to a new sheet in the Excel file\n",
    "    bu_df.to_excel(writer, sheet_name=f'{bu}', index=False)\n",
    "\n",
    "# Save the Excel file\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a744e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XYZ analysis\n",
    "\n",
    "def mean_std_from_first_nonzero(row):\n",
    "    # Find the index of the first non-zero value in the row\n",
    "    nonzero_indices = np.nonzero(row.values[1:])[0]\n",
    "    if len(nonzero_indices) > 0:\n",
    "        first_nonzero_index = nonzero_indices[0] + 1  # Add 1 to account for the fact that we started at the second column\n",
    "        mean = row.iloc[first_nonzero_index:].mean()  # Calculate the mean of the remaining values\n",
    "        std = row.iloc[first_nonzero_index:].std()  # Calculate the standard deviation of the remaining values\n",
    "        return pd.Series({'Mean': mean, 'Std': std})  # Return the mean and standard deviation as a Series\n",
    "    else:\n",
    "        return pd.Series({'Mean': 0, 'Std': 0})  # If all values are zero, return 0 for mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f69011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table for ms_code for each month with NaN values filled with 0\n",
    "pivot_table_month = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns='year_month_date', aggfunc='sum', fill_value=0) # margins=True , fill_value=0\n",
    "pivot_table_month.reset_index(inplace=True)\n",
    "# sort the pivot table by the total column in descending order\n",
    "#pivot_table_month = pivot_table_month.sort_values(by='All', ascending=False)\n",
    "\n",
    "pivot_table_half_year = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns=['FY', 'half_year'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_year.reset_index(inplace=True)\n",
    "\n",
    "pivot_table_half_quarter = pd.pivot_table(orders_data_opt, values='order_intake_quantity', index='ms_code', columns=['FY', 'quarter'], aggfunc='sum', fill_value=0)\n",
    "pivot_table_half_quarter.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# Calculate the sum of the last year for different pivots\n",
    "last_12_sum = pivot_table_month.iloc[:, -12:].sum(axis=1)\n",
    "last_2_sum = pivot_table_half_year.iloc[:, -2:].sum(axis=1)\n",
    "last_4_sum = pivot_table_half_quarter.iloc[:, -4:].sum(axis=1)\n",
    "\n",
    "\n",
    "# Select the rows where the sum is greater than 0\n",
    "pivot_table_month = pivot_table_month[last_12_sum > 0]\n",
    "pivot_table_month.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year[last_2_sum > 0]\n",
    "pivot_table_half_year.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter[last_4_sum > 0]\n",
    "pivot_table_half_quarter.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "# calculate mean and std deviation for each product from the first month where it was sold\n",
    "# Apply the function to each row of the dataframe, and store the results in new columns\n",
    "pivot_table_month[['Mean_from_first', 'Std_from_first']] = pivot_table_month.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_year[['Mean_from_first_hy', 'Std_from_first_hy']] = pivot_table_half_year.apply(mean_std_from_first_nonzero, axis=1)\n",
    "pivot_table_half_quarter[['Mean_from_first_q', 'Std_from_first_q']] = pivot_table_half_quarter.apply(mean_std_from_first_nonzero, axis=1)\n",
    "\n",
    "# calculate mean and std deviation for each product\n",
    "df_mean = pivot_table_month.iloc[:, 1:].mean(axis=1)\n",
    "df_std = pivot_table_month.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_h = pivot_table_half_year.iloc[:, 1:].mean(axis=1)\n",
    "df_std_h = pivot_table_half_year.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "df_mean_q = pivot_table_half_quarter.iloc[:, 1:].mean(axis=1)\n",
    "df_std_q = pivot_table_half_quarter.iloc[:, 1:].std(axis=1)\n",
    "\n",
    "# categorize products based on std deviation\n",
    "df_category = pd.cut(df_std, bins=[-float('inf'), 0.5*pivot_table_month['Mean_from_first'].mean(), pivot_table_month['Mean_from_first'].mean(), float('inf')], labels=['Z', 'Y', 'X'])\n",
    "df_category_h = pd.cut(df_std_h, bins=[-float('inf'), 0.5*pivot_table_half_year['Mean_from_first_hy'].mean(), pivot_table_half_year['Mean_from_first_hy'].mean(), float('inf')], labels=['ZH', 'YH', 'XH'])\n",
    "df_category_q = pd.cut(df_std_q, bins=[-float('inf'), 0.5*pivot_table_half_quarter['Mean_from_first_q'].mean(), pivot_table_half_quarter['Mean_from_first_q'].mean(), float('inf')], labels=['ZQ', 'YQ', 'XQ'])\n",
    "\n",
    "# add new columns to the original dataframe\n",
    "pivot_table_month = pivot_table_month.assign(Mean=df_mean, Std=df_std, Category=df_category)\n",
    "pivot_table_month = pivot_table_month.loc[:,['ms_code','Mean_from_first', 'Std_from_first', 'Mean', 'Std', 'Category']]\n",
    "\n",
    "pivot_table_half_year = pivot_table_half_year.assign(Mean_hy=df_mean_h, Std_hy=df_std_h, Category_hy=df_category_h)\n",
    "pivot_table_half_year = pivot_table_half_year.loc[:,['ms_code','Mean_from_first_hy', 'Std_from_first_hy', 'Mean_hy', 'Std_hy', 'Category_hy']]\n",
    "pivot_table_half_year = pivot_table_half_year.reset_index(level=0, drop=True)\n",
    "pivot_table_half_year.columns = pivot_table_half_year.columns.get_level_values(0)\n",
    "\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.assign(Mean_q=df_mean_q, Std_q=df_std_q, Category_q=df_category_q)\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.loc[:,['ms_code','Mean_from_first_q', 'Std_from_first_q', 'Mean_q', 'Std_q', 'Category_q']]\n",
    "pivot_table_half_quarter = pivot_table_half_quarter.reset_index(level=0, drop=True)\n",
    "pivot_table_half_quarter.columns = pivot_table_half_quarter.columns.get_level_values(0)\n",
    "\n",
    "writer = pd.ExcelWriter('data_files/order_data_XYZ.xlsx', engine='xlsxwriter')\n",
    "pivot_table_month.to_excel(writer, sheet_name='month')\n",
    "pivot_table_half_year.to_excel(writer, sheet_name='half year')\n",
    "pivot_table_half_quarter.to_excel(writer, sheet_name='quarter')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4851f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pricing information\n",
    "priced = pd.read_excel('data_files/priced_positions.xlsx')\n",
    "priced = priced.loc[:,['Model', 'COGS', 'Chk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d35591",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_opt_with_price = pd.merge(orders_data_opt, priced, left_on='ms_code', right_on='Model', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7037b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('data_files/test.xlsx', engine='xlsxwriter')\n",
    "orders_data_opt_with_price.to_excel(writer, sheet_name='month')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6effc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_data_opt = orders_data_opt_with_price.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a1251632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABC + XYZ analysis per bu\n",
    "\n",
    "# Create a new Excel writer object\n",
    "writer = pd.ExcelWriter('data_files/order_data_ABC_XYZ_per_bu.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Get a list of the unique 'bu' values\n",
    "bu_values = sorted(orders_data_opt['bu'].unique())\n",
    "\n",
    "# Loop over each 'bu' value\n",
    "for bu in bu_values:\n",
    "\n",
    "    # Filter the data for the current 'bu' value\n",
    "    bu_df = orders_data_opt[orders_data_opt['bu'] == bu]\n",
    "    \n",
    "    # prices \n",
    "    \n",
    "    indexed_df = bu_df.set_index('ms_code')\n",
    "    ms_code_price = indexed_df['COGS'].to_dict()\n",
    "    ms_code_priced = pd.Series(ms_code_price)\n",
    "    \n",
    "    indexed_df_status = bu_df.set_index('ms_code')\n",
    "    ms_code_status = indexed_df['Chk'].to_dict()\n",
    "    ms_code_statused = pd.Series(ms_code_status)\n",
    "\n",
    "    # Group by 'ms_code' and calculate the total 'order_intake_EUR'\n",
    "    total_eur = bu_df.groupby('ms_code')['order_intake_EUR'].sum()\n",
    "    total_quant = bu_df.groupby('ms_code')['order_intake_quantity'].sum()\n",
    "\n",
    "    # Calculate the share of 'order_intake_EUR' for each 'ms_code'\n",
    "    eur_share = total_eur / total_eur.sum()\n",
    "\n",
    "    # Sort the 'ms_code' by descending 'order_intake_EUR'\n",
    "    sorted_ms = total_eur.sort_values(ascending=False)\n",
    "\n",
    "    # Calculate the cumulative sum of the sorted 'order_intake_EUR'\n",
    "    cumulative_sum = sorted_ms.cumsum()\n",
    "\n",
    "    # Calculate the percentage of the cumulative sum\n",
    "    cumulative_percent = cumulative_sum / total_eur.sum() * 100\n",
    "\n",
    "    # Categorize the 'ms_code' into ABC groups based on the cumulative percentage\n",
    "    abc_group = pd.cut(cumulative_percent, bins=[0, 70, 90, 100], labels=['A', 'B', 'C'])\n",
    "\n",
    "    # Create a new dataframe with the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'Total_EUR': total_eur,\n",
    "        'Share': eur_share,\n",
    "        'Cumulative_Sum_EUR': cumulative_sum,\n",
    "        'Cumulative_Percent': cumulative_percent,\n",
    "        'ABC_Group': abc_group,\n",
    "        'Quantity': total_quant,\n",
    "        'COGS': ms_code_priced,\n",
    "        'Status': ms_code_statused\n",
    "    })\n",
    "    \n",
    "\n",
    "    # Write the results to a new sheet in the Excel file\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df = results_df.rename(columns={'index': 'ms_code'})\n",
    "    results_df = results_df.merge(pivot_table_month[['ms_code', 'Mean_from_first', 'Std_from_first', 'Category']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df= results_df.merge(pivot_table_half_quarter[['ms_code', 'Mean_from_first_q', 'Std_from_first_q', 'Category_q']],\n",
    "                       on='ms_code', how='left')\n",
    "    results_df = results_df.merge(pivot_table_half_year[['ms_code', 'Mean_from_first_hy', 'Std_from_first_hy', 'Category_hy']],\n",
    "                       on='ms_code', how='left')\n",
    "    \n",
    "    abc_xyz = results_df.loc[:,['ms_code', 'Total_EUR', 'ABC_Group',  'Category', 'Quantity', 'Mean_from_first',\n",
    "       'Category_q', 'Mean_from_first_q', 'Category_hy', 'Mean_from_first_hy', 'COGS', 'Status']]\n",
    "    \n",
    "    abc_xyz = abc_xyz.rename(columns={\n",
    "        'ms_code': 'Model',\n",
    "        'Mean_from_first': 'Mean',\n",
    "        'Category': 'Category_XYZ',\n",
    "        'Mean_from_first_q': 'Mean_Q',\n",
    "        'Category_q': 'Category_XYZ_Q',\n",
    "        'Mean_from_first_hy': 'Mean_HY',\n",
    "        'Category_hy': 'Category_XYZ_HY'})\n",
    "    \n",
    "    abc_xyz['Quantity'] = abc_xyz['Quantity'].round(0)\n",
    "    abc_xyz['Mean'] = abc_xyz['Mean'].round(0)\n",
    "    abc_xyz['Mean_Q'] = abc_xyz['Mean_Q'].round(0)\n",
    "    abc_xyz['Mean_HY'] = abc_xyz['Mean_HY'].round(0)\n",
    "    \n",
    "    abc_xyz = abc_xyz.sort_values(by=['ABC_Group', 'Category_XYZ', 'Total_EUR', 'Quantity'], ascending=[True, False, False, False])\n",
    "    \n",
    "    abc_xyz['sum'] = 0  # initialize 'sum' column to 0\n",
    "    mask = (abc_xyz['ABC_Group'] == 'A') & (abc_xyz['Category_XYZ'] == 'X')  # create a boolean mask for the rows to multiply\n",
    "    mask2 = (abc_xyz['Status'] == 1)\n",
    "    abc_xyz.loc[mask2, 'COGS'] = ((abc_xyz.loc[mask2, 'Total_EUR'])* 0.7 / abc_xyz.loc[mask2, 'Quantity'])\n",
    "\n",
    "    abc_xyz.loc[mask, 'sum'] = abc_xyz.loc[mask, 'COGS'] * abc_xyz.loc[mask, 'Mean']  # multiply the selected rows and assign to 'sum' column\n",
    "\n",
    "    abc_xyz.to_excel(writer, sheet_name=bu)\n",
    "\n",
    "# Save and close the Excel writer object\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
